{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"YOLOs-CPP","text":"<p>     Modern C++ YOLO Library   </p> <p>Welcome to the official documentation for YOLOs-CPP - a high-performance, production-ready C++ library for object detection.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"Section Description Getting Started Installation and first steps API Reference Complete API documentation Examples Code examples Models Available YOLO models Architecture System design Benchmarks Benchmark evaluation Contributing How to contribute"},{"location":"#features","title":"Features","text":"<ul> <li>Multiple YOLO Models \u2014 YOLOv8 to YOLOv26</li> <li>Multiple Tasks \u2014 Detection, Segmentation, Pose Estimation</li> <li>High Performance \u2014 Optimized C++17 implementation</li> <li>Modern API \u2014 Clean, intuitive interface with ONNX Runtime and OpenCV</li> <li>Cross-Platform \u2014 Linux, macOS, Windows</li> <li>Well Tested \u2014 Comprehensive unit tests</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n#include &lt;chrono&gt;\n#include &lt;filesystem&gt;\n#include &lt;vector&gt;\n#include \"yolos/tasks/detection.hpp\"\n#include \"utils.hpp\"\n\nusing namespace yolos::det;\n\nint main(int argc, char* argv[]) {\n    namespace fs = std::filesystem;\n\n    // Default configuration\n    std::string modelPath = \"../../models/yolo11n.onnx\";\n    std::string inputPath = \"../../data/dog.jpg\";\n    std::string labelsPath = \"../../models/coco.names\";\n    std::string outputDir = \"../../outputs/det/\";\n\n    // Check for help flag\n    if (argc &gt; 1 &amp;&amp; (std::string(argv[1]) == \"--help\" || std::string(argv[1]) == \"-h\")) {\n        utils::printUsage(argv[0], \"Object Detection\", modelPath, inputPath, labelsPath);\n        return 0;\n    }\n\n    // Parse command line arguments\n    if (argc &gt; 1) modelPath = argv[1];\n    if (argc &gt; 2) inputPath = argv[2];\n    if (argc &gt; 3) labelsPath = argv[3];\n\n    // Print usage information\n    utils::printUsage(argv[0], \"Object Detection\", modelPath, inputPath, labelsPath);\n\n    // Collect image files\n    std::vector&lt;std::string&gt; imageFiles;\n    try {\n        if (fs::is_directory(inputPath)) {\n            for (const auto&amp; entry : fs::directory_iterator(inputPath)) {\n                if (entry.is_regular_file() &amp;&amp; utils::isImageFile(entry.path().string())) {\n                    imageFiles.push_back(fs::absolute(entry.path()).string());\n                }\n            }\n            if (imageFiles.empty()) {\n                std::cerr &lt;&lt; \"\u274c No image files found in: \" &lt;&lt; inputPath &lt;&lt; std::endl;\n                return -1;\n            }\n        } else if (fs::is_regular_file(inputPath)) {\n            imageFiles.push_back(inputPath);\n        } else {\n            std::cerr &lt;&lt; \"\u274c Invalid path: \" &lt;&lt; inputPath &lt;&lt; std::endl;\n            return -1;\n        }\n    } catch (const fs::filesystem_error&amp; e) {\n        std::cerr &lt;&lt; \"\u274c Filesystem error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n        return -1;\n    }\n\n    // Initialize YOLO detector\n    bool useGPU = false; // CPU by default\n    std::cout &lt;&lt; \"\ud83d\udd04 Loading detection model: \" &lt;&lt; modelPath &lt;&lt; std::endl;\n\n    try {\n        YOLODetector detector(modelPath, labelsPath, useGPU);\n        std::cout &lt;&lt; \"\u2705 Model loaded successfully!\" &lt;&lt; std::endl;\n\n        // Process each image\n        for (const auto&amp; imgPath : imageFiles) {\n            std::cout &lt;&lt; \"\\n\ud83d\udcf7 Processing: \" &lt;&lt; imgPath &lt;&lt; std::endl;\n\n            // Load image\n            cv::Mat image = cv::imread(imgPath);\n            if (image.empty()) {\n                std::cerr &lt;&lt; \"\u274c Could not load image: \" &lt;&lt; imgPath &lt;&lt; std::endl;\n                continue;\n            }\n\n            // Run detection with timing\n            auto start = std::chrono::high_resolution_clock::now();\n            std::vector&lt;Detection&gt; detections = detector.detect(image);\n            auto duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(\n                std::chrono::high_resolution_clock::now() - start);\n\n            // Print results\n            std::cout &lt;&lt; \"\u2705 Detection completed!\" &lt;&lt; std::endl;\n            std::cout &lt;&lt; \"\ud83d\udcca Found \" &lt;&lt; detections.size() &lt;&lt; \" objects\" &lt;&lt; std::endl;\n\n            for (size_t i = 0; i &lt; detections.size(); ++i) {\n                std::cout &lt;&lt; \"   [\" &lt;&lt; i &lt;&lt; \"] Class=\" &lt;&lt; detections[i].classId \n                          &lt;&lt; \", Confidence=\" &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; detections[i].conf\n                          &lt;&lt; \", Box=(\" &lt;&lt; detections[i].box.x &lt;&lt; \",\" &lt;&lt; detections[i].box.y &lt;&lt; \",\"\n                          &lt;&lt; detections[i].box.width &lt;&lt; \"x\" &lt;&lt; detections[i].box.height &lt;&lt; \")\" &lt;&lt; std::endl;\n            }\n\n            // Draw detections\n            cv::Mat resultImage = image.clone();\n            detector.drawDetections(resultImage, detections);\n\n            // Save output with timestamp\n            std::string outputPath = utils::saveImage(resultImage, imgPath, outputDir);\n            std::cout &lt;&lt; \"\ud83d\udcbe Saved result to: \" &lt;&lt; outputPath &lt;&lt; std::endl;\n\n            // Display metrics\n            utils::printMetrics(\"Detection\", duration.count());\n\n            // Display result\n            cv::imshow(\"YOLO Detection\", resultImage);\n            std::cout &lt;&lt; \"Press any key to continue...\" &lt;&lt; std::endl;\n            cv::waitKey(0);\n        }\n\n        cv::destroyAllWindows();\n        std::cout &lt;&lt; \"\\n\u2705 All images processed successfully!\" &lt;&lt; std::endl;\n\n    } catch (const std::exception&amp; e) {\n        std::cerr &lt;&lt; \"\u274c Error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n        return -1;\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>YOLOs-CPP is licensed under the GNU Affero General Public License v3.0.</p>"},{"location":"#citation","title":"Citation","text":"<p>@software{YOLOs-CPP2026,   author = {YOLOs-CPP contributors},   title = {YOLOs-CPP: Modern C++ YOLO Library},   year = {2026},   url = {https://github.com/Geekgineer/YOLOs-CPP},   license = {AGPL-3.0} }</p>"},{"location":"YOLOs-CPP_on_Windows_11/","title":"YOLOs-CPP","text":"<p>YOLOs-CPP is a C++ implementation for running YOLO models (v5, v7, v8, v9, v10, v11, v12) for object detection, instance segmentation, oriented bounding boxes (OBB), pose estimation, and quantized model support. The project uses ONNX Runtime and OpenCV for efficient inference on images, videos, and camera feeds. All setup, model export, quantization, and testing were performed by the project owner on Windows 11 (x64).</p>"},{"location":"YOLOs-CPP_on_Windows_11/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Prerequisites</li> <li>Installation</li> <li>Windows-Specific Instructions</li> <li>Building the Project</li> <li>Usage Instructions</li> <li>Python Scripts for Model Export</li> <li>Modifications Made</li> <li>Troubleshooting</li> <li>Notes</li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#overview","title":"Overview","text":"<p>This project provides a C++ framework for running YOLO models for object detection, instance segmentation, oriented bounding boxes (OBB), and pose estimation. It supports: - Real-time inference on camera feeds (<code>camera_inference.cpp</code>). - Processing static images (<code>image_inference.cpp</code>). - Processing video files (<code>video_inference.cpp</code>). - Quantized models for faster CPU inference (<code>yolo11n_uint8.onnx</code>).</p> <p>All steps, from installation to testing, were executed and verified on Windows 11 (x64) using Visual Studio 2022, CMake, OpenCV 4.6.0, and ONNX Runtime.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#prerequisites","title":"Prerequisites","text":"<ul> <li>C++17 compatible compiler</li> <li>CMake (version 3.10 or higher)</li> <li>OpenCV (version 4.5.5 or higher)</li> <li>ONNX Runtime (version 1.16.3 or 1.19.2 recommended, with optional GPU support)</li> <li>Python Version 3.8+ with <code>onnxruntime</code> and <code>ultralytics</code> packages.</li> <li>Git for cloning the repository</li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#installation","title":"Installation","text":""},{"location":"YOLOs-CPP_on_Windows_11/#windows-specific-instructions","title":"Windows-Specific Instructions","text":"<p>All steps were performed by the project owner on Windows 11 (x64).</p> <ol> <li>Install Visual Studio 2022:</li> <li>Open https://visualstudio.microsoft.com/vs/.</li> <li>Click \"Free download\" under \"Community 2022\".</li> <li>Run the installer and select Desktop development with C++.</li> <li>Ensure MSVC v143 - VS 2022 C++ x64/x86 build tools is checked in the right panel.</li> <li>Click Install and restart your system if prompted.</li> <li> <p>Verify by opening Visual Studio and creating a new C++ project.</p> </li> <li> <p>Install CMake:</p> </li> <li>Open https://cmake.org/download/.</li> <li>Download the latest Windows x64 Installer.</li> <li>Run the installer and select Add CMake to the system PATH for all users.</li> <li> <p>Verify by opening PowerShell or CMD and running:      <code>powershell      cmake --version</code></p> <ul> <li>Expected output: <code>cmake version 3.x.x</code>.</li> </ul> </li> <li> <p>Install Python 3.8+:</p> </li> <li>Open https://www.python.org/downloads/.</li> <li>Download the latest Python 3.8+ installer.</li> <li>Run the installer and check Add Python to PATH in the first screen.</li> <li>Install and verify by running:      <code>powershell      python --version      pip --version</code></li> <li>Install required packages:      <code>powershell      pip install onnx onnxruntime numpy ultralytics</code></li> <li>If you see \"Python was not found\":<ul> <li>Open Start, search for \"App execution aliases\".</li> <li>Turn off <code>python.exe</code> and <code>python3.exe</code>.</li> </ul> </li> <li> <p>Verify Python packages:      <code>powershell      python -c \"import cv2; print(cv2.__version__)\"</code></p> <ul> <li>Expected output: <code>4.6.0</code> or higher.</li> </ul> </li> <li> <p>Install Git:</p> </li> <li>Open https://git-scm.com/download/win.</li> <li>Download and run the installer.</li> <li>Verify by running:      <code>powershell      git --version</code><ul> <li>Expected output: <code>git version 2.x.x</code>.</li> </ul> </li> </ol>"},{"location":"YOLOs-CPP_on_Windows_11/#set-up-dlls","title":"Set Up DLLs","text":"<ol> <li>Install OpenCV:</li> <li>Open https://opencv.org/releases/.</li> <li>Download OpenCV 4.6.0 for Windows.</li> <li>Extract to <code>C:\\opencv</code>.</li> <li>Copy the following DLLs from <code>C:\\opencv\\build\\x64\\vc16\\bin</code> to <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release</code> (after building):<ul> <li><code>opencv_videoio_ffmpeg460_64.dll</code></li> <li><code>opencv_videoio_msmf460_64.dll</code></li> <li><code>opencv_world460.dll</code></li> </ul> </li> <li>Add OpenCV\u2019s <code>bin</code> directory to the system PATH:<ul> <li>Open Start, search for \"Edit the system environment variables\".</li> <li>Click Environment Variables.</li> <li>Under System variables, select Path, click Edit.</li> <li>Click New and add:    <code>C:\\opencv\\build\\x64\\vc16\\bin</code></li> <li>Click OK to save all changes.</li> </ul> </li> <li>Restart PowerShell or CMD.</li> <li> <p>Verify:      <code>powershell      python -c \"import cv2; print(cv2.__version__)\"</code></p> <ul> <li>Expected output: <code>4.6.0</code>.</li> </ul> </li> <li> <p>Install ONNX Runtime:</p> </li> <li>Open https://github.com/microsoft/onnxruntime/releases.</li> <li>Download the Windows x64 ZIP (e.g., <code>onnxruntime-win-x64-gpu-1.16.3.zip</code> for GPU support).</li> <li>Extract to <code>C:\\onnxruntime</code>.</li> <li>Copy the following DLLs from <code>C:\\onnxruntime\\lib</code> to <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release</code> (after building):<ul> <li><code>onnxruntime.dll</code></li> <li><code>onnxruntime_providers_shared.dll</code></li> <li><code>onnxruntime_providers_cuda.dll</code> (if using GPU)</li> <li><code>onnxruntime_providers_tensorrt.dll</code> (if using GPU)</li> </ul> </li> <li>Add ONNX Runtime\u2019s <code>lib</code> directory to the system PATH:<ul> <li>Open Environment Variables as above.</li> <li>Select Path, click Edit.</li> <li>Click New and add:    <code>C:\\onnxruntime\\lib</code></li> <li>Click OK to save.</li> </ul> </li> <li>Restart PowerShell or CMD.</li> </ol>"},{"location":"YOLOs-CPP_on_Windows_11/#clone-the-repository","title":"Clone the Repository","text":"<ul> <li>Open PowerShell or CMD.</li> <li>Run:      <code>powershell      cd C:\\Users\\DELL\\source\\repos      git clone https://github.com/Geekgineer/YOLOs-CPP.git      cd YOLOs-CPP</code></li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#export-yolo-models-to-onnx","title":"Export YOLO Models to ONNX","text":"<ol> <li>Navigate to the <code>models</code> directory:    <code>powershell    cd C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\models</code></li> <li>Run the export scripts:</li> <li>Object Detection:      <code>powershell      python export_onnx.py</code><ul> <li>Exports <code>yolo11n.pt</code> to <code>yolo11n.onnx</code>.</li> </ul> </li> <li>Segmentation:      <code>powershell      python export_onnx_to_segment.py</code><ul> <li>Exports <code>yolo11n-seg.pt</code> to <code>yolo11n-seg.onnx</code>.</li> </ul> </li> <li>OBB:      <code>powershell      python export_onnx_to_obb.py</code><ul> <li>Exports <code>yolo11n-obb.pt</code> to <code>yolo11n-obb.onnx</code>.</li> </ul> </li> <li>Pose:      <code>powershell      python export_onnx_to_pose.py</code><ul> <li>Exports <code>yolo11n-pose.pt</code> to <code>yolo11n-pose.onnx</code>.</li> </ul> </li> <li>Verify that the ONNX files are in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\models</code>.</li> </ol>"},{"location":"YOLOs-CPP_on_Windows_11/#quantize-yolo-model","title":"Quantize YOLO Model","text":"<ol> <li>Navigate to the <code>quantized_models</code> directory:    <code>powershell    cd C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\quantized_models</code></li> <li>Run the quantization script:    <code>powershell    python yolos_quantization.py</code></li> <li>Quantizes <code>yolo11n.onnx</code> to <code>yolo11n_uint8.onnx</code> using per-channel quantization (UINT8).</li> <li>Verify that <code>yolo11n_uint8.onnx</code> is in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\models</code>.</li> </ol>"},{"location":"YOLOs-CPP_on_Windows_11/#building-the-project","title":"Building the Project","text":"<ol> <li>Navigate to the project directory:    <code>powershell    cd C:\\Users\\DELL\\source\\repos\\YOLOs-CPP</code></li> <li>Create and navigate to the build directory:    <code>powershell    mkdir build    cd build</code></li> <li> <p>Configure the project with CMake:    <code>powershell    cmake .. -G \"Visual Studio 17 2022\" -A x64 -DOpenCV_DIR=\"C:/opencv/build\" -DONNXRUNTIME_DIR=\"C:/onnxruntime\"</code></p> </li> <li> <p>Build the project in Release mode:    <code>powershell    cmake --build . --config Release</code></p> </li> </ol>"},{"location":"YOLOs-CPP_on_Windows_11/#usage-instructions","title":"Usage Instructions","text":"<p>All commands were tested successfully by the project owner on Windows 11 (x64). Ensure model files, label files, and input files are in the specified paths.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#object-detection-quantized-model","title":"Object Detection (Quantized Model)","text":"<p>Uses <code>yolo11n_uint8.onnx</code> for faster CPU inference. - Image Inference:   <code>powershell   cd C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build   .\\Release\\image_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\dog.jpg</code>   - Output: <code>output_dog.jpg</code> with bounding boxes. - Video Inference:   <code>powershell   .\\Release\\video_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\test.mp4</code>   - Output: <code>output_video.mp4</code> with bounding boxes. - Camera Inference:   <code>powershell   .\\Release\\camera_inference.exe</code>   - Output: PNG frames in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release\\output_frames</code>.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#instance-segmentation","title":"Instance Segmentation","text":"<p>Uses <code>yolo11n-seg.onnx</code> with <code>YOLO11SegDetector</code> (<code>seg/YOLO11Seg.hpp</code>). - Image Inference:   <code>powershell   .\\Release\\image_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\dog.jpg</code>   - Output: <code>output_dog.jpg</code> with segmentation masks. - Video Inference:   <code>powershell   .\\Release\\video_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\test.mp4</code>   - Output: <code>output_video.mp4</code> with segmentation masks. - Camera Inference:   <code>powershell   .\\Release\\camera_inference.exe</code>   - Output: PNG frames in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release\\output_frames</code>.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#oriented-bounding-boxes-obb","title":"Oriented Bounding Boxes (OBB)","text":"<p>Uses <code>yolo11n-obb.onnx</code> with <code>YOLO11OBBDetector</code> (<code>obb/YOLO11-OBB.hpp</code>) and <code>Dota.names</code>. - Image Inference:   <code>powershell   .\\Release\\image_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\dog.jpg</code>   - Output: <code>output_dog_obb.jpg</code> with oriented bounding boxes. - Video Inference:   <code>powershell   .\\Release\\video_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\test.mp4</code>   - Output: <code>output_video_obb.mp4</code> with oriented bounding boxes. - Camera Inference:   <code>powershell   .\\Release\\camera_inference.exe</code>   - Output: PNG frames in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release\\output_frames_obb</code>.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#pose-estimation","title":"Pose Estimation","text":"<p>Uses <code>yolo11n-pose.onnx</code> with <code>YOLO11POSEDetector</code> (<code>pose/YOLO11-POSE.hpp</code>) on inputs with persons. - Image Inference:   <code>powershell   .\\Release\\image_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\person.jpg</code>   - Output: <code>output_pose.jpg</code> with keypoints and skeletons. - Video Inference:   <code>powershell   .\\Release\\video_inference.exe C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\data\\test_pose.mp4</code>   - Output: <code>output_video_pose.mp4</code> with keypoints and skeletons. - Camera Inference:   <code>powershell   .\\Release\\camera_inference.exe</code>   - Output: PNG frames in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release\\output_frames_pose</code>.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#python-scripts-for-model-export","title":"Python Scripts for Model Export","text":"<p>The following Python scripts were created or modified by the project owner to export and quantize YOLO models.</p> <ol> <li><code>export_onnx.py</code> (modified):    ```python    from ultralytics import YOLO</li> </ol> <p># Load the YOLOv11n model    model = YOLO(\"yolo11n.pt\")</p> <p># Export the model to ONNX format    model.export(format=\"onnx\")    ```</p> <ol> <li><code>export_onnx_to_segment.py</code> (created):    ```python    from ultralytics import YOLO</li> </ol> <p># Load the YOLOv11 segmentation model    model = YOLO(\"yolo11n-seg.pt\")</p> <p># Export to ONNX format    model.export(format=\"onnx\", task=\"segment\")    ```</p> <ol> <li><code>export_onnx_to_obb.py</code> (created):    ```python    from ultralytics import YOLO</li> </ol> <p># Load the YOLOv11 OBB model    model = YOLO(\"yolo11n-obb.pt\")</p> <p># Export to ONNX format    model.export(format=\"onnx\", task=\"obb\")    ```</p> <ol> <li><code>export_onnx_to_pose.py</code> (created):    ```python    from ultralytics import YOLO</li> </ol> <p># Load the YOLOv11 pose model    model = YOLO(\"yolo11n-pose.pt\")</p> <p># Export to ONNX format    model.export(format=\"onnx\", task=\"pose\")    ```</p> <ol> <li><code>yolos_quantization.py</code> (modified):    ```python    from onnxruntime.quantization import quantize_dynamic, QuantType    from pathlib import Path    from typing import Union</li> </ol> <p>def quantize_onnx_model(onnx_model_path: Union[str, Path], quantized_model_path: Union[str, Path], per_channel: bool = False):        \"\"\"        Quantizes an ONNX model and saves the quantized version.</p> <pre><code>   Args:\n       onnx_model_path: Path to the original ONNX model file.\n       quantized_model_path: Path to save the quantized model.\n       per_channel: If True, quantizes weights per channel instead of per layer.\n           Per-channel quantization can improve model accuracy by allowing each output channel\n           to have its own scale and zero-point, which better captures the distribution of weights.\n           This is especially beneficial for complex models with many channels or varying value ranges.\n           Use this option when:\n           - The model is complex (e.g., deep convolutional networks).\n           - You observe accuracy degradation with per-layer quantization.\n   \"\"\"\n   # Quantize the model\n   quantize_dynamic(\n       model_input=onnx_model_path,\n       model_output=quantized_model_path,\n       per_channel=per_channel,\n       weight_type=QuantType.QUInt8\n   )\n\n   print(\"Quantization completed. Quantized model saved to:\", quantized_model_path)\n</code></pre> <p>if name == \"main\":        # Load the original ONNX model file path        onnx_model_path = 'C:/Users/DELL/source/repos/YOLOs-CPP/models/yolo11n.onnx'        # Specify the output path for the quantized model        quantized_model_path = 'C:/Users/DELL/source/repos/YOLOs-CPP/models/yolo11n_uint8.onnx'        # Call the quantization function        quantize_onnx_model(onnx_model_path, quantized_model_path, per_channel=True)    ```</p> <p>6- <code>CMakeLists.txt</code> (modified):    ```txt    cmake_minimum_required(VERSION 3.0.0)    project(yolo_ort)</p> <p>option(ONNXRUNTIME_DIR \"Path to built ONNX Runtime directory.\" STRING)    message(STATUS \"ONNXRUNTIME_DIR: ${ONNXRUNTIME_DIR}\")</p> <p>find_package(OpenCV REQUIRED)</p> <p>include_directories(\"include/\")</p> <p># Add executable for image inference    add_executable(image_inference                   src/image_inference.cpp)</p> <p># Add executable for camera inference    add_executable(camera_inference                   src/camera_inference.cpp)</p> <p># Add executable for video inference    add_executable(video_inference                   src/video_inference.cpp)</p> <p>set(CMAKE_CXX_STANDARD 17)    set(CMAKE_CXX_STANDARD_REQUIRED ON)</p> <p># Set include directories for all executables    target_include_directories(image_inference PRIVATE \"${ONNXRUNTIME_DIR}/include\")    target_include_directories(camera_inference PRIVATE \"${ONNXRUNTIME_DIR}/include\")    target_include_directories(video_inference PRIVATE \"${ONNXRUNTIME_DIR}/include\")</p> <p># Set compile features for all executables    target_compile_features(image_inference PRIVATE cxx_std_17)    target_compile_features(camera_inference PRIVATE cxx_std_17)    target_compile_features(video_inference PRIVATE cxx_std_17)</p> <p># Link libraries for all executables     #### Replace ${OpenCV_LIBS} with opencv_world    target_link_libraries(image_inference opencv_world)    target_link_libraries(camera_inference opencv_world)    target_link_libraries(video_inference opencv_world)</p> <p>if(UNIX)        message(STATUS \"We are building on Linux!\")        # Specific Linux build commands or flags        target_link_libraries(image_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.so\")        target_link_libraries(camera_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.so\")        target_link_libraries(video_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.so\")    endif(UNIX)</p> <p>if(APPLE)        message(STATUS \"We are building on macOS!\")        # Specific macOS build commands or flags        target_link_libraries(image_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.dylib\")        target_link_libraries(camera_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.dylib\")        target_link_libraries(video_inference \"${ONNXRUNTIME_DIR}/lib/libonnxruntime.dylib\")    endif(APPLE)</p> <p>if(WIN32)        message(STATUS \"We are building on Windows!\")        # Specific Windows build commands or flags        target_link_libraries(image_inference \"${ONNXRUNTIME_DIR}/lib/onnxruntime.lib\")        target_link_libraries(camera_inference \"${ONNXRUNTIME_DIR}/lib/onnxruntime.lib\")        target_link_libraries(video_inference \"${ONNXRUNTIME_DIR}/lib/onnxruntime.lib\")    endif(WIN32) ```</p>"},{"location":"YOLOs-CPP_on_Windows_11/#modifications-made","title":"Modifications Made","text":"<p>The project owner made the following changes: - Modified <code>yolos_quantization.py</code> to support <code>yolo11n.onnx</code> and generate <code>yolo11n_uint8.onnx</code>. - Modified <code>export_onnx.py</code> to export <code>yolo11n.pt</code> to <code>yolo11n.onnx</code>. - Created <code>export_onnx_to_segment.py</code>, <code>export_onnx_to_obb.py</code>, and <code>export_onnx_to_pose.py</code> to export segmentation, OBB, and pose models. - Modified <code>camera_inference.cpp</code>, <code>image_inference.cpp</code>, and <code>video_inference.cpp</code> to support:   - Quantized model (<code>yolo11n_uint8.onnx</code>) with <code>YOLO11Detector</code>.   - Segmentation (<code>yolo11n-seg.onnx</code>) with <code>YOLO11SegDetector</code> and <code>drawSegmentations</code>.   - OBB (<code>yolo11n-obb.onnx</code>) with <code>YOLO11OBBDetector</code> and <code>Dota.names</code>.   - Pose (<code>yolo11n-pose.onnx</code>) with <code>YOLO11POSEDetector</code> and keypoints/skeletons drawing. - Updated paths in all <code>.cpp</code> files to use absolute paths (e.g., <code>C:/Users/DELL/source/repos/YOLOs-CPP/models</code>). - Set <code>isGPU = false</code> for CPU processing. - Added file existence checks using <code>fs::exists</code>. - Added detailed logging for detection time and details. - Added saving of outputs (PNG frames for camera, images for image inference, videos for video inference). - Tested all models and confirmed successful results with bounding boxes, masks, oriented boxes, and keypoints/skeletons.</p>"},{"location":"YOLOs-CPP_on_Windows_11/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Model file does not exist:</li> <li>Verify that <code>yolo11n_uint8.onnx</code>, <code>yolo11n-seg.onnx</code>, <code>yolo11n-obb.onnx</code>, and <code>yolo11n-pose.onnx</code> are in <code>C:/Users/DELL/source/repos/YOLOs-CPP/models</code>.</li> <li>Run the export scripts (<code>export_onnx.py</code>, <code>export_onnx_to_segment.py</code>, etc.) to generate missing models.</li> <li>Labels file does not exist:</li> <li>Ensure <code>coco.names</code> (for detection, segmentation, pose) and <code>Dota.names</code> (for OBB) are in <code>C:/Users/DELL/source/repos/YOLOs-CPP/quantized_models</code>.</li> <li>Could not open video/image:</li> <li>Check that <code>dog.jpg</code>, <code>person.jpg</code>, <code>test.mp4</code>, and <code>test_pose.mp4</code> are in <code>C:/Users/DELL/source/repos/YOLOs-CPP/data</code>.</li> <li>No poses detected:</li> <li>Use inputs with persons (e.g., <code>person.jpg</code>, <code>test_pose.mp4</code>) for pose estimation.</li> <li>DLL errors:</li> <li>Ensure all DLLs (<code>opencv_*.dll</code>, <code>onnxruntime*.dll</code>) are in <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release</code>.</li> <li>Verify that <code>C:\\opencv\\build\\x64\\vc16\\bin</code> and <code>C:\\onnxruntime\\lib</code> are in the system PATH.</li> <li>CMake errors:</li> <li>Ensure <code>OpenCV_DIR</code> and <code>ONNXRUNTIME_DIR</code> are correctly set in the CMake command.</li> <li>If <code>std::filesystem</code> errors occur, update <code>CMakeLists.txt</code> to use C++17 (see Building the Project).</li> <li>Add include directories in <code>CMakeLists.txt</code> for segmentation, OBB, and pose:     <code>cmake     include_directories(${CMAKE_SOURCE_DIR}/seg)     include_directories(${CMAKE_SOURCE_DIR}/obb)     include_directories(${CMAKE_SOURCE_DIR}/pose)</code></li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#notes","title":"Notes","text":"<ul> <li>All models were tested on CPU (<code>isGPU = false</code>) for compatibility. Enable GPU by setting <code>isGPU = true</code> if supported hardware is available (include <code>onnxruntime_providers_cuda.dll</code> and <code>onnxruntime_providers_tensorrt.dll</code>).</li> <li>Quantized models (<code>yolo11n_uint8.onnx</code>) provide faster inference with minimal accuracy loss.</li> <li>OBB requires <code>Dota.names</code> for correct class labeling.</li> <li>Pose estimation requires inputs with persons to detect keypoints and skeletons.</li> <li>Outputs are saved as:</li> <li>Images: <code>output_&lt;filename&gt;.jpg</code> (e.g., <code>output_dog.jpg</code>, <code>output_pose.jpg</code>).</li> <li>Videos: <code>output_video.mp4</code>, <code>output_video_obb.mp4</code>, <code>output_video_pose.mp4</code>.</li> <li>Camera frames: PNGs in <code>output_frames</code>, <code>output_frames_obb</code>, or <code>output_frames_pose</code>.</li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#if-you-encounter-errors-related-to-stdfilesystem-requiring-c17","title":"If you encounter errors related to <code>std::filesystem</code> (requiring C++17):","text":"<ul> <li>Open <code>CMakeLists.txt</code> in the project root (<code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP</code>).</li> <li>Replace like in \"CMakeLists.txt (modified)\":</li> <li>Save the file.</li> <li>Delete the <code>build</code> directory and recreate it:     <code>powershell     cd C:\\Users\\DELL\\source\\repos\\YOLOs-CPP     Remove-Item -Recurse -Force build     mkdir build     cd build     cmake .. -G \"Visual Studio 17 2022\" -A x64 -DOpenCV_DIR=\"C:/opencv/build\" -DONNXRUNTIME_DIR=\"C:/onnxruntime\"</code> </li> </ul>"},{"location":"YOLOs-CPP_on_Windows_11/#if-there-error-in-path","title":"if there error in path","text":"<ul> <li>Copy DLLs to <code>build\\Release</code>:</li> <li>From <code>C:\\opencv\\build\\x64\\vc16\\bin</code>:<ul> <li><code>opencv_videoio_ffmpeg460_64.dll</code></li> <li><code>opencv_videoio_msmf460_64.dll</code></li> <li><code>opencv_world460.dll</code></li> </ul> </li> <li>From <code>C:\\onnxruntime\\lib</code>:<ul> <li><code>onnxruntime.dll</code></li> <li><code>onnxruntime_providers_shared.dll</code></li> <li><code>onnxruntime_providers_cuda.dll</code> (if using GPU)</li> <li><code>onnxruntime_providers_tensorrt.dll</code> (if using GPU)</li> </ul> </li> <li>Paste all DLLs into <code>C:\\Users\\DELL\\source\\repos\\YOLOs-CPP\\build\\Release</code>.</li> </ul>"},{"location":"acknowledgments/","title":"Acknowledgments","text":"<p>YOLOs-CPP is built on the foundation of outstanding open-source projects.</p>"},{"location":"acknowledgments/#core-dependencies","title":"Core Dependencies","text":"Project Purpose License Ultralytics YOLO models &amp; training AGPL-3.0 ONNX Runtime High-performance inference MIT OpenCV Computer vision primitives Apache-2.0"},{"location":"acknowledgments/#inspiration","title":"Inspiration","text":"<p>This project was inspired by and builds upon work from:</p> <ul> <li>itsnine/yolov5-onnxruntime</li> <li>WongKinYiu/yolov7</li> <li>Li-99/yolov8_onnxruntime</li> </ul>"},{"location":"acknowledgments/#contributors","title":"Contributors","text":"<p>Thanks to everyone who has contributed to YOLOs-CPP:</p> <p> </p>"},{"location":"acknowledgments/#special-thanks","title":"Special Thanks","text":"<ul> <li>The Ultralytics team for their continuous improvements to YOLO</li> <li>Microsoft for the ONNX Runtime project</li> <li>The OpenCV community for their computer vision library</li> <li>All our users and contributors</li> </ul> <p>If you'd like to contribute, see our Contributing Guide.</p>"},{"location":"contributing/","title":"Contributing to YOLOs-CPP","text":"<p>Thank you for your interest in contributing! This guide will help you get started.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Bug reports \u2014 Found an issue? Open a GitHub issue</li> <li>Feature requests \u2014 Have an idea? Let's discuss it</li> <li>Code contributions \u2014 Fix bugs or add features</li> <li>Documentation \u2014 Improve docs, add examples</li> <li>Testing \u2014 Add test cases, improve coverage</li> </ul>"},{"location":"contributing/#development-setup","title":"Development Setup","text":""},{"location":"contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code>git clone https://github.com/YOUR_USERNAME/YOLOs-CPP.git\ncd YOLOs-CPP\n</code></pre>"},{"location":"contributing/#2-create-a-branch","title":"2. Create a Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/issue-description\n</code></pre>"},{"location":"contributing/#3-build-and-test","title":"3. Build and Test","text":"<pre><code># Build\n./build.sh 1.20.1 0\n\n# Run tests\ncd tests &amp;&amp; ./test_all.sh\n</code></pre>"},{"location":"contributing/#code-guidelines","title":"Code Guidelines","text":""},{"location":"contributing/#style","title":"Style","text":"<ul> <li>C++17 standard</li> <li>4 spaces for indentation (no tabs)</li> <li>snake_case for variables and functions</li> <li>PascalCase for classes and types</li> <li>Max line length: 100 characters</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Document public APIs with <code>///</code> comments</li> <li>Include <code>@brief</code>, <code>@param</code>, <code>@return</code> for functions</li> <li>Add code examples where helpful</li> </ul>"},{"location":"contributing/#example","title":"Example","text":"<pre><code>/// @brief Detect objects in an image\n/// @param image Input image (BGR format)\n/// @param confThreshold Confidence threshold [0, 1]\n/// @param iouThreshold IoU threshold for NMS [0, 1]\n/// @return Vector of detections\n[[nodiscard]] std::vector&lt;Detection&gt; detect(\n    const cv::Mat&amp; image,\n    float confThreshold = 0.25f,\n    float iouThreshold = 0.45f\n);\n</code></pre>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Use conventional commits:</p> <pre><code>feat: add YOLO-World support\nfix: correct NMS threshold handling\ndocs: update installation guide\ntest: add segmentation edge cases\nrefactor: simplify preprocessing pipeline\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#1-before-submitting","title":"1. Before Submitting","text":"<ul> <li>[ ] Code compiles without warnings</li> <li>[ ] All tests pass (<code>./test_all.sh</code>)</li> <li>[ ] New code has tests</li> <li>[ ] Documentation is updated</li> </ul>"},{"location":"contributing/#2-submit-pr","title":"2. Submit PR","text":"<ul> <li>Open PR against <code>main</code> branch</li> <li>Fill out the PR template</li> <li>Link related issues</li> </ul>"},{"location":"contributing/#3-review-process","title":"3. Review Process","text":"<ul> <li>Maintainers will review within 3-5 days</li> <li>Address feedback promptly</li> <li>Once approved, we'll merge</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":""},{"location":"contributing/#run-all-tests","title":"Run All Tests","text":"<pre><code>cd tests\n./test_all.sh\n</code></pre>"},{"location":"contributing/#run-specific-tests","title":"Run Specific Tests","text":"<pre><code>./test_detection.sh\n./test_segmentation.sh\n./test_pose.sh\n./test_obb.sh\n./test_classification.sh\n</code></pre>"},{"location":"contributing/#add-new-tests","title":"Add New Tests","text":"<ol> <li>Add model to <code>tests/&lt;task&gt;/models/</code></li> <li>Update inference script</li> <li>Add comparison cases</li> </ol>"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":""},{"location":"contributing/#bug-reports","title":"Bug Reports","text":"<p>Include: - YOLOs-CPP version - OS and compiler version - ONNX Runtime version - Minimal reproduction steps - Error messages / logs</p>"},{"location":"contributing/#feature-requests","title":"Feature Requests","text":"<p>Include: - Use case description - Expected behavior - Any relevant examples</p>"},{"location":"contributing/#community","title":"Community","text":"<ul> <li>GitHub Issues \u2014 Bug reports, feature requests</li> <li>GitHub Discussions \u2014 Questions, ideas</li> <li>Pull Requests \u2014 Code contributions</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under AGPL-3.0.</p> <p>Thank you for helping make YOLOs-CPP better!</p>"},{"location":"api/api/","title":"API Reference","text":"<p>This section provides a detailed API reference for YOLOs-CPP, generated from the source code comments using Doxygen.</p>"},{"location":"api/api/#object-detection","title":"Object Detection","text":""},{"location":"api/api/#yolodetector","title":"YOLODetector","text":"<p>The main class for running YOLO object detection.</p>"},{"location":"api/api/#class-yolosdetyolodetector","title":"Class yolos::det::YOLODetector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLODetector</p> <p>Base YOLO detector with runtime version auto-detection. </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p> <p>Inherited by the following classes: yolos::det::YOLO26Detector,  yolos::det::YOLONASDetector,  yolos::det::YOLOv10Detector,  yolos::det::YOLOv11Detector,  yolos::det::YOLOv7Detector,  yolos::det::YOLOv8Detector</p>"},{"location":"api/api/#public-functions","title":"Public Functions","text":"Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"api/api/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"api/api/#protected-attributes","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"api/api/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"api/api/#protected-functions","title":"Protected Functions","text":"Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"api/api/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"api/api/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"api/api/#function-yolodetector","title":"function YOLODetector","text":"<p>Constructor. </p> <pre><code>inline yolos::det::YOLODetector::YOLODetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false,\n    YOLOVersion version=YOLOVersion::Auto\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> <li><code>version</code> YOLO version (Auto for runtime detection) </li> </ul>"},{"location":"api/api/#function-detect","title":"function detect","text":"<p>Run detection on an image (optimized with buffer reuse) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.45f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of detections </p>"},{"location":"api/api/#function-drawdetections","title":"function drawDetections","text":"<p>Draw detections on an image. </p> <pre><code>inline void yolos::det::YOLODetector::drawDetections (\n    cv::Mat &amp; image,\n    const std::vector&lt; Detection &gt; &amp; detections\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>detections</code> Vector of detections </li> </ul>"},{"location":"api/api/#function-drawdetectionswithmask","title":"function drawDetectionsWithMask","text":"<p>Draw detections with semi-transparent mask fill. </p> <pre><code>inline void yolos::det::YOLODetector::drawDetectionsWithMask (\n    cv::Mat &amp; image,\n    const std::vector&lt; Detection &gt; &amp; detections,\n    float alpha=0.4f\n) const\n</code></pre>"},{"location":"api/api/#function-getclasscolors","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::det::YOLODetector::getClassColors () const\n</code></pre>"},{"location":"api/api/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::det::YOLODetector::getClassNames () const\n</code></pre>"},{"location":"api/api/#function-yolodetector_1","title":"function ~YOLODetector","text":"<pre><code>virtual yolos::det::YOLODetector::~YOLODetector () = default\n</code></pre>"},{"location":"api/api/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"api/api/#variable-buffer_","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::det::YOLODetector::buffer_;\n</code></pre>"},{"location":"api/api/#variable-classcolors_","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::det::YOLODetector::classColors_;\n</code></pre>"},{"location":"api/api/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::det::YOLODetector::classNames_;\n</code></pre>"},{"location":"api/api/#variable-version_","title":"variable version_","text":"<pre><code>YOLOVersion yolos::det::YOLODetector::version_;\n</code></pre>"},{"location":"api/api/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"api/api/#function-detectversion","title":"function detectVersion","text":"<p>Detect YOLO version from output tensors. </p> <pre><code>inline YOLOVersion yolos::det::YOLODetector::detectVersion (\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors\n) \n</code></pre>"},{"location":"api/api/#function-postprocess","title":"function postprocess","text":"<p>Postprocess based on detected version. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    YOLOVersion version,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessnas","title":"function postprocessNAS","text":"<p>Postprocess for YOLO-NAS format (two outputs: boxes and scores) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessNAS (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessstandard","title":"function postprocessStandard","text":"<p>Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessStandard (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv10","title":"function postprocessV10","text":"<p>Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessV10 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv7","title":"function postprocessV7","text":"<p>Postprocess for YOLOv7 format [batch, boxes, features]. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessV7 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"api/api/#instance-segmentation","title":"Instance Segmentation","text":""},{"location":"api/api/#yolosegdetector","title":"YOLOSegDetector","text":"<p>Class for running instance segmentation.</p>"},{"location":"api/api/#class-yolossegyolosegdetector","title":"Class yolos::seg::YOLOSegDetector","text":"<p>ClassList &gt; yolos &gt; seg &gt; YOLOSegDetector</p> <p>YOLO segmentation detector with mask prediction. </p> <ul> <li><code>#include &lt;segmentation.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"api/api/#public-functions_1","title":"Public Functions","text":"Type Name YOLOSegDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false) Constructor. void drawMasksOnly (cv::Mat &amp; image, const std::vector&lt; Segmentation &gt; &amp; results, float maskAlpha=0.5f) constDraw only segmentation masks (no boxes) void drawSegmentations (cv::Mat &amp; image, const std::vector&lt; Segmentation &gt; &amp; results, float maskAlpha=0.5f) constDraw segmentations with boxes and labels on an image. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. std::vector&lt; Segmentation &gt; segment (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run segmentation on an image (optimized with buffer reuse) virtual ~YOLOSegDetector () = default"},{"location":"api/api/#public-functions-inherited-from-yolosortsessionbase_1","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"api/api/#protected-attributes_1","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"api/api/#protected-attributes-inherited-from-yolosortsessionbase_1","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"api/api/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name constexpr float MASK_THRESHOLD   = <code>0.5f</code>"},{"location":"api/api/#protected-functions_1","title":"Protected Functions","text":"Type Name std::vector&lt; Segmentation &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; letterboxSize, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess segmentation outputs. std::vector&lt; Segmentation &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; letterboxSize, const float * output0, const float * output1, const std::vector&lt; int64_t &gt; &amp; shape0, const std::vector&lt; int64_t &gt; &amp; shape1, float confThreshold) Postprocess YOLO26-seg format outputs (end-to-end, no NMS needed) Output0 shape: [1, num_detections, 38] where 38 = 4 (x1,y1,x2,y2) + 1 (conf) + 1 (class_id) + 32 (mask_coeffs)"},{"location":"api/api/#protected-functions-inherited-from-yolosortsessionbase_1","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"api/api/#public-functions-documentation_1","title":"Public Functions Documentation","text":""},{"location":"api/api/#function-yolosegdetector","title":"function YOLOSegDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::seg::YOLOSegDetector::YOLOSegDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"api/api/#function-drawmasksonly","title":"function drawMasksOnly","text":"<p>Draw only segmentation masks (no boxes) </p> <pre><code>inline void yolos::seg::YOLOSegDetector::drawMasksOnly (\n    cv::Mat &amp; image,\n    const std::vector&lt; Segmentation &gt; &amp; results,\n    float maskAlpha=0.5f\n) const\n</code></pre>"},{"location":"api/api/#function-drawsegmentations","title":"function drawSegmentations","text":"<p>Draw segmentations with boxes and labels on an image. </p> <pre><code>inline void yolos::seg::YOLOSegDetector::drawSegmentations (\n    cv::Mat &amp; image,\n    const std::vector&lt; Segmentation &gt; &amp; results,\n    float maskAlpha=0.5f\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of segmentation results </li> <li><code>maskAlpha</code> Mask transparency (0-1) </li> </ul>"},{"location":"api/api/#function-getclasscolors_1","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::seg::YOLOSegDetector::getClassColors () const\n</code></pre>"},{"location":"api/api/#function-getclassnames_1","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::seg::YOLOSegDetector::getClassNames () const\n</code></pre>"},{"location":"api/api/#function-segment","title":"function segment","text":"<p>Run segmentation on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::segment (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.45f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of segmentation results </p>"},{"location":"api/api/#function-yolosegdetector_1","title":"function ~YOLOSegDetector","text":"<pre><code>virtual yolos::seg::YOLOSegDetector::~YOLOSegDetector () = default\n</code></pre>"},{"location":"api/api/#protected-attributes-documentation_1","title":"Protected Attributes Documentation","text":""},{"location":"api/api/#variable-buffer__1","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::seg::YOLOSegDetector::buffer_;\n</code></pre>"},{"location":"api/api/#variable-classcolors__1","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::seg::YOLOSegDetector::classColors_;\n</code></pre>"},{"location":"api/api/#variable-classnames__1","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::seg::YOLOSegDetector::classNames_;\n</code></pre>"},{"location":"api/api/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"api/api/#variable-mask_threshold","title":"variable MASK_THRESHOLD","text":"<pre><code>constexpr float yolos::seg::YOLOSegDetector::MASK_THRESHOLD;\n</code></pre>"},{"location":"api/api/#protected-functions-documentation_1","title":"Protected Functions Documentation","text":""},{"location":"api/api/#function-postprocess_1","title":"function postprocess","text":"<p>Postprocess segmentation outputs. </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; letterboxSize,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv26","title":"function postprocessV26","text":"<p>Postprocess YOLO26-seg format outputs (end-to-end, no NMS needed) Output0 shape: [1, num_detections, 38] where 38 = 4 (x1,y1,x2,y2) + 1 (conf) + 1 (class_id) + 32 (mask_coeffs) </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; letterboxSize,\n    const float * output0,\n    const float * output1,\n    const std::vector&lt; int64_t &gt; &amp; shape0,\n    const std::vector&lt; int64_t &gt; &amp; shape1,\n    float confThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/segmentation.hpp</code></p>"},{"location":"api/api/#pose-estimation","title":"Pose Estimation","text":""},{"location":"api/api/#yoloposedetector","title":"YOLOPoseDetector","text":"<p>Class for running pose estimation.</p>"},{"location":"api/api/#class-yolosposeyoloposedetector","title":"Class yolos::pose::YOLOPoseDetector","text":"<p>ClassList &gt; yolos &gt; pose &gt; YOLOPoseDetector</p> <p>YOLO pose estimation detector with keypoint detection. </p> <ul> <li><code>#include &lt;pose.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"api/api/#public-functions_2","title":"Public Functions","text":"Type Name YOLOPoseDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath=\"\", bool useGPU=false) Constructor. std::vector&lt; PoseResult &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.5f) Run pose detection on an image (optimized with buffer reuse) void drawPoses (cv::Mat &amp; image, const std::vector&lt; PoseResult &gt; &amp; results, int kptRadius=4, float kptThreshold=0.5f, int lineThickness=2) constDraw pose estimations on an image. void drawSkeletonsOnly (cv::Mat &amp; image, const std::vector&lt; PoseResult &gt; &amp; results, int kptRadius=4, float kptThreshold=0.5f, int lineThickness=2) constDraw only skeletons (no bounding boxes) const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLOPoseDetector () = default"},{"location":"api/api/#public-functions-inherited-from-yolosortsessionbase_2","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"api/api/#public-static-functions","title":"Public Static Functions","text":"Type Name const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; getPoseSkeleton () Get COCO pose skeleton connections."},{"location":"api/api/#protected-attributes_2","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"api/api/#protected-attributes-inherited-from-yolosortsessionbase_2","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"api/api/#protected-static-attributes_1","title":"Protected Static Attributes","text":"Type Name constexpr int FEATURES_PER_KEYPOINT   = <code>3</code> constexpr int NUM_KEYPOINTS   = <code>17</code>"},{"location":"api/api/#protected-functions_2","title":"Protected Functions","text":"Type Name std::vector&lt; PoseResult &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess pose detection outputs. std::vector&lt; PoseResult &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold) Postprocess YOLO26 pose detection outputs (end-to-end, NMS-free) std::vector&lt; PoseResult &gt; postprocessV8 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, float iouThreshold) Postprocess YOLOv8/v11 pose detection outputs (requires NMS)"},{"location":"api/api/#protected-functions-inherited-from-yolosortsessionbase_2","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"api/api/#public-functions-documentation_2","title":"Public Functions Documentation","text":""},{"location":"api/api/#function-yoloposedetector","title":"function YOLOPoseDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::pose::YOLOPoseDetector::YOLOPoseDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath=\"\",\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file (optional for pose) </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"api/api/#function-detect_1","title":"function detect","text":"<p>Run pose detection on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.5f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of pose results </p>"},{"location":"api/api/#function-drawposes","title":"function drawPoses","text":"<p>Draw pose estimations on an image. </p> <pre><code>inline void yolos::pose::YOLOPoseDetector::drawPoses (\n    cv::Mat &amp; image,\n    const std::vector&lt; PoseResult &gt; &amp; results,\n    int kptRadius=4,\n    float kptThreshold=0.5f,\n    int lineThickness=2\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of pose results </li> <li><code>kptRadius</code> Keypoint circle radius </li> <li><code>kptThreshold</code> Minimum confidence to draw keypoint </li> <li><code>lineThickness</code> Skeleton line thickness </li> </ul>"},{"location":"api/api/#function-drawskeletonsonly","title":"function drawSkeletonsOnly","text":"<p>Draw only skeletons (no bounding boxes) </p> <pre><code>inline void yolos::pose::YOLOPoseDetector::drawSkeletonsOnly (\n    cv::Mat &amp; image,\n    const std::vector&lt; PoseResult &gt; &amp; results,\n    int kptRadius=4,\n    float kptThreshold=0.5f,\n    int lineThickness=2\n) const\n</code></pre>"},{"location":"api/api/#function-getclassnames_2","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::pose::YOLOPoseDetector::getClassNames () const\n</code></pre>"},{"location":"api/api/#function-yoloposedetector_1","title":"function ~YOLOPoseDetector","text":"<pre><code>virtual yolos::pose::YOLOPoseDetector::~YOLOPoseDetector () = default\n</code></pre>"},{"location":"api/api/#public-static-functions-documentation","title":"Public Static Functions Documentation","text":""},{"location":"api/api/#function-getposeskeleton","title":"function getPoseSkeleton","text":"<p>Get COCO pose skeleton connections. </p> <pre><code>static inline const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; yolos::pose::YOLOPoseDetector::getPoseSkeleton () \n</code></pre>"},{"location":"api/api/#protected-attributes-documentation_2","title":"Protected Attributes Documentation","text":""},{"location":"api/api/#variable-buffer__2","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::pose::YOLOPoseDetector::buffer_;\n</code></pre>"},{"location":"api/api/#variable-classcolors__2","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::pose::YOLOPoseDetector::classColors_;\n</code></pre>"},{"location":"api/api/#variable-classnames__2","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::pose::YOLOPoseDetector::classNames_;\n</code></pre>"},{"location":"api/api/#protected-static-attributes-documentation_1","title":"Protected Static Attributes Documentation","text":""},{"location":"api/api/#variable-features_per_keypoint","title":"variable FEATURES_PER_KEYPOINT","text":"<pre><code>constexpr int yolos::pose::YOLOPoseDetector::FEATURES_PER_KEYPOINT;\n</code></pre>"},{"location":"api/api/#variable-num_keypoints","title":"variable NUM_KEYPOINTS","text":"<pre><code>constexpr int yolos::pose::YOLOPoseDetector::NUM_KEYPOINTS;\n</code></pre>"},{"location":"api/api/#protected-functions-documentation_2","title":"Protected Functions Documentation","text":""},{"location":"api/api/#function-postprocess_2","title":"function postprocess","text":"<p>Postprocess pose detection outputs. </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv26_1","title":"function postprocessV26","text":"<p>Postprocess YOLO26 pose detection outputs (end-to-end, NMS-free) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv8","title":"function postprocessV8","text":"<p>Postprocess YOLOv8/v11 pose detection outputs (requires NMS) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocessV8 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/pose.hpp</code></p>"},{"location":"api/api/#oriented-bounding-boxes-obb","title":"Oriented Bounding Boxes (OBB)","text":""},{"location":"api/api/#yoloobbdetector","title":"YOLOOBBDetector","text":"<p>Class for running detection with oriented bounding boxes.</p>"},{"location":"api/api/#class-yolosobbyoloobbdetector","title":"Class yolos::obb::YOLOOBBDetector","text":"<p>ClassList &gt; yolos &gt; obb &gt; YOLOOBBDetector</p> <p>YOLO oriented bounding box detector for rotated object detection. </p> <ul> <li><code>#include &lt;obb.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"api/api/#public-functions_3","title":"Public Functions","text":"Type Name YOLOOBBDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false) Constructor. std::vector&lt; OBBResult &gt; detect (const cv::Mat &amp; image, float confThreshold=0.25f, float iouThreshold=0.45f, int maxDet=300) Run OBB detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; OBBResult &gt; &amp; results, int thickness=2) constDraw OBB detections on an image. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLOOBBDetector () = default"},{"location":"api/api/#public-functions-inherited-from-yolosortsessionbase_3","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"api/api/#protected-attributes_3","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"api/api/#protected-attributes-inherited-from-yolosortsessionbase_3","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"api/api/#protected-functions_3","title":"Protected Functions","text":"Type Name std::vector&lt; OBBResult &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold, int maxDet) Postprocess OBB detection outputs. std::vector&lt; OBBResult &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, int maxDet) Postprocess YOLO26 OBB detection outputs (end-to-end, NMS-free) std::vector&lt; OBBResult &gt; postprocessV8 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, float iouThreshold, int maxDet) Postprocess YOLOv8/v11 OBB detection outputs (requires NMS)"},{"location":"api/api/#protected-functions-inherited-from-yolosortsessionbase_3","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"api/api/#public-functions-documentation_3","title":"Public Functions Documentation","text":""},{"location":"api/api/#function-yoloobbdetector","title":"function YOLOOBBDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::obb::YOLOOBBDetector::YOLOOBBDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"api/api/#function-detect_2","title":"function detect","text":"<p>Run OBB detection on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.25f,\n    float iouThreshold=0.45f,\n    int maxDet=300\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> <li><code>maxDet</code> Maximum number of detections to return </li> </ul> <p>Returns:</p> <p>Vector of OBB detection results </p>"},{"location":"api/api/#function-drawdetections_1","title":"function drawDetections","text":"<p>Draw OBB detections on an image. </p> <pre><code>inline void yolos::obb::YOLOOBBDetector::drawDetections (\n    cv::Mat &amp; image,\n    const std::vector&lt; OBBResult &gt; &amp; results,\n    int thickness=2\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of OBB detection results </li> <li><code>thickness</code> Line thickness </li> </ul>"},{"location":"api/api/#function-getclasscolors_2","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::obb::YOLOOBBDetector::getClassColors () const\n</code></pre>"},{"location":"api/api/#function-getclassnames_3","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::obb::YOLOOBBDetector::getClassNames () const\n</code></pre>"},{"location":"api/api/#function-yoloobbdetector_1","title":"function ~YOLOOBBDetector","text":"<pre><code>virtual yolos::obb::YOLOOBBDetector::~YOLOOBBDetector () = default\n</code></pre>"},{"location":"api/api/#protected-attributes-documentation_3","title":"Protected Attributes Documentation","text":""},{"location":"api/api/#variable-buffer__3","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::obb::YOLOOBBDetector::buffer_;\n</code></pre>"},{"location":"api/api/#variable-classcolors__3","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::obb::YOLOOBBDetector::classColors_;\n</code></pre>"},{"location":"api/api/#variable-classnames__3","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::obb::YOLOOBBDetector::classNames_;\n</code></pre>"},{"location":"api/api/#protected-functions-documentation_3","title":"Protected Functions Documentation","text":""},{"location":"api/api/#function-postprocess_3","title":"function postprocess","text":"<p>Postprocess OBB detection outputs. </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold,\n    int maxDet\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv26_2","title":"function postprocessV26","text":"<p>Postprocess YOLO26 OBB detection outputs (end-to-end, NMS-free) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    int maxDet\n) \n</code></pre>"},{"location":"api/api/#function-postprocessv8_1","title":"function postprocessV8","text":"<p>Postprocess YOLOv8/v11 OBB detection outputs (requires NMS) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocessV8 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    float iouThreshold,\n    int maxDet\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/obb.hpp</code></p>"},{"location":"api/api/#image-classification","title":"Image Classification","text":""},{"location":"api/api/#yoloclassifier","title":"YOLOClassifier","text":"<p>Class for running image classification.</p>"},{"location":"api/api/#class-yolosclsyoloclassifier","title":"Class yolos::cls::YOLOClassifier","text":"<p>ClassList &gt; yolos &gt; cls &gt; YOLOClassifier</p> <p>YOLO classifier for image classification. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: yolos::cls::YOLO11Classifier,  yolos::cls::YOLO12Classifier,  yolos::cls::YOLO26Classifier</p>"},{"location":"api/api/#public-functions_4","title":"Public Functions","text":"Type Name YOLOClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, const cv::Size &amp; targetInputShape=cv::Size(224, 224)) Constructor. ClassificationResult classify (const cv::Mat &amp; image) Run classification on an image. void drawResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30)) constDraw classification result on an image. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. cv::Size getInputShape () constGet input shape. bool isDynamicInputShape () constCheck if input shape is dynamic. virtual ~YOLOClassifier () = default"},{"location":"api/api/#protected-attributes_4","title":"Protected Attributes","text":"Type Name std::vector&lt; std::string &gt; classNames_ Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; float &gt; inputBuffer_ cv::Size inputImageShape_ std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ bool isDynamicInputShape_   = <code>{false}</code> int numClasses_   = <code>{0}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"api/api/#protected-functions_4","title":"Protected Functions","text":"Type Name void initSession (const std::string &amp; modelPath, bool useGPU)  ClassificationResult postprocess (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Postprocess classification output. void preprocess (const cv::Mat &amp; image, std::vector&lt; int64_t &gt; &amp; inputTensorShape) Preprocess image for classification (Ultralytics-style)"},{"location":"api/api/#public-functions-documentation_4","title":"Public Functions Documentation","text":""},{"location":"api/api/#function-yoloclassifier","title":"function YOLOClassifier","text":"<p>Constructor. </p> <pre><code>inline yolos::cls::YOLOClassifier::YOLOClassifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false,\n    const cv::Size &amp; targetInputShape=cv::Size(224, 224)\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> <li><code>targetInputShape</code> Target input shape for preprocessing </li> </ul>"},{"location":"api/api/#function-classify","title":"function classify","text":"<p>Run classification on an image. </p> <pre><code>inline ClassificationResult yolos::cls::YOLOClassifier::classify (\n    const cv::Mat &amp; image\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> </ul> <p>Returns:</p> <p>Classification result </p>"},{"location":"api/api/#function-drawresult","title":"function drawResult","text":"<p>Draw classification result on an image. </p> <pre><code>inline void yolos::cls::YOLOClassifier::drawResult (\n    cv::Mat &amp; image,\n    const ClassificationResult &amp; result,\n    const cv::Point &amp; position=cv::Point(10, 30)\n) const\n</code></pre>"},{"location":"api/api/#function-getclassnames_4","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::cls::YOLOClassifier::getClassNames () const\n</code></pre>"},{"location":"api/api/#function-getinputshape","title":"function getInputShape","text":"<p>Get input shape. </p> <pre><code>inline cv::Size yolos::cls::YOLOClassifier::getInputShape () const\n</code></pre>"},{"location":"api/api/#function-isdynamicinputshape","title":"function isDynamicInputShape","text":"<p>Check if input shape is dynamic. </p> <pre><code>inline bool yolos::cls::YOLOClassifier::isDynamicInputShape () const\n</code></pre>"},{"location":"api/api/#function-yoloclassifier_1","title":"function ~YOLOClassifier","text":"<pre><code>virtual yolos::cls::YOLOClassifier::~YOLOClassifier () = default\n</code></pre>"},{"location":"api/api/#protected-attributes-documentation_4","title":"Protected Attributes Documentation","text":""},{"location":"api/api/#variable-classnames__4","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::cls::YOLOClassifier::classNames_;\n</code></pre>"},{"location":"api/api/#variable-env_","title":"variable env_","text":"<pre><code>Ort::Env yolos::cls::YOLOClassifier::env_;\n</code></pre>"},{"location":"api/api/#variable-inputbuffer_","title":"variable inputBuffer_","text":"<pre><code>std::vector&lt;float&gt; yolos::cls::YOLOClassifier::inputBuffer_;\n</code></pre>"},{"location":"api/api/#variable-inputimageshape_","title":"variable inputImageShape_","text":"<pre><code>cv::Size yolos::cls::YOLOClassifier::inputImageShape_;\n</code></pre>"},{"location":"api/api/#variable-inputnameallocs_","title":"variable inputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::cls::YOLOClassifier::inputNameAllocs_;\n</code></pre>"},{"location":"api/api/#variable-inputnames_","title":"variable inputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::cls::YOLOClassifier::inputNames_;\n</code></pre>"},{"location":"api/api/#variable-isdynamicinputshape_","title":"variable isDynamicInputShape_","text":"<pre><code>bool yolos::cls::YOLOClassifier::isDynamicInputShape_;\n</code></pre>"},{"location":"api/api/#variable-numclasses_","title":"variable numClasses_","text":"<pre><code>int yolos::cls::YOLOClassifier::numClasses_;\n</code></pre>"},{"location":"api/api/#variable-numinputnodes_","title":"variable numInputNodes_","text":"<pre><code>size_t yolos::cls::YOLOClassifier::numInputNodes_;\n</code></pre>"},{"location":"api/api/#variable-numoutputnodes_","title":"variable numOutputNodes_","text":"<pre><code>size_t yolos::cls::YOLOClassifier::numOutputNodes_;\n</code></pre>"},{"location":"api/api/#variable-outputnameallocs_","title":"variable outputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::cls::YOLOClassifier::outputNameAllocs_;\n</code></pre>"},{"location":"api/api/#variable-outputnames_","title":"variable outputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::cls::YOLOClassifier::outputNames_;\n</code></pre>"},{"location":"api/api/#variable-sessionoptions_","title":"variable sessionOptions_","text":"<pre><code>Ort::SessionOptions yolos::cls::YOLOClassifier::sessionOptions_;\n</code></pre>"},{"location":"api/api/#variable-session_","title":"variable session_","text":"<pre><code>Ort::Session yolos::cls::YOLOClassifier::session_;\n</code></pre>"},{"location":"api/api/#protected-functions-documentation_4","title":"Protected Functions Documentation","text":""},{"location":"api/api/#function-initsession","title":"function initSession","text":"<pre><code>inline void yolos::cls::YOLOClassifier::initSession (\n    const std::string &amp; modelPath,\n    bool useGPU\n) \n</code></pre>"},{"location":"api/api/#function-postprocess_4","title":"function postprocess","text":"<p>Postprocess classification output. </p> <pre><code>inline ClassificationResult yolos::cls::YOLOClassifier::postprocess (\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors\n) \n</code></pre>"},{"location":"api/api/#function-preprocess","title":"function preprocess","text":"<p>Preprocess image for classification (Ultralytics-style) </p> <pre><code>inline void yolos::cls::YOLOClassifier::preprocess (\n    const cv::Mat &amp; image,\n    std::vector&lt; int64_t &gt; &amp; inputTensorShape\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"api/api/#core-types","title":"Core Types","text":""},{"location":"api/api/#boundingbox","title":"BoundingBoxMkDoxy Error: Incorrect class configurationMkDoxy Error: Incorrect class configuration","text":"<p>Basic structure for axis-aligned bounding boxes.</p> <p>Did not find Class with name: `yolos::BoundingBox`</p> Available classes: <pre><code>yolos::OrtSessionBase\nyolos::cls::YOLO11Classifier\nyolos::cls::YOLO12Classifier\nyolos::cls::YOLO26Classifier\nyolos::cls::YOLOClassifier\nyolos::det::YOLO26Detector\nyolos::det::YOLODetector\nyolos::det::YOLONASDetector\nyolos::det::YOLOv10Detector\nyolos::det::YOLOv11Detector\nyolos::det::YOLOv7Detector\nyolos::det::YOLOv8Detector\nyolos::obb::YOLOOBBDetector\nyolos::pose::YOLOPoseDetector\nyolos::seg::YOLOSegDetector\n</code></pre> Snippet <pre><code>::: doxy.yolos.Class\n    name: yolos::BoundingBox\n\n</code></pre>        ### Detection Structure containing detection results.    <p>Did not find Class with name: `yolos::det::Detection`</p> Available classes: <pre><code>yolos::OrtSessionBase\nyolos::cls::YOLO11Classifier\nyolos::cls::YOLO12Classifier\nyolos::cls::YOLO26Classifier\nyolos::cls::YOLOClassifier\nyolos::det::YOLO26Detector\nyolos::det::YOLODetector\nyolos::det::YOLONASDetector\nyolos::det::YOLOv10Detector\nyolos::det::YOLOv11Detector\nyolos::det::YOLOv7Detector\nyolos::det::YOLOv8Detector\nyolos::obb::YOLOOBBDetector\nyolos::pose::YOLOPoseDetector\nyolos::seg::YOLOSegDetector\n</code></pre> Snippet <pre><code>::: doxy.yolos.Class\n    name: yolos::det::Detection\n\n</code></pre>"},{"location":"examples/examples/","title":"Usage Guide","text":"<p>Complete API reference and code examples for YOLOs-CPP.</p>"},{"location":"examples/examples/#quick-start","title":"Quick Start","text":"<pre><code>#include \"yolos/yolos.hpp\"\n\n// Initialize any detector\nyolos::det::YOLODetector detector(\"model.onnx\", \"labels.txt\", /*gpu=*/true);\n\n// Run inference\nauto detections = detector.detect(frame, /*conf=*/0.25f, /*iou=*/0.45f);\n\n// Visualize\ndetector.drawDetections(frame, detections);\n</code></pre>"},{"location":"examples/examples/#namespace-structure","title":"Namespace Structure","text":"Namespace Purpose <code>yolos::det::</code> Object detection <code>yolos::seg::</code> Instance segmentation <code>yolos::pose::</code> Pose estimation <code>yolos::obb::</code> Oriented bounding boxes <code>yolos::cls::</code> Image classification"},{"location":"examples/examples/#object-detection","title":"Object Detection","text":"<pre><code>#include \"yolos/yolos.hpp\"\n\nyolos::det::YOLODetector detector(\n    \"models/yolo11n.onnx\",\n    \"models/coco.names\",\n    true  // GPU\n);\n\ncv::Mat image = cv::imread(\"image.jpg\");\nauto detections = detector.detect(image, 0.25f, 0.45f);\n\nfor (const auto&amp; det : detections) {\n    std::cout &lt;&lt; det.className &lt;&lt; \": \" &lt;&lt; det.confidence &lt;&lt; std::endl;\n}\n\ndetector.drawDetections(image, detections);\n</code></pre>"},{"location":"examples/examples/#instance-segmentation","title":"Instance Segmentation","text":"<pre><code>yolos::seg::YOLOSegDetector detector(\n    \"models/yolo11n-seg.onnx\",\n    \"models/coco.names\",\n    true\n);\n\nauto segments = detector.segment(image, 0.25f, 0.45f);\ndetector.drawSegmentations(image, segments, 0.5f);  // 50% opacity\n</code></pre>"},{"location":"examples/examples/#pose-estimation","title":"Pose Estimation","text":"<pre><code>yolos::pose::YOLOPoseDetector detector(\n    \"models/yolo11n-pose.onnx\",\n    \"\",  // No labels needed\n    true\n);\n\nauto poses = detector.detect(image, 0.25f, 0.45f);\ndetector.drawPoses(image, poses);\n</code></pre>"},{"location":"examples/examples/#oriented-bounding-boxes","title":"Oriented Bounding Boxes","text":"<pre><code>yolos::obb::YOLOOBBDetector detector(\n    \"models/yolo11n-obb.onnx\",\n    \"models/Dota.names\",\n    true\n);\n\nauto boxes = detector.detect(image, 0.25f, 0.45f);\ndetector.drawOBBs(image, boxes);\n</code></pre>"},{"location":"examples/examples/#image-classification","title":"Image Classification","text":"<pre><code>yolos::cls::YOLOClassifier classifier(\n    \"models/yolo11n-cls.onnx\",\n    \"models/imagenet_classes.txt\",\n    true\n);\n\nauto result = classifier.classify(image);\nstd::cout &lt;&lt; result.className &lt;&lt; \": \" &lt;&lt; result.confidence * 100 &lt;&lt; \"%\" &lt;&lt; std::endl;\n</code></pre>"},{"location":"examples/examples/#video-processing","title":"Video Processing","text":"<pre><code>cv::VideoCapture cap(\"video.mp4\");\ncv::Mat frame;\n\nwhile (cap.read(frame)) {\n    auto detections = detector.detect(frame);\n    detector.drawDetections(frame, detections);\n    cv::imshow(\"Detection\", frame);\n    if (cv::waitKey(1) == 27) break;\n}\n</code></pre>"},{"location":"examples/examples/#camera-stream","title":"Camera Stream","text":"<pre><code>cv::VideoCapture cap(0);\ncap.set(cv::CAP_PROP_FRAME_WIDTH, 1280);\ncap.set(cv::CAP_PROP_FRAME_HEIGHT, 720);\n\ncv::Mat frame;\nwhile (cap.read(frame)) {\n    auto detections = detector.detect(frame);\n    detector.drawDetections(frame, detections);\n    cv::imshow(\"Live\", frame);\n    if (cv::waitKey(1) == 27) break;\n}\n</code></pre>"},{"location":"examples/examples/#performance-tips","title":"Performance Tips","text":"<ol> <li>Reuse detector instances \u2014 Create once, infer many times</li> <li>Use GPU when available \u2014 5-10x faster than CPU</li> <li>Adjust thresholds \u2014 Higher confidence = fewer detections, faster NMS</li> <li>Match input resolution \u2014 Use model's expected size (640x640)</li> </ol>"},{"location":"examples/examples/#error-handling","title":"Error Handling","text":"<pre><code>try {\n    yolos::det::YOLODetector detector(\"model.onnx\", \"labels.txt\", true);\n} catch (const Ort::Exception&amp; e) {\n    std::cerr &lt;&lt; \"ONNX error: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"examples/examples/#next-steps","title":"Next Steps","text":"<ul> <li>Model Guide \u2014 Export and optimize models</li> <li>Development \u2014 Extend the library</li> </ul>"},{"location":"guides/architecture/","title":"Development Guide","text":"<p>Architecture overview, extending YOLOs-CPP, and debugging.</p>"},{"location":"guides/architecture/#architecture","title":"Architecture","text":"<pre><code>include/yolos/\n\u251c\u2500\u2500 core/                    # Shared utilities\n\u2502   \u251c\u2500\u2500 types.hpp           # Detection, Segmentation types\n\u2502   \u251c\u2500\u2500 preprocessing.hpp   # Letterbox, normalization\n\u2502   \u251c\u2500\u2500 nms.hpp             # Non-maximum suppression\n\u2502   \u251c\u2500\u2500 drawing.hpp         # Visualization\n\u2502   \u251c\u2500\u2500 version.hpp         # YOLO version detection\n\u2502   \u251c\u2500\u2500 utils.hpp           # Helper functions\n\u2502   \u2514\u2500\u2500 session_base.hpp    # ONNX session wrapper\n\u251c\u2500\u2500 tasks/                   # Task implementations\n\u2502   \u251c\u2500\u2500 detection.hpp       # YOLODetector\n\u2502   \u251c\u2500\u2500 segmentation.hpp    # YOLOSegDetector\n\u2502   \u251c\u2500\u2500 pose.hpp            # YOLOPoseDetector\n\u2502   \u251c\u2500\u2500 obb.hpp             # YOLOOBBDetector\n\u2502   \u2514\u2500\u2500 classification.hpp  # YOLOClassifier\n\u2514\u2500\u2500 yolos.hpp               # Master include\n</code></pre>"},{"location":"guides/architecture/#core-components","title":"Core Components","text":""},{"location":"guides/architecture/#preprocessing-preprocessinghpp","title":"Preprocessing (<code>preprocessing.hpp</code>)","text":"<pre><code>// Letterbox with padding\ncv::Mat blob = yolos::preprocessing::letterBoxToBlob(\n    image,\n    cv::Size(640, 640),\n    scalePad  // Returns scale and padding info\n);\n</code></pre>"},{"location":"guides/architecture/#nms-nmshpp","title":"NMS (<code>nms.hpp</code>)","text":"<pre><code>// Class-aware batched NMS\nstd::vector&lt;int&gt; indices;\nyolos::nms::NMSBoxesFBatched(\n    boxes, scores, classIds,\n    confThreshold, iouThreshold,\n    indices\n);\n</code></pre>"},{"location":"guides/architecture/#drawing-drawinghpp","title":"Drawing (<code>drawing.hpp</code>)","text":"<pre><code>yolos::drawing::drawBoundingBox(image, box, label, color);\nyolos::drawing::drawMask(image, mask, color, alpha);\nyolos::drawing::drawKeypoints(image, keypoints);\n</code></pre>"},{"location":"guides/architecture/#adding-a-new-yolo-version","title":"Adding a New YOLO Version","text":""},{"location":"guides/architecture/#step-1-update-version-enum","title":"Step 1: Update Version Enum","text":"<pre><code>// include/yolos/core/version.hpp\nenum class YOLOVersion {\n    V5, V6, V7, V8, V9, V10, V11, V12, V26,\n    VNew  // Add your version\n};\n</code></pre>"},{"location":"guides/architecture/#step-2-implement-postprocessing","title":"Step 2: Implement Postprocessing","text":"<pre><code>// include/yolos/tasks/detection.hpp\nvoid postprocessVNew(/* params */) {\n    // Parse model output\n    // Apply NMS\n    // Return detections\n}\n</code></pre>"},{"location":"guides/architecture/#step-3-update-factory","title":"Step 3: Update Factory","text":"<pre><code>switch (version) {\n    case YOLOVersion::VNew:\n        return postprocessVNew(...);\n    // ...\n}\n</code></pre>"},{"location":"guides/architecture/#step-4-add-tests","title":"Step 4: Add Tests","text":"<pre><code>// tests/detection/compare_results.cpp\n// Add model to test suite\n</code></pre>"},{"location":"guides/architecture/#onnx-runtime-integration","title":"ONNX Runtime Integration","text":""},{"location":"guides/architecture/#session-management","title":"Session Management","text":"<pre><code>Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"YOLOs-CPP\");\nOrt::SessionOptions options;\n\n// CPU optimization\noptions.SetIntraOpNumThreads(4);\noptions.SetGraphOptimizationLevel(ORT_ENABLE_ALL);\n\n// GPU (CUDA)\nOrtCUDAProviderOptions cuda_options{};\noptions.AppendExecutionProvider_CUDA(cuda_options);\n\nOrt::Session session(env, \"model.onnx\", options);\n</code></pre>"},{"location":"guides/architecture/#memory-efficiency","title":"Memory Efficiency","text":"<pre><code>// Pre-allocate buffers\nstd::vector&lt;float&gt; inputBuffer(3 * 640 * 640);\n\n// Create tensor from existing memory\nOrt::Value::CreateTensor&lt;float&gt;(\n    memoryInfo,\n    inputBuffer.data(),\n    inputBuffer.size(),\n    inputShape.data(),\n    inputShape.size()\n);\n</code></pre>"},{"location":"guides/architecture/#debugging","title":"Debugging","text":""},{"location":"guides/architecture/#enable-verbose-output","title":"Enable Verbose Output","text":"<pre><code>Ort::Env env(ORT_LOGGING_LEVEL_VERBOSE, \"Debug\");\n</code></pre>"},{"location":"guides/architecture/#profile-inference","title":"Profile Inference","text":"<pre><code>#include &lt;chrono&gt;\n\nauto start = std::chrono::high_resolution_clock::now();\nauto detections = detector.detect(frame);\nauto end = std::chrono::high_resolution_clock::now();\n\nauto ms = std::chrono::duration&lt;double, std::milli&gt;(end - start).count();\nstd::cout &lt;&lt; \"Inference: \" &lt;&lt; ms &lt;&lt; \" ms\" &lt;&lt; std::endl;\n</code></pre>"},{"location":"guides/architecture/#validate-against-python","title":"Validate Against Python","text":"<pre><code># Run comparison tests\ncd tests\n./test_detection.sh\n</code></pre>"},{"location":"guides/architecture/#code-style","title":"Code Style","text":"<ul> <li>C++17 standard</li> <li>snake_case for variables and functions</li> <li>PascalCase for classes and types</li> <li>UPPER_CASE for constants</li> <li>Use <code>const</code> and <code>[[nodiscard]]</code> where appropriate</li> </ul>"},{"location":"guides/architecture/#building-tests","title":"Building Tests","text":"<pre><code>cd tests\n./build_test.sh 0  # Detection\n./build_test.sh 1  # Classification\n./build_test.sh 2  # Segmentation\n./build_test.sh 3  # Pose\n./build_test.sh 4  # OBB\n</code></pre>"},{"location":"guides/architecture/#benchmarking","title":"Benchmarking","text":"<pre><code>cd benchmarks\n./auto_bench.sh 1.20.1 0 yolo11n,yolov8n\n</code></pre>"},{"location":"guides/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Contributing \u2014 Submit changes</li> <li>Model Guide \u2014 Model compatibility</li> </ul>"},{"location":"guides/benchmarks/","title":"YOLO Detection Models Benchmark Report","text":"<p>Generated: January 17, 2026 Benchmark Version: 2.0.0 Framework: YOLOs-CPP (C++ ONNX Runtime Inference)</p>"},{"location":"guides/benchmarks/#system-specifications","title":"System Specifications","text":"Component Details OS Ubuntu 24.04 LTS (Linux 6.14.0-37-generic) Architecture x86_64 CPU Intel Core i7-1185G7 @ 3.00GHz (11th Gen Tiger Lake) CPU Cores 4 physical cores, 8 threads CPU Frequency 400 MHz - 4800 MHz (Turbo) RAM 38 GB DDR4 GPU Integrated Intel Iris Xe (CPU inference only) Storage NVMe SSD OpenCV 4.6.0 ONNX Runtime 1.20.1 (CPU) Compiler GCC with C++17"},{"location":"guides/benchmarks/#benchmark-configuration","title":"Benchmark Configuration","text":"Parameter Value Input Image dog_bike_car.jpg (768\u00d7576 pixels) Model Input Size 320\u00d7320 Precision FP32 Warmup Iterations 20 Benchmark Iterations 100 Confidence Threshold 0.25 NMS Threshold 0.45 Device CPU Dataset Pascal VOC (20 classes)"},{"location":"guides/benchmarks/#performance-results-summary","title":"Performance Results Summary","text":""},{"location":"guides/benchmarks/#fps-comparison-higher-is-better","title":"FPS Comparison (Higher is Better)","text":"Model FPS Rank YOLOv11n 97.18 \ud83e\udd47 1st YOLOv8n 85.55 \ud83e\udd48 2nd YOLOv12n 80.99 \ud83e\udd49 3rd YOLO26n 78.31 4th YOLOv5nu 77.22 5th YOLOv6n 76.85 6th YOLOv10n 69.27 7th YOLOv9t 46.28 8th"},{"location":"guides/benchmarks/#detailed-benchmark-results","title":"Detailed Benchmark Results","text":""},{"location":"guides/benchmarks/#latency-statistics-milliseconds","title":"Latency Statistics (milliseconds)","text":"Model Avg StdDev Min Max P50 P90 P95 P99 YOLOv11n 10.29 0.96 8.47 12.65 10.25 11.59 12.11 12.57 YOLOv8n 11.69 1.25 9.86 16.08 11.56 13.10 14.18 15.73 YOLOv12n 12.35 0.99 10.36 18.76 12.14 13.33 13.95 15.32 YOLO26n 12.77 0.94 11.70 18.49 12.56 13.96 14.34 15.21 YOLOv5nu 12.95 1.30 11.32 19.56 12.70 13.98 15.28 19.39 YOLOv6n 13.01 1.26 11.61 19.57 12.49 14.36 15.00 17.36 YOLOv10n 14.44 8.13 9.12 55.35 11.45 23.08 33.35 48.04 YOLOv9t 21.61 11.06 15.48 87.97 17.44 32.16 41.20 67.76"},{"location":"guides/benchmarks/#load-warmup-times-milliseconds","title":"Load &amp; Warmup Times (milliseconds)","text":"Model Load Time Warmup Time Total Startup YOLOv8n 55.34 228.29 283.63 YOLOv11n 59.09 230.38 289.47 YOLOv6n 61.70 261.34 323.04 YOLOv5nu 67.94 278.62 346.56 YOLO26n 70.16 279.41 349.57 YOLOv10n 74.65 200.34 274.99 YOLOv9t 98.71 402.03 500.74 YOLOv12n 103.60 243.54 347.14"},{"location":"guides/benchmarks/#memory-usage","title":"Memory Usage","text":"Model Peak Memory (MB) Memory Delta (MB) CPU Usage (%) YOLOv5nu 110.2 5.2 84.7 YOLOv10n 111.4 7.3 94.0 YOLOv8n 116.8 9.4 86.6 YOLOv11n 119.4 13.8 85.2 YOLO26n 120.1 14.8 85.6 YOLOv6n 121.2 4.1 85.6 YOLOv12n 121.2 13.4 85.6 YOLOv9t 123.4 14.8 90.4"},{"location":"guides/benchmarks/#model-file-sizes","title":"Model File Sizes","text":"Model ONNX Size Architecture YOLOv9t 7.8 MB Gelan-based YOLOv10n 8.8 MB End-to-end NMS-free YOLO26n 9.3 MB End-to-end NMS-free YOLOv5nu 9.7 MB CSPDarknet YOLOv11n 10 MB C3k2 blocks YOLOv12n 10 MB Area Attention YOLOv8n 12 MB C2f blocks YOLOv6n 17 MB EfficientRep"},{"location":"guides/benchmarks/#analysis-insights","title":"Analysis &amp; Insights","text":""},{"location":"guides/benchmarks/#performance-leaders","title":"\ud83c\udfc6 Performance Leaders","text":"<ol> <li>YOLOv11n achieves the highest FPS (97.18) with excellent latency consistency (\u03c3=0.96ms)</li> <li>YOLOv8n follows closely at 85.55 FPS with good stability</li> <li>YOLOv12n and YOLO26n perform similarly (~80 FPS)</li> </ol>"},{"location":"guides/benchmarks/#latency-stability","title":"\u26a1 Latency Stability","text":"Model Stability Rating Notes YOLO26n \u2b50\u2b50\u2b50\u2b50\u2b50 Lowest std dev (0.94ms), most predictable YOLOv11n \u2b50\u2b50\u2b50\u2b50\u2b50 Very stable (0.96ms std dev) YOLOv12n \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent consistency (0.99ms) YOLOv8n \u2b50\u2b50\u2b50\u2b50 Good stability (1.25ms) YOLOv5nu \u2b50\u2b50\u2b50\u2b50 Acceptable variance (1.30ms) YOLOv6n \u2b50\u2b50\u2b50\u2b50 Good for production (1.26ms) YOLOv10n \u2b50\u2b50 High variance (8.13ms), outliers up to 55ms YOLOv9t \u2b50 Very high variance (11.06ms), not production-ready"},{"location":"guides/benchmarks/#memory-efficiency","title":"\ud83d\udcbe Memory Efficiency","text":"<ul> <li>YOLOv5nu and YOLOv10n are most memory-efficient (~110 MB)</li> <li>All models fit comfortably in typical embedded systems with 256MB+ RAM</li> <li>Memory delta during inference is minimal (&lt;15 MB)</li> </ul>"},{"location":"guides/benchmarks/#end-to-end-nms-free-models","title":"\ud83c\udfaf End-to-End NMS-Free Models","text":"<p>YOLO26n and YOLOv10n feature built-in NMS: - \u2705 No separate NMS postprocessing step - \u2705 Simpler deployment pipeline - \u2705 Consistent latency (no NMS variance) - \u26a0\ufe0f YOLOv10n shows higher variance likely due to model complexity</p>"},{"location":"guides/benchmarks/#recommendations","title":"Recommendations","text":""},{"location":"guides/benchmarks/#for-real-time-applications-60-fps-required","title":"For Real-Time Applications (&gt;60 FPS required)","text":"<ul> <li>Best Choice: YOLOv11n (97 FPS, excellent stability)</li> <li>Runner-up: YOLOv8n (86 FPS, proven reliability)</li> </ul>"},{"location":"guides/benchmarks/#for-edge-deployment-memory-constrained","title":"For Edge Deployment (Memory Constrained)","text":"<ul> <li>Best Choice: YOLOv5nu (110 MB, 77 FPS)</li> <li>Alternative: YOLOv10n (111 MB, end-to-end architecture)</li> </ul>"},{"location":"guides/benchmarks/#for-predictable-latency-production-systems","title":"For Predictable Latency (Production Systems)","text":"<ul> <li>Best Choice: YOLO26n (lowest variance, 78 FPS)</li> <li>Alternative: YOLOv11n (stable with higher throughput)</li> </ul>"},{"location":"guides/benchmarks/#for-simplest-deployment-no-nms-handling","title":"For Simplest Deployment (No NMS handling)","text":"<ul> <li>Best Choice: YOLO26n (end-to-end, stable, modern)</li> <li>Alternative: YOLOv10n (end-to-end, but less stable)</li> </ul>"},{"location":"guides/benchmarks/#raw-data","title":"Raw Data","text":"<p>Full benchmark CSV available at: <code>benchmarks/results/benchmark_results.csv</code></p>"},{"location":"guides/benchmarks/#notes","title":"Notes","text":"<ul> <li>All models were fine-tuned on Pascal VOC dataset (20 classes)</li> <li>Benchmarks run on CPU-only configuration</li> <li>Results may vary with GPU acceleration (typically 3-5x faster)</li> <li>Input image resolution affects performance proportionally</li> <li>Models exported with ONNX opset 12 for maximum compatibility</li> </ul> <p>Report generated by YOLOs-CPP Unified Benchmark Suite v2.0.0</p>"},{"location":"guides/getting-started/","title":"Installation Guide","text":"<p>This guide covers system requirements, build options, and troubleshooting for YOLOs-CPP.</p>"},{"location":"guides/getting-started/#system-requirements","title":"System Requirements","text":""},{"location":"guides/getting-started/#minimum-requirements","title":"Minimum Requirements","text":"Component Requirement OS Linux (Ubuntu 20.04+), Windows 10+, macOS 12+ Compiler GCC 9+, Clang 10+, or MSVC 2019+ CMake 3.16 or higher OpenCV 4.5 or higher C++ Standard C++17"},{"location":"guides/getting-started/#gpu-acceleration-optional","title":"GPU Acceleration (Optional)","text":"Component Requirement NVIDIA GPU Compute Capability 5.0+ CUDA Toolkit 11.0 or higher cuDNN 8.0+ (recommended)"},{"location":"guides/getting-started/#quick-install","title":"Quick Install","text":""},{"location":"guides/getting-started/#linux-macos","title":"Linux / macOS","text":"<pre><code># Clone the repository\ngit clone https://github.com/Geekgineer/YOLOs-CPP.git\ncd YOLOs-CPP\n\n# Build with auto-download of ONNX Runtime\n./build.sh 1.20.1 0   # CPU build\n./build.sh 1.20.1 1   # GPU build (requires CUDA)\n</code></pre>"},{"location":"guides/getting-started/#windows","title":"Windows","text":"<p>See Windows Setup Guide for detailed Windows instructions.</p>"},{"location":"guides/getting-started/#manual-build","title":"Manual Build","text":""},{"location":"guides/getting-started/#step-1-install-dependencies","title":"Step 1: Install Dependencies","text":"<p>Ubuntu/Debian:</p> <pre><code>sudo apt update\nsudo apt install -y build-essential cmake libopencv-dev\n</code></pre> <p>macOS (Homebrew):</p> <pre><code>brew install cmake opencv\n</code></pre>"},{"location":"guides/getting-started/#step-2-download-onnx-runtime","title":"Step 2: Download ONNX Runtime","text":"<pre><code># Linux x64 CPU\nwget https://github.com/microsoft/onnxruntime/releases/download/v1.20.1/onnxruntime-linux-x64-1.20.1.tgz\ntar -xzf onnxruntime-linux-x64-1.20.1.tgz\n\n# Linux x64 GPU\nwget https://github.com/microsoft/onnxruntime/releases/download/v1.20.1/onnxruntime-linux-x64-gpu-1.20.1.tgz\ntar -xzf onnxruntime-linux-x64-gpu-1.20.1.tgz\n</code></pre>"},{"location":"guides/getting-started/#step-3-configure-and-build","title":"Step 3: Configure and Build","text":"<pre><code>mkdir build &amp;&amp; cd build\n\n# CPU build\ncmake .. \\\n  -DONNXRUNTIME_DIR=../onnxruntime-linux-x64-1.20.1 \\\n  -DCMAKE_BUILD_TYPE=Release\n\n# Compile\nmake -j$(nproc)\n</code></pre>"},{"location":"guides/getting-started/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<pre><code>./image_inference ../models/yolo11n.onnx ../data/dog.jpg\n</code></pre>"},{"location":"guides/getting-started/#build-options","title":"Build Options","text":"CMake Option Default Description <code>ONNXRUNTIME_DIR</code> auto-detect Path to ONNX Runtime installation <code>BUILD_EXAMPLES</code> OFF Build task-specific examples <code>CMAKE_BUILD_TYPE</code> Release Build type (Debug/Release)"},{"location":"guides/getting-started/#docker-installation","title":"Docker Installation","text":"<pre><code># CPU\ndocker build -f Dockerfile.cpu -t yolos-cpp:cpu .\ndocker run --rm -it yolos-cpp:cpu\n\n# GPU (requires nvidia-docker)\ndocker build -t yolos-cpp:gpu .\ndocker run --gpus all --rm -it yolos-cpp:gpu\n</code></pre>"},{"location":"guides/getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/getting-started/#opencv-not-found","title":"\"OpenCV not found\"","text":"<pre><code>pkg-config --modversion opencv4\ncmake .. -DOpenCV_DIR=/path/to/opencv/build\n</code></pre>"},{"location":"guides/getting-started/#onnx-runtime-not-found","title":"\"ONNX Runtime not found\"","text":"<pre><code>ls $ONNXRUNTIME_DIR/include/onnxruntime_cxx_api.h\n</code></pre>"},{"location":"guides/getting-started/#build-fails-on-windows","title":"Build fails on Windows","text":"<p>See Windows Setup Guide.</p>"},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Usage Guide \u2014 Learn the API</li> <li>Model Guide \u2014 Export and use models</li> </ul>"},{"location":"guides/getting-started/#windows-quick-start","title":"Windows Quick Start","text":""},{"location":"guides/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Visual Studio 2019+ with \"Desktop development with C++\"</li> <li>CMake 3.16+</li> <li>OpenCV 4.5+ (from opencv.org or vcpkg)</li> </ul>"},{"location":"guides/getting-started/#option-1-powershell-script","title":"Option 1: PowerShell Script","text":"<pre><code># CPU build\n.\\build.ps1\n\n# GPU build (requires CUDA)\n.\\build.ps1 -GPU\n\n# Clean build\n.\\build.ps1 -Clean\n</code></pre>"},{"location":"guides/getting-started/#option-2-batch-script","title":"Option 2: Batch Script","text":"<pre><code>build.bat          # CPU build\nbuild.bat gpu      # GPU build\n</code></pre>"},{"location":"guides/getting-started/#option-3-manual-build","title":"Option 3: Manual Build","text":"<pre><code># Download ONNX Runtime\nInvoke-WebRequest -Uri \"https://github.com/microsoft/onnxruntime/releases/download/v1.20.1/onnxruntime-win-x64-1.20.1.zip\" -OutFile \"ort.zip\"\nExpand-Archive -Path \"ort.zip\" -DestinationPath \".\"\n\n# Build\nmkdir build; cd build\ncmake .. -DONNXRUNTIME_DIR=\"..\\onnxruntime-win-x64-1.20.1\"\ncmake --build . --config Release\n\n# Run\n.\\Release\\image_inference.exe ..\\models\\yolo11n.onnx ..\\data\\dog.jpg\n</code></pre>"},{"location":"guides/getting-started/#setting-up-opencv-on-windows","title":"Setting up OpenCV on Windows","text":"<p>Option A: Pre-built binaries 1. Download from https://opencv.org/releases/ 2. Extract to <code>C:\\opencv</code> 3. Add <code>C:\\opencv\\build\\x64\\vc16\\bin</code> to PATH</p> <p>Option B: Using vcpkg</p> <pre><code>vcpkg install opencv4:x64-windows\ncmake .. -DCMAKE_TOOLCHAIN_FILE=\"[vcpkg]/scripts/buildsystems/vcpkg.cmake\"\n</code></pre> <p>See Windows Setup Guide for complete instructions.</p>"},{"location":"guides/getting-started/#macos-quick-start","title":"macOS Quick Start","text":"<pre><code># Install dependencies\nbrew install cmake opencv\n\n# Download ONNX Runtime (Apple Silicon)\nwget https://github.com/microsoft/onnxruntime/releases/download/v1.20.1/onnxruntime-osx-arm64-1.20.1.tgz\ntar -xzf onnxruntime-osx-arm64-1.20.1.tgz\n\n# Build\nmkdir build &amp;&amp; cd build\ncmake .. -DONNXRUNTIME_DIR=../onnxruntime-osx-arm64-1.20.1\nmake -j$(sysctl -n hw.ncpu)\n</code></pre> <p>For Intel Macs, use <code>onnxruntime-osx-x86_64-1.20.1.tgz</code>.</p>"},{"location":"guides/models/","title":"Model Guide","text":"<p>Supported models, ONNX export, and optimization for YOLOs-CPP.</p>"},{"location":"guides/models/#supported-models","title":"Supported Models","text":""},{"location":"guides/models/#detection","title":"Detection","text":"Model Params mAP Speed (GPU) YOLOv5n 1.9M 28.0 6.3ms YOLOv8n 3.2M 37.3 6.2ms YOLOv11n 2.6M 39.5 6.5ms YOLO26n 2.5M 40.2 7.1ms"},{"location":"guides/models/#segmentation","title":"Segmentation","text":"Model Params mAP Speed (GPU) YOLOv8n-seg 3.4M 36.7 8.4ms YOLOv11n-seg 2.9M 38.9 8.1ms YOLO26n-seg 2.8M 39.4 8.8ms"},{"location":"guides/models/#pose-estimation","title":"Pose Estimation","text":"Model Params mAP Speed (GPU) YOLOv8n-pose 3.3M 50.4 5.9ms YOLOv11n-pose 2.9M 52.1 5.7ms YOLO26n-pose 2.8M 53.0 6.2ms"},{"location":"guides/models/#obb-oriented-bounding-boxes","title":"OBB (Oriented Bounding Boxes)","text":"Model Params Dataset YOLOv8n-obb 3.1M DOTA YOLOv11n-obb 2.7M DOTA YOLO26n-obb 2.6M DOTA"},{"location":"guides/models/#classification","title":"Classification","text":"Model Params Top-1 Acc YOLOv8n-cls 2.7M 66.6% YOLOv11n-cls 1.6M 70.0% YOLO26n-cls 1.5M 71.2%"},{"location":"guides/models/#exporting-to-onnx","title":"Exporting to ONNX","text":""},{"location":"guides/models/#using-ultralytics","title":"Using Ultralytics","text":"<pre><code>from ultralytics import YOLO\n\n# Load model\nmodel = YOLO(\"yolo11n.pt\")\n\n# Export to ONNX\nmodel.export(\n    format=\"onnx\",\n    imgsz=640,\n    opset=12,        # ONNX opset version\n    simplify=False,\n    half=False,\n    dynamic=False,\n    nms=False        # NMS is done in C++\n)\n</code></pre>"},{"location":"guides/models/#export-options","title":"Export Options","text":"Option Value Notes <code>opset</code> 12-17 Use 12 for max compatibility <code>imgsz</code> 640 Match your inference resolution <code>half</code> False FP32 for accuracy (FP16 optional) <code>dynamic</code> False Static shapes for best performance <code>nms</code> False C++ handles NMS"},{"location":"guides/models/#batch-export-script","title":"Batch Export Script","text":"<pre><code>python models/export_onnx.py\n</code></pre>"},{"location":"guides/models/#label-files","title":"Label Files","text":"File Classes Use Case <code>coco.names</code> 80 General detection <code>Dota.names</code> 15 Aerial/satellite OBB <code>imagenet_classes.txt</code> 1000 Classification"},{"location":"guides/models/#model-paths","title":"Model Paths","text":"<pre><code>// Detection\n\"models/yolo11n.onnx\"\n\n// Segmentation\n\"models/yolo11n-seg.onnx\"\n\n// Pose\n\"models/yolo11n-pose.onnx\"\n\n// OBB\n\"models/yolo11n-obb.onnx\"\n\n// Classification\n\"models/yolo11n-cls.onnx\"\n</code></pre>"},{"location":"guides/models/#quantization","title":"Quantization","text":"<p>Quantized models offer: - 2-4x smaller file size - 1.5-2x faster CPU inference - Slight accuracy loss (~1-2% mAP)</p>"},{"location":"guides/models/#quantize-with-onnx","title":"Quantize with ONNX","text":"<pre><code>from onnxruntime.quantization import quantize_dynamic\n\nquantize_dynamic(\n    \"model.onnx\",\n    \"model_int8.onnx\"\n)\n</code></pre> <p>See <code>quantized_models/yolos_quantization.py</code> for examples.</p>"},{"location":"guides/models/#custom-models","title":"Custom Models","text":"<p>To use custom-trained models:</p> <ol> <li>Train with Ultralytics</li> <li>Export to ONNX with compatible settings</li> <li>Create matching label file</li> <li>Load in YOLOs-CPP</li> </ol> <pre><code>yolos::det::YOLODetector detector(\n    \"custom_model.onnx\",\n    \"custom_labels.txt\",\n    true\n);\n</code></pre>"},{"location":"guides/quantization/","title":"Model Quantization Guide","text":"<p>Optimize models for faster inference and smaller file size.</p>"},{"location":"guides/quantization/#what-is-quantization","title":"What is Quantization?","text":"<p>Quantization converts model weights from 32-bit floating point (FP32) to lower precision formats:</p> Format Size Speed Accuracy FP32 100% Baseline Best FP16 50% 1.5-2x ~Same INT8 25% 2-4x -1-2% mAP"},{"location":"guides/quantization/#quick-start","title":"Quick Start","text":"<pre><code>from onnxruntime.quantization import quantize_dynamic\n\nquantize_dynamic(\n    \"yolo11n.onnx\",\n    \"yolo11n_int8.onnx\"\n)\n</code></pre>"},{"location":"guides/quantization/#dynamic-quantization","title":"Dynamic Quantization","text":"<p>Best for CPU inference. No calibration data needed.</p> <pre><code>from onnxruntime.quantization import quantize_dynamic, QuantType\n\nquantize_dynamic(\n    model_input=\"yolo11n.onnx\",\n    model_output=\"yolo11n_int8.onnx\",\n    weight_type=QuantType.QUInt8\n)\n</code></pre>"},{"location":"guides/quantization/#static-quantization","title":"Static Quantization","text":"<p>Better accuracy with calibration data.</p> <pre><code>from onnxruntime.quantization import quantize_static, CalibrationDataReader\n\nclass YOLOCalibrationReader(CalibrationDataReader):\n    def __init__(self, images_dir, input_name, input_shape):\n        self.images = [...]  # Load calibration images\n        self.input_name = input_name\n        self.input_shape = input_shape\n        self.index = 0\n\n    def get_next(self):\n        if self.index &gt;= len(self.images):\n            return None\n        # Preprocess image\n        data = self.preprocess(self.images[self.index])\n        self.index += 1\n        return {self.input_name: data}\n\ncalibration_reader = YOLOCalibrationReader(\n    \"calibration_images/\",\n    \"images\",\n    [1, 3, 640, 640]\n)\n\nquantize_static(\n    \"yolo11n.onnx\",\n    \"yolo11n_static_int8.onnx\",\n    calibration_reader\n)\n</code></pre>"},{"location":"guides/quantization/#using-quantized-models","title":"Using Quantized Models","text":"<pre><code>// Same API as FP32 models\nyolos::det::YOLODetector detector(\n    \"yolo11n_int8.onnx\",\n    \"coco.names\",\n    false  // CPU (quantized models are CPU-optimized)\n);\n\nauto detections = detector.detect(frame);\n</code></pre>"},{"location":"guides/quantization/#benchmarks","title":"Benchmarks","text":"<p>Tested on Intel i7-12700H (CPU):</p> Model Size Latency mAP YOLOv11n (FP32) 5.4MB 67ms 39.5 YOLOv11n (INT8) 1.8MB 28ms 38.2 YOLOv8n (FP32) 6.2MB 72ms 37.3 YOLOv8n (INT8) 2.1MB 31ms 36.1"},{"location":"guides/quantization/#tips","title":"Tips","text":"<ol> <li>Calibration data matters \u2014 Use 100-500 representative images</li> <li>Test accuracy \u2014 Validate mAP after quantization</li> <li>CPU only \u2014 INT8 is optimized for CPU, not GPU</li> <li>Per-channel \u2014 Better accuracy than per-tensor</li> </ol>"},{"location":"guides/quantization/#script","title":"Script","text":"<p>See <code>quantized_models/yolos_quantization.py</code> for a complete example.</p>"},{"location":"guides/quantization/#next-steps","title":"Next Steps","text":"<ul> <li>Model Guide \u2014 ONNX export</li> <li>Benchmarks \u2014 Performance testing</li> </ul>"},{"location":"yolos/annotated/","title":"Class List","text":"<p>Here are the classes, structs, unions and interfaces with brief descriptions:</p> <ul> <li>namespace yolos <ul> <li>struct BoundingBox </li> <li>struct KeyPoint </li> <li>struct OrientedBoundingBox </li> <li>class OrtSessionBase Base class for ONNX Runtime session management Handles model loading, session configuration, and common inference setup. </li> <li>namespace cls <ul> <li>struct ClassificationResult Classification result containing class ID, confidence, and class name. </li> <li>class YOLO11Classifier YOLOv11 classifier. </li> <li>class YOLO12Classifier YOLOv12 classifier. </li> <li>class YOLO26Classifier YOLO26 classifier. </li> <li>class YOLOClassifier YOLO classifier for image classification. </li> </ul> </li> <li>namespace det <ul> <li>struct Detection Detection result containing bounding box, confidence, and class ID. </li> <li>class YOLO26Detector YOLOv26 detector (forces V26 end-to-end postprocessing) </li> <li>class YOLODetector Base YOLO detector with runtime version auto-detection. </li> <li>class YOLONASDetector YOLO-NAS detector (forces NAS postprocessing) </li> <li>class YOLOv10Detector YOLOv10 detector (forces V10 end-to-end postprocessing) </li> <li>class YOLOv11Detector YOLOv11 detector (forces standard postprocessing) </li> <li>class YOLOv7Detector YOLOv7 detector (forces V7 postprocessing) </li> <li>class YOLOv8Detector YOLOv8 detector (forces standard postprocessing) </li> </ul> </li> <li>namespace drawing </li> <li>namespace nms </li> <li>namespace obb <ul> <li>struct OBBResult OBB detection result containing oriented bounding box, confidence, and class ID. </li> <li>class YOLOOBBDetector YOLO oriented bounding box detector for rotated object detection. </li> </ul> </li> <li>namespace pose <ul> <li>struct PoseResult Pose estimation result containing bounding box, confidence, and keypoints. </li> <li>class YOLOPoseDetector YOLO pose estimation detector with keypoint detection. </li> </ul> </li> <li>namespace preprocessing <ul> <li>struct InferenceBuffer Pre-allocated inference buffer to avoid per-frame allocations. </li> </ul> </li> <li>namespace seg <ul> <li>struct Segmentation Segmentation result containing bounding box, confidence, class ID, and mask. </li> <li>class YOLOSegDetector YOLO segmentation detector with mask prediction. </li> </ul> </li> <li>namespace utils </li> <li>namespace version </li> </ul> </li> </ul>"},{"location":"yolos/files/","title":"File List","text":"<p>Here is a list of all files with brief descriptions:</p> <ul> <li>dir include <ul> <li>dir yolos <ul> <li>dir core <ul> <li>file drawing.hpp </li> <li>file nms.hpp </li> <li>file preprocessing.hpp </li> <li>file session_base.hpp </li> <li>file types.hpp </li> <li>file utils.hpp </li> <li>file version.hpp </li> </ul> </li> <li>dir tasks <ul> <li>file classification.hpp </li> <li>file detection.hpp </li> <li>file obb.hpp </li> <li>file pose.hpp </li> <li>file segmentation.hpp </li> </ul> </li> <li>file yolos.hpp </li> </ul> </li> </ul> </li> </ul>"},{"location":"yolos/namespaceyolos/","title":"Namespace yolos","text":"<p>Namespace List &gt; yolos</p>"},{"location":"yolos/namespaceyolos/#namespaces","title":"Namespaces","text":"Type Name namespace cls namespace det namespace drawing namespace nms namespace obb namespace pose namespace preprocessing namespace seg namespace utils namespace version"},{"location":"yolos/namespaceyolos/#classes","title":"Classes","text":"Type Name struct BoundingBox struct KeyPoint struct OrientedBoundingBox class OrtSessionBase Base class for ONNX Runtime session management Handles model loading, session configuration, and common inference setup."},{"location":"yolos/namespaceyolos/#public-types","title":"Public Types","text":"Type Name typedef cls::ClassificationResult ClassificationResult typedef det::Detection Detection typedef obb::OBBResult OBBResult typedef pose::PoseResult PoseResult typedef seg::Segmentation Segmentation typedef cls::YOLO26Classifier YOLO26Classifier typedef det::YOLO26Detector YOLO26Detector typedef cls::YOLOClassifier YOLOClassifier typedef det::YOLODetector YOLODetector typedef obb::YOLOOBBDetector YOLOOBBDetector typedef pose::YOLOPoseDetector YOLOPoseDetector typedef seg::YOLOSegDetector YOLOSegDetector enum YOLOVersion"},{"location":"yolos/namespaceyolos/#public-functions","title":"Public Functions","text":"Type Name const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; getPoseSkeleton ()"},{"location":"yolos/namespaceyolos/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"yolos/namespaceyolos/#typedef-classificationresult","title":"typedef ClassificationResult","text":"<pre><code>using yolos::ClassificationResult = typedef cls::ClassificationResult;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-detection","title":"typedef Detection","text":"<pre><code>using yolos::Detection = typedef det::Detection;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-obbresult","title":"typedef OBBResult","text":"<pre><code>using yolos::OBBResult = typedef obb::OBBResult;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-poseresult","title":"typedef PoseResult","text":"<pre><code>using yolos::PoseResult = typedef pose::PoseResult;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-segmentation","title":"typedef Segmentation","text":"<pre><code>using yolos::Segmentation = typedef seg::Segmentation;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yolo26classifier","title":"typedef YOLO26Classifier","text":"<pre><code>using yolos::YOLO26Classifier = typedef cls::YOLO26Classifier;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yolo26detector","title":"typedef YOLO26Detector","text":"<pre><code>using yolos::YOLO26Detector = typedef det::YOLO26Detector;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yoloclassifier","title":"typedef YOLOClassifier","text":"<pre><code>using yolos::YOLOClassifier = typedef cls::YOLOClassifier;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yolodetector","title":"typedef YOLODetector","text":"<pre><code>using yolos::YOLODetector = typedef det::YOLODetector;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yoloobbdetector","title":"typedef YOLOOBBDetector","text":"<pre><code>using yolos::YOLOOBBDetector = typedef obb::YOLOOBBDetector;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yoloposedetector","title":"typedef YOLOPoseDetector","text":"<pre><code>using yolos::YOLOPoseDetector = typedef pose::YOLOPoseDetector;\n</code></pre>"},{"location":"yolos/namespaceyolos/#typedef-yolosegdetector","title":"typedef YOLOSegDetector","text":"<pre><code>using yolos::YOLOSegDetector = typedef seg::YOLOSegDetector;\n</code></pre>"},{"location":"yolos/namespaceyolos/#enum-yoloversion","title":"enum YOLOVersion","text":"<pre><code>enum yolos::YOLOVersion {\n    Auto,\n    V7,\n    V8,\n    V10,\n    V11,\n    V12,\n    V26,\n    NAS\n};\n</code></pre>"},{"location":"yolos/namespaceyolos/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos/#function-getposeskeleton","title":"function getPoseSkeleton","text":"<pre><code>inline const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; yolos::getPoseSkeleton () \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/drawing.hpp</code></p>"},{"location":"yolos/structyolos_1_1BoundingBox/","title":"Struct yolos::BoundingBox","text":"<p>ClassList &gt; yolos &gt; BoundingBox</p> <ul> <li><code>#include &lt;types.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1BoundingBox/#public-attributes","title":"Public Attributes","text":"Type Name int height   = <code>{0}</code>Height of the bounding box. int width   = <code>{0}</code>Width of the bounding box. int x   = <code>{0}</code>X-coordinate of top-left corner. int y   = <code>{0}</code>Y-coordinate of top-left corner."},{"location":"yolos/structyolos_1_1BoundingBox/#public-functions","title":"Public Functions","text":"Type Name BoundingBox () = default BoundingBox (int x_, int y_, int width_, int height_)  float area () noexcept constCompute area of the bounding box. BoundingBox intersect (const BoundingBox &amp; other) noexcept constCompute intersection with another bounding box. float iou (const BoundingBox &amp; other) noexcept constCompute IoU (Intersection over Union) with another bounding box."},{"location":"yolos/structyolos_1_1BoundingBox/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1BoundingBox/#variable-height","title":"variable height","text":"<p>Height of the bounding box. </p> <pre><code>int yolos::BoundingBox::height;\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#variable-width","title":"variable width","text":"<p>Width of the bounding box. </p> <pre><code>int yolos::BoundingBox::width;\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#variable-x","title":"variable x","text":"<p>X-coordinate of top-left corner. </p> <pre><code>int yolos::BoundingBox::x;\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#variable-y","title":"variable y","text":"<p>Y-coordinate of top-left corner. </p> <pre><code>int yolos::BoundingBox::y;\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1BoundingBox/#function-boundingbox-12","title":"function BoundingBox [1/2]","text":"<pre><code>yolos::BoundingBox::BoundingBox () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#function-boundingbox-22","title":"function BoundingBox [2/2]","text":"<pre><code>inline yolos::BoundingBox::BoundingBox (\n    int x_,\n    int y_,\n    int width_,\n    int height_\n) \n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#function-area","title":"function area","text":"<p>Compute area of the bounding box. </p> <pre><code>inline float yolos::BoundingBox::area () noexcept const\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#function-intersect","title":"function intersect","text":"<p>Compute intersection with another bounding box. </p> <pre><code>inline BoundingBox yolos::BoundingBox::intersect (\n    const BoundingBox &amp; other\n) noexcept const\n</code></pre>"},{"location":"yolos/structyolos_1_1BoundingBox/#function-iou","title":"function iou","text":"<p>Compute IoU (Intersection over Union) with another bounding box. </p> <pre><code>inline float yolos::BoundingBox::iou (\n    const BoundingBox &amp; other\n) noexcept const\n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/types.hpp</code></p>"},{"location":"yolos/structyolos_1_1KeyPoint/","title":"Struct yolos::KeyPoint","text":"<p>ClassList &gt; yolos &gt; KeyPoint</p> <ul> <li><code>#include &lt;types.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1KeyPoint/#public-attributes","title":"Public Attributes","text":"Type Name float confidence   = <code>{0.0f}</code>Confidence score. float x   = <code>{0.0f}</code>X-coordinate. float y   = <code>{0.0f}</code>Y-coordinate."},{"location":"yolos/structyolos_1_1KeyPoint/#public-functions","title":"Public Functions","text":"Type Name KeyPoint () = default KeyPoint (float x_, float y_, float conf_=0.0f)"},{"location":"yolos/structyolos_1_1KeyPoint/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1KeyPoint/#variable-confidence","title":"variable confidence","text":"<p>Confidence score. </p> <pre><code>float yolos::KeyPoint::confidence;\n</code></pre>"},{"location":"yolos/structyolos_1_1KeyPoint/#variable-x","title":"variable x","text":"<p>X-coordinate. </p> <pre><code>float yolos::KeyPoint::x;\n</code></pre>"},{"location":"yolos/structyolos_1_1KeyPoint/#variable-y","title":"variable y","text":"<p>Y-coordinate. </p> <pre><code>float yolos::KeyPoint::y;\n</code></pre>"},{"location":"yolos/structyolos_1_1KeyPoint/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1KeyPoint/#function-keypoint-12","title":"function KeyPoint [1/2]","text":"<pre><code>yolos::KeyPoint::KeyPoint () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1KeyPoint/#function-keypoint-22","title":"function KeyPoint [2/2]","text":"<pre><code>inline yolos::KeyPoint::KeyPoint (\n    float x_,\n    float y_,\n    float conf_=0.0f\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/types.hpp</code></p>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/","title":"Struct yolos::OrientedBoundingBox","text":"<p>ClassList &gt; yolos &gt; OrientedBoundingBox</p> <ul> <li><code>#include &lt;types.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#public-attributes","title":"Public Attributes","text":"Type Name float angle   = <code>{0.0f}</code>Rotation angle in radians. float height   = <code>{0.0f}</code>Height of the box. float width   = <code>{0.0f}</code>Width of the box. float x   = <code>{0.0f}</code>X-coordinate of center. float y   = <code>{0.0f}</code>Y-coordinate of center."},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#public-functions","title":"Public Functions","text":"Type Name OrientedBoundingBox () = default OrientedBoundingBox (float x_, float y_, float width_, float height_, float angle_)  float area () noexcept constCompute area of the oriented bounding box."},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#variable-angle","title":"variable angle","text":"<p>Rotation angle in radians. </p> <pre><code>float yolos::OrientedBoundingBox::angle;\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#variable-height","title":"variable height","text":"<p>Height of the box. </p> <pre><code>float yolos::OrientedBoundingBox::height;\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#variable-width","title":"variable width","text":"<p>Width of the box. </p> <pre><code>float yolos::OrientedBoundingBox::width;\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#variable-x","title":"variable x","text":"<p>X-coordinate of center. </p> <pre><code>float yolos::OrientedBoundingBox::x;\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#variable-y","title":"variable y","text":"<p>Y-coordinate of center. </p> <pre><code>float yolos::OrientedBoundingBox::y;\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#function-orientedboundingbox-12","title":"function OrientedBoundingBox [1/2]","text":"<pre><code>yolos::OrientedBoundingBox::OrientedBoundingBox () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#function-orientedboundingbox-22","title":"function OrientedBoundingBox [2/2]","text":"<pre><code>inline yolos::OrientedBoundingBox::OrientedBoundingBox (\n    float x_,\n    float y_,\n    float width_,\n    float height_,\n    float angle_\n) \n</code></pre>"},{"location":"yolos/structyolos_1_1OrientedBoundingBox/#function-area","title":"function area","text":"<p>Compute area of the oriented bounding box. </p> <pre><code>inline float yolos::OrientedBoundingBox::area () noexcept const\n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/types.hpp</code></p>"},{"location":"yolos/classyolos_1_1OrtSessionBase/","title":"Class yolos::OrtSessionBase","text":"<p>ClassList &gt; yolos &gt; OrtSessionBase</p> <p>Base class for ONNX Runtime session management Handles model loading, session configuration, and common inference setup. </p> <ul> <li><code>#include &lt;session_base.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: yolos::det::YOLODetector,  yolos::obb::YOLOOBBDetector,  yolos::pose::YOLOPoseDetector,  yolos::seg::YOLOSegDetector</p>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#public-functions","title":"Public Functions","text":"Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1OrtSessionBase/#protected-attributes","title":"Protected Attributes","text":"Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#protected-functions","title":"Protected Functions","text":"Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1OrtSessionBase/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-ortsessionbase-13","title":"function OrtSessionBase [1/3]","text":"<p>Constructor - loads and initializes the ONNX model. </p> <pre><code>inline yolos::OrtSessionBase::OrtSessionBase (\n    const std::string &amp; modelPath,\n    bool useGPU=false,\n    int numThreads=0\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>useGPU</code> Whether to use GPU (CUDA) for inference </li> <li><code>numThreads</code> Number of intra-op threads (0 = auto) </li> </ul>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-ortsessionbase-23","title":"function OrtSessionBase [2/3]","text":"<pre><code>yolos::OrtSessionBase::OrtSessionBase (\n    const OrtSessionBase &amp;\n) = delete\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-ortsessionbase-33","title":"function OrtSessionBase [3/3]","text":"<pre><code>yolos::OrtSessionBase::OrtSessionBase (\n    OrtSessionBase &amp;&amp;\n) = default\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-getdevice","title":"function getDevice","text":"<p>Get the device being used for inference. </p> <pre><code>inline const std::string &amp; yolos::OrtSessionBase::getDevice () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-getinputshape","title":"function getInputShape","text":"<p>Get the input image shape expected by the model. </p> <pre><code>inline cv::Size yolos::OrtSessionBase::getInputShape () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-getnuminputnodes","title":"function getNumInputNodes","text":"<p>Get the number of input nodes. </p> <pre><code>inline size_t yolos::OrtSessionBase::getNumInputNodes () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-getnumoutputnodes","title":"function getNumOutputNodes","text":"<p>Get the number of output nodes. </p> <pre><code>inline size_t yolos::OrtSessionBase::getNumOutputNodes () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-isdynamicbatchsize","title":"function isDynamicBatchSize","text":"<p>Check if batch size is dynamic. </p> <pre><code>inline bool yolos::OrtSessionBase::isDynamicBatchSize () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-isdynamicinputshape","title":"function isDynamicInputShape","text":"<p>Check if input shape is dynamic. </p> <pre><code>inline bool yolos::OrtSessionBase::isDynamicInputShape () noexcept const\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-operator","title":"function operator=","text":"<pre><code>OrtSessionBase &amp; yolos::OrtSessionBase::operator= (\n    const OrtSessionBase &amp;\n) = delete\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-operator_1","title":"function operator=","text":"<pre><code>OrtSessionBase &amp; yolos::OrtSessionBase::operator= (\n    OrtSessionBase &amp;&amp;\n) = default\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-ortsessionbase","title":"function ~OrtSessionBase","text":"<pre><code>virtual yolos::OrtSessionBase::~OrtSessionBase () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-device_","title":"variable device_","text":"<pre><code>std::string yolos::OrtSessionBase::device_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-env_","title":"variable env_","text":"<pre><code>Ort::Env yolos::OrtSessionBase::env_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-inputnameallocs_","title":"variable inputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::OrtSessionBase::inputNameAllocs_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-inputnames_","title":"variable inputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::OrtSessionBase::inputNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-inputshape_","title":"variable inputShape_","text":"<pre><code>cv::Size yolos::OrtSessionBase::inputShape_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-isdynamicbatchsize_","title":"variable isDynamicBatchSize_","text":"<pre><code>bool yolos::OrtSessionBase::isDynamicBatchSize_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-isdynamicinputshape_","title":"variable isDynamicInputShape_","text":"<pre><code>bool yolos::OrtSessionBase::isDynamicInputShape_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-numinputnodes_","title":"variable numInputNodes_","text":"<pre><code>size_t yolos::OrtSessionBase::numInputNodes_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-numoutputnodes_","title":"variable numOutputNodes_","text":"<pre><code>size_t yolos::OrtSessionBase::numOutputNodes_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-outputnameallocs_","title":"variable outputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::OrtSessionBase::outputNameAllocs_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-outputnames_","title":"variable outputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::OrtSessionBase::outputNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-sessionoptions_","title":"variable sessionOptions_","text":"<pre><code>Ort::SessionOptions yolos::OrtSessionBase::sessionOptions_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#variable-session_","title":"variable session_","text":"<pre><code>Ort::Session yolos::OrtSessionBase::session_;\n</code></pre>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-createinputtensor","title":"function createInputTensor","text":"<p>Create an input tensor from a blob. </p> <pre><code>inline Ort::Value yolos::OrtSessionBase::createInputTensor (\n    float * blob,\n    const std::vector&lt; int64_t &gt; &amp; inputTensorShape\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>blob</code> Pointer to the input data </li> <li><code>inputTensorShape</code> Shape of the input tensor </li> </ul> <p>Returns:</p> <p>ONNX Runtime input tensor </p>"},{"location":"yolos/classyolos_1_1OrtSessionBase/#function-runinference","title":"function runInference","text":"<p>Run inference with the given input tensor. </p> <pre><code>inline std::vector&lt; Ort::Value &gt; yolos::OrtSessionBase::runInference (\n    Ort::Value &amp; inputTensor\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>inputTensor</code> Input tensor </li> </ul> <p>Returns:</p> <p>Vector of output tensors </p> <p>The documentation for this class was generated from the following file <code>include/yolos/core/session_base.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1cls/","title":"Namespace yolos::cls","text":"<p>Namespace List &gt; yolos &gt; cls</p>"},{"location":"yolos/namespaceyolos_1_1cls/#classes","title":"Classes","text":"Type Name struct ClassificationResult Classification result containing class ID, confidence, and class name. class YOLO11Classifier YOLOv11 classifier. class YOLO12Classifier YOLOv12 classifier. class YOLO26Classifier YOLO26 classifier. class YOLOClassifier YOLO classifier for image classification."},{"location":"yolos/namespaceyolos_1_1cls/#public-functions","title":"Public Functions","text":"Type Name std::unique_ptr&lt; YOLOClassifier &gt; createClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, YOLOVersion version=YOLOVersion::V11, bool useGPU=false) Create a classifier with explicit version selection. void drawClassificationResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30), const cv::Scalar &amp; textColor=cv::Scalar(0, 255, 0), const cv::Scalar &amp; bgColor=cv::Scalar(0, 0, 0)) Draw classification result on an image."},{"location":"yolos/namespaceyolos_1_1cls/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1cls/#function-createclassifier","title":"function createClassifier","text":"<p>Create a classifier with explicit version selection. </p> <pre><code>inline std::unique_ptr&lt; YOLOClassifier &gt; yolos::cls::createClassifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    YOLOVersion version=YOLOVersion::V11,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>version</code> YOLO version </li> <li><code>useGPU</code> Whether to use GPU </li> </ul> <p>Returns:</p> <p>Unique pointer to classifier </p>"},{"location":"yolos/namespaceyolos_1_1cls/#function-drawclassificationresult","title":"function drawClassificationResult","text":"<p>Draw classification result on an image. </p> <pre><code>inline void yolos::cls::drawClassificationResult (\n    cv::Mat &amp; image,\n    const ClassificationResult &amp; result,\n    const cv::Point &amp; position=cv::Point(10, 30),\n    const cv::Scalar &amp; textColor=cv::Scalar(0, 255, 0),\n    const cv::Scalar &amp; bgColor=cv::Scalar(0, 0, 0)\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>result</code> Classification result </li> <li><code>position</code> Position for the text </li> <li><code>textColor</code> Text color </li> <li><code>bgColor</code> Background color </li> </ul> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/","title":"Struct yolos::cls::ClassificationResult","text":"<p>ClassList &gt; yolos &gt; cls &gt; ClassificationResult</p> <p>Classification result containing class ID, confidence, and class name. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#public-attributes","title":"Public Attributes","text":"Type Name int classId   = <code>{-1}</code>Predicted class ID. std::string className   = <code>{}</code>Human-readable class name. float confidence   = <code>{0.0f}</code>Confidence score."},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#public-functions","title":"Public Functions","text":"Type Name ClassificationResult () = default ClassificationResult (int id, float conf, std::string name)"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#variable-classid","title":"variable classId","text":"<p>Predicted class ID. </p> <pre><code>int yolos::cls::ClassificationResult::classId;\n</code></pre>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#variable-classname","title":"variable className","text":"<p>Human-readable class name. </p> <pre><code>std::string yolos::cls::ClassificationResult::className;\n</code></pre>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#variable-confidence","title":"variable confidence","text":"<p>Confidence score. </p> <pre><code>float yolos::cls::ClassificationResult::confidence;\n</code></pre>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#function-classificationresult-12","title":"function ClassificationResult [1/2]","text":"<pre><code>yolos::cls::ClassificationResult::ClassificationResult () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1cls_1_1ClassificationResult/#function-classificationresult-22","title":"function ClassificationResult [2/2]","text":"<pre><code>inline yolos::cls::ClassificationResult::ClassificationResult (\n    int id,\n    float conf,\n    std::string name\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/","title":"Class yolos::cls::YOLO11Classifier","text":"<p>ClassList &gt; yolos &gt; cls &gt; YOLO11Classifier</p> <p>YOLOv11 classifier. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::cls::YOLOClassifier</p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#public-functions","title":"Public Functions","text":"Type Name YOLO11Classifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#public-functions-inherited-from-yolosclsyoloclassifier","title":"Public Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name YOLOClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, const cv::Size &amp; targetInputShape=cv::Size(224, 224)) Constructor. ClassificationResult classify (const cv::Mat &amp; image) Run classification on an image. void drawResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30)) constDraw classification result on an image. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. cv::Size getInputShape () constGet input shape. bool isDynamicInputShape () constCheck if input shape is dynamic. virtual ~YOLOClassifier () = default"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#protected-attributes-inherited-from-yolosclsyoloclassifier","title":"Protected Attributes inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name std::vector&lt; std::string &gt; classNames_ Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; float &gt; inputBuffer_ cv::Size inputImageShape_ std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ bool isDynamicInputShape_   = <code>{false}</code> int numClasses_   = <code>{0}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#protected-functions-inherited-from-yolosclsyoloclassifier","title":"Protected Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name void initSession (const std::string &amp; modelPath, bool useGPU)  ClassificationResult postprocess (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Postprocess classification output. void preprocess (const cv::Mat &amp; image, std::vector&lt; int64_t &gt; &amp; inputTensorShape) Preprocess image for classification (Ultralytics-style)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLO11Classifier/#function-yolo11classifier","title":"function YOLO11Classifier","text":"<pre><code>inline yolos::cls::YOLO11Classifier::YOLO11Classifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/","title":"Class yolos::cls::YOLO12Classifier","text":"<p>ClassList &gt; yolos &gt; cls &gt; YOLO12Classifier</p> <p>YOLOv12 classifier. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::cls::YOLOClassifier</p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#public-functions","title":"Public Functions","text":"Type Name YOLO12Classifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#public-functions-inherited-from-yolosclsyoloclassifier","title":"Public Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name YOLOClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, const cv::Size &amp; targetInputShape=cv::Size(224, 224)) Constructor. ClassificationResult classify (const cv::Mat &amp; image) Run classification on an image. void drawResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30)) constDraw classification result on an image. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. cv::Size getInputShape () constGet input shape. bool isDynamicInputShape () constCheck if input shape is dynamic. virtual ~YOLOClassifier () = default"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#protected-attributes-inherited-from-yolosclsyoloclassifier","title":"Protected Attributes inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name std::vector&lt; std::string &gt; classNames_ Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; float &gt; inputBuffer_ cv::Size inputImageShape_ std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ bool isDynamicInputShape_   = <code>{false}</code> int numClasses_   = <code>{0}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#protected-functions-inherited-from-yolosclsyoloclassifier","title":"Protected Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name void initSession (const std::string &amp; modelPath, bool useGPU)  ClassificationResult postprocess (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Postprocess classification output. void preprocess (const cv::Mat &amp; image, std::vector&lt; int64_t &gt; &amp; inputTensorShape) Preprocess image for classification (Ultralytics-style)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLO12Classifier/#function-yolo12classifier","title":"function YOLO12Classifier","text":"<pre><code>inline yolos::cls::YOLO12Classifier::YOLO12Classifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/","title":"Class yolos::cls::YOLO26Classifier","text":"<p>ClassList &gt; yolos &gt; cls &gt; YOLO26Classifier</p> <p>YOLO26 classifier. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::cls::YOLOClassifier</p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#public-functions","title":"Public Functions","text":"Type Name YOLO26Classifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#public-functions-inherited-from-yolosclsyoloclassifier","title":"Public Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name YOLOClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, const cv::Size &amp; targetInputShape=cv::Size(224, 224)) Constructor. ClassificationResult classify (const cv::Mat &amp; image) Run classification on an image. void drawResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30)) constDraw classification result on an image. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. cv::Size getInputShape () constGet input shape. bool isDynamicInputShape () constCheck if input shape is dynamic. virtual ~YOLOClassifier () = default"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#protected-attributes-inherited-from-yolosclsyoloclassifier","title":"Protected Attributes inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name std::vector&lt; std::string &gt; classNames_ Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; float &gt; inputBuffer_ cv::Size inputImageShape_ std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ bool isDynamicInputShape_   = <code>{false}</code> int numClasses_   = <code>{0}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#protected-functions-inherited-from-yolosclsyoloclassifier","title":"Protected Functions inherited from yolos::cls::YOLOClassifier","text":"<p>See yolos::cls::YOLOClassifier</p> Type Name void initSession (const std::string &amp; modelPath, bool useGPU)  ClassificationResult postprocess (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Postprocess classification output. void preprocess (const cv::Mat &amp; image, std::vector&lt; int64_t &gt; &amp; inputTensorShape) Preprocess image for classification (Ultralytics-style)"},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLO26Classifier/#function-yolo26classifier","title":"function YOLO26Classifier","text":"<pre><code>inline yolos::cls::YOLO26Classifier::YOLO26Classifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/","title":"Class yolos::cls::YOLOClassifier","text":"<p>ClassList &gt; yolos &gt; cls &gt; YOLOClassifier</p> <p>YOLO classifier for image classification. </p> <ul> <li><code>#include &lt;classification.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: yolos::cls::YOLO11Classifier,  yolos::cls::YOLO12Classifier,  yolos::cls::YOLO26Classifier</p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#public-functions","title":"Public Functions","text":"Type Name YOLOClassifier (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, const cv::Size &amp; targetInputShape=cv::Size(224, 224)) Constructor. ClassificationResult classify (const cv::Mat &amp; image) Run classification on an image. void drawResult (cv::Mat &amp; image, const ClassificationResult &amp; result, const cv::Point &amp; position=cv::Point(10, 30)) constDraw classification result on an image. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. cv::Size getInputShape () constGet input shape. bool isDynamicInputShape () constCheck if input shape is dynamic. virtual ~YOLOClassifier () = default"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#protected-attributes","title":"Protected Attributes","text":"Type Name std::vector&lt; std::string &gt; classNames_ Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; float &gt; inputBuffer_ cv::Size inputImageShape_ std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ bool isDynamicInputShape_   = <code>{false}</code> int numClasses_   = <code>{0}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#protected-functions","title":"Protected Functions","text":"Type Name void initSession (const std::string &amp; modelPath, bool useGPU)  ClassificationResult postprocess (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Postprocess classification output. void preprocess (const cv::Mat &amp; image, std::vector&lt; int64_t &gt; &amp; inputTensorShape) Preprocess image for classification (Ultralytics-style)"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-yoloclassifier","title":"function YOLOClassifier","text":"<p>Constructor. </p> <pre><code>inline yolos::cls::YOLOClassifier::YOLOClassifier (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false,\n    const cv::Size &amp; targetInputShape=cv::Size(224, 224)\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> <li><code>targetInputShape</code> Target input shape for preprocessing </li> </ul>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-classify","title":"function classify","text":"<p>Run classification on an image. </p> <pre><code>inline ClassificationResult yolos::cls::YOLOClassifier::classify (\n    const cv::Mat &amp; image\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> </ul> <p>Returns:</p> <p>Classification result </p>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-drawresult","title":"function drawResult","text":"<p>Draw classification result on an image. </p> <pre><code>inline void yolos::cls::YOLOClassifier::drawResult (\n    cv::Mat &amp; image,\n    const ClassificationResult &amp; result,\n    const cv::Point &amp; position=cv::Point(10, 30)\n) const\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::cls::YOLOClassifier::getClassNames () const\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-getinputshape","title":"function getInputShape","text":"<p>Get input shape. </p> <pre><code>inline cv::Size yolos::cls::YOLOClassifier::getInputShape () const\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-isdynamicinputshape","title":"function isDynamicInputShape","text":"<p>Check if input shape is dynamic. </p> <pre><code>inline bool yolos::cls::YOLOClassifier::isDynamicInputShape () const\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-yoloclassifier_1","title":"function ~YOLOClassifier","text":"<pre><code>virtual yolos::cls::YOLOClassifier::~YOLOClassifier () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::cls::YOLOClassifier::classNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-env_","title":"variable env_","text":"<pre><code>Ort::Env yolos::cls::YOLOClassifier::env_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-inputbuffer_","title":"variable inputBuffer_","text":"<pre><code>std::vector&lt;float&gt; yolos::cls::YOLOClassifier::inputBuffer_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-inputimageshape_","title":"variable inputImageShape_","text":"<pre><code>cv::Size yolos::cls::YOLOClassifier::inputImageShape_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-inputnameallocs_","title":"variable inputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::cls::YOLOClassifier::inputNameAllocs_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-inputnames_","title":"variable inputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::cls::YOLOClassifier::inputNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-isdynamicinputshape_","title":"variable isDynamicInputShape_","text":"<pre><code>bool yolos::cls::YOLOClassifier::isDynamicInputShape_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-numclasses_","title":"variable numClasses_","text":"<pre><code>int yolos::cls::YOLOClassifier::numClasses_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-numinputnodes_","title":"variable numInputNodes_","text":"<pre><code>size_t yolos::cls::YOLOClassifier::numInputNodes_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-numoutputnodes_","title":"variable numOutputNodes_","text":"<pre><code>size_t yolos::cls::YOLOClassifier::numOutputNodes_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-outputnameallocs_","title":"variable outputNameAllocs_","text":"<pre><code>std::vector&lt;Ort::AllocatedStringPtr&gt; yolos::cls::YOLOClassifier::outputNameAllocs_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-outputnames_","title":"variable outputNames_","text":"<pre><code>std::vector&lt;const char*&gt; yolos::cls::YOLOClassifier::outputNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-sessionoptions_","title":"variable sessionOptions_","text":"<pre><code>Ort::SessionOptions yolos::cls::YOLOClassifier::sessionOptions_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#variable-session_","title":"variable session_","text":"<pre><code>Ort::Session yolos::cls::YOLOClassifier::session_;\n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-initsession","title":"function initSession","text":"<pre><code>inline void yolos::cls::YOLOClassifier::initSession (\n    const std::string &amp; modelPath,\n    bool useGPU\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-postprocess","title":"function postprocess","text":"<p>Postprocess classification output. </p> <pre><code>inline ClassificationResult yolos::cls::YOLOClassifier::postprocess (\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1cls_1_1YOLOClassifier/#function-preprocess","title":"function preprocess","text":"<p>Preprocess image for classification (Ultralytics-style) </p> <pre><code>inline void yolos::cls::YOLOClassifier::preprocess (\n    const cv::Mat &amp; image,\n    std::vector&lt; int64_t &gt; &amp; inputTensorShape\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1det/","title":"Namespace yolos::det","text":"<p>Namespace List &gt; yolos &gt; det</p>"},{"location":"yolos/namespaceyolos_1_1det/#classes","title":"Classes","text":"Type Name struct Detection Detection result containing bounding box, confidence, and class ID. class YOLO26Detector YOLOv26 detector (forces V26 end-to-end postprocessing) class YOLODetector Base YOLO detector with runtime version auto-detection. class YOLONASDetector YOLO-NAS detector (forces NAS postprocessing) class YOLOv10Detector YOLOv10 detector (forces V10 end-to-end postprocessing) class YOLOv11Detector YOLOv11 detector (forces standard postprocessing) class YOLOv7Detector YOLOv7 detector (forces V7 postprocessing) class YOLOv8Detector YOLOv8 detector (forces standard postprocessing)"},{"location":"yolos/namespaceyolos_1_1det/#public-functions","title":"Public Functions","text":"Type Name std::unique_ptr&lt; YOLODetector &gt; createDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, YOLOVersion version=YOLOVersion::Auto, bool useGPU=false) Create a detector with explicit version selection."},{"location":"yolos/namespaceyolos_1_1det/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1det/#function-createdetector","title":"function createDetector","text":"<p>Create a detector with explicit version selection. </p> <pre><code>inline std::unique_ptr&lt; YOLODetector &gt; yolos::det::createDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    YOLOVersion version=YOLOVersion::Auto,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>version</code> YOLO version (Auto for runtime detection) </li> <li><code>useGPU</code> Whether to use GPU </li> </ul> <p>Returns:</p> <p>Unique pointer to detector </p> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/structyolos_1_1det_1_1Detection/","title":"Struct yolos::det::Detection","text":"<p>ClassList &gt; yolos &gt; det &gt; Detection</p> <p>Detection result containing bounding box, confidence, and class ID.</p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1det_1_1Detection/#public-attributes","title":"Public Attributes","text":"Type Name BoundingBox box Axis-aligned bounding box. int classId   = <code>{-1}</code>Class ID. float conf   = <code>{0.0f}</code>Confidence score."},{"location":"yolos/structyolos_1_1det_1_1Detection/#public-functions","title":"Public Functions","text":"Type Name Detection () = default Detection (const BoundingBox &amp; box_, float conf_, int classId_)"},{"location":"yolos/structyolos_1_1det_1_1Detection/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1det_1_1Detection/#variable-box","title":"variable box","text":"<p>Axis-aligned bounding box. </p> <pre><code>BoundingBox yolos::det::Detection::box;\n</code></pre>"},{"location":"yolos/structyolos_1_1det_1_1Detection/#variable-classid","title":"variable classId","text":"<p>Class ID. </p> <pre><code>int yolos::det::Detection::classId;\n</code></pre>"},{"location":"yolos/structyolos_1_1det_1_1Detection/#variable-conf","title":"variable conf","text":"<p>Confidence score. </p> <pre><code>float yolos::det::Detection::conf;\n</code></pre>"},{"location":"yolos/structyolos_1_1det_1_1Detection/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1det_1_1Detection/#function-detection-12","title":"function Detection [1/2]","text":"<pre><code>yolos::det::Detection::Detection () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1det_1_1Detection/#function-detection-22","title":"function Detection [2/2]","text":"<pre><code>inline yolos::det::Detection::Detection (\n    const BoundingBox &amp; box_,\n    float conf_,\n    int classId_\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/","title":"Class yolos::det::YOLO26Detector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLO26Detector</p> <p>YOLOv26 detector (forces V26 end-to-end postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#public-functions","title":"Public Functions","text":"Type Name YOLO26Detector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLO26Detector/#function-yolo26detector","title":"function YOLO26Detector","text":"<pre><code>inline yolos::det::YOLO26Detector::YOLO26Detector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/","title":"Class yolos::det::YOLODetector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLODetector</p> <p>Base YOLO detector with runtime version auto-detection. </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p> <p>Inherited by the following classes: yolos::det::YOLO26Detector,  yolos::det::YOLONASDetector,  yolos::det::YOLOv10Detector,  yolos::det::YOLOv11Detector,  yolos::det::YOLOv7Detector,  yolos::det::YOLOv8Detector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#public-functions","title":"Public Functions","text":"Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-attributes","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-functions","title":"Protected Functions","text":"Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-yolodetector","title":"function YOLODetector","text":"<p>Constructor. </p> <pre><code>inline yolos::det::YOLODetector::YOLODetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false,\n    YOLOVersion version=YOLOVersion::Auto\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> <li><code>version</code> YOLO version (Auto for runtime detection) </li> </ul>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-detect","title":"function detect","text":"<p>Run detection on an image (optimized with buffer reuse) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.45f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of detections </p>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-drawdetections","title":"function drawDetections","text":"<p>Draw detections on an image. </p> <pre><code>inline void yolos::det::YOLODetector::drawDetections (\n    cv::Mat &amp; image,\n    const std::vector&lt; Detection &gt; &amp; detections\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>detections</code> Vector of detections </li> </ul>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-drawdetectionswithmask","title":"function drawDetectionsWithMask","text":"<p>Draw detections with semi-transparent mask fill. </p> <pre><code>inline void yolos::det::YOLODetector::drawDetectionsWithMask (\n    cv::Mat &amp; image,\n    const std::vector&lt; Detection &gt; &amp; detections,\n    float alpha=0.4f\n) const\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-getclasscolors","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::det::YOLODetector::getClassColors () const\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::det::YOLODetector::getClassNames () const\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-yolodetector_1","title":"function ~YOLODetector","text":"<pre><code>virtual yolos::det::YOLODetector::~YOLODetector () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#variable-buffer_","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::det::YOLODetector::buffer_;\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#variable-classcolors_","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::det::YOLODetector::classColors_;\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::det::YOLODetector::classNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#variable-version_","title":"variable version_","text":"<pre><code>YOLOVersion yolos::det::YOLODetector::version_;\n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-detectversion","title":"function detectVersion","text":"<p>Detect YOLO version from output tensors. </p> <pre><code>inline YOLOVersion yolos::det::YOLODetector::detectVersion (\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-postprocess","title":"function postprocess","text":"<p>Postprocess based on detected version. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    YOLOVersion version,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-postprocessnas","title":"function postprocessNAS","text":"<p>Postprocess for YOLO-NAS format (two outputs: boxes and scores) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessNAS (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-postprocessstandard","title":"function postprocessStandard","text":"<p>Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessStandard (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-postprocessv10","title":"function postprocessV10","text":"<p>Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessV10 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1det_1_1YOLODetector/#function-postprocessv7","title":"function postprocessV7","text":"<p>Postprocess for YOLOv7 format [batch, boxes, features]. </p> <pre><code>inline virtual std::vector&lt; Detection &gt; yolos::det::YOLODetector::postprocessV7 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/","title":"Class yolos::det::YOLONASDetector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLONASDetector</p> <p>YOLO-NAS detector (forces NAS postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#public-functions","title":"Public Functions","text":"Type Name YOLONASDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLONASDetector/#function-yolonasdetector","title":"function YOLONASDetector","text":"<pre><code>inline yolos::det::YOLONASDetector::YOLONASDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/","title":"Class yolos::det::YOLOv10Detector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLOv10Detector</p> <p>YOLOv10 detector (forces V10 end-to-end postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#public-functions","title":"Public Functions","text":"Type Name YOLOv10Detector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLOv10Detector/#function-yolov10detector","title":"function YOLOv10Detector","text":"<pre><code>inline yolos::det::YOLOv10Detector::YOLOv10Detector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/","title":"Class yolos::det::YOLOv11Detector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLOv11Detector</p> <p>YOLOv11 detector (forces standard postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#public-functions","title":"Public Functions","text":"Type Name YOLOv11Detector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLOv11Detector/#function-yolov11detector","title":"function YOLOv11Detector","text":"<pre><code>inline yolos::det::YOLOv11Detector::YOLOv11Detector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/","title":"Class yolos::det::YOLOv7Detector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLOv7Detector</p> <p>YOLOv7 detector (forces V7 postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#public-functions","title":"Public Functions","text":"Type Name YOLOv7Detector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLOv7Detector/#function-yolov7detector","title":"function YOLOv7Detector","text":"<pre><code>inline yolos::det::YOLOv7Detector::YOLOv7Detector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/","title":"Class yolos::det::YOLOv8Detector","text":"<p>ClassList &gt; yolos &gt; det &gt; YOLOv8Detector</p> <p>YOLOv8 detector (forces standard postprocessing) </p> <ul> <li><code>#include &lt;detection.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::det::YOLODetector</p>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#public-functions","title":"Public Functions","text":"Type Name YOLOv8Detector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false)"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#public-functions-inherited-from-yolosdetyolodetector","title":"Public Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLODetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false, YOLOVersion version=YOLOVersion::Auto) Constructor. virtual std::vector&lt; Detection &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections) constDraw detections on an image. void drawDetectionsWithMask (cv::Mat &amp; image, const std::vector&lt; Detection &gt; &amp; detections, float alpha=0.4f) constDraw detections with semi-transparent mask fill. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLODetector () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#protected-attributes-inherited-from-yolosdetyolodetector","title":"Protected Attributes inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_ YOLOVersion version_   = <code>{YOLOVersion::Auto}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#protected-functions-inherited-from-yolosdetyolodetector","title":"Protected Functions inherited from yolos::det::YOLODetector","text":"<p>See yolos::det::YOLODetector</p> Type Name YOLOVersion detectVersion (const std::vector&lt; Ort::Value &gt; &amp; outputTensors) Detect YOLO version from output tensors. virtual std::vector&lt; Detection &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, YOLOVersion version, float confThreshold, float iouThreshold) Postprocess based on detected version. virtual std::vector&lt; Detection &gt; postprocessNAS (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLO-NAS format (two outputs: boxes and scores) virtual std::vector&lt; Detection &gt; postprocessStandard (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Standard postprocess for YOLOv8/v11 format [batch, features, boxes] Optimized: single box storage with batched NMS. virtual std::vector&lt; Detection &gt; postprocessV10 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float) Postprocess for YOLOv10 format [batch, boxes, 6] (end-to-end, no NMS needed) virtual std::vector&lt; Detection &gt; postprocessV7 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess for YOLOv7 format [batch, boxes, features]."},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1det_1_1YOLOv8Detector/#function-yolov8detector","title":"function YOLOv8Detector","text":"<pre><code>inline yolos::det::YOLOv8Detector::YOLOv8Detector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1drawing/","title":"Namespace yolos::drawing","text":"<p>Namespace List &gt; yolos &gt; drawing</p>"},{"location":"yolos/namespaceyolos_1_1drawing/#public-functions","title":"Public Functions","text":"Type Name void drawBoundingBox (cv::Mat &amp; image, const BoundingBox &amp; box, const std::string &amp; label, const cv::Scalar &amp; color, int thickness=2) Draw a single bounding box with label on an image. void drawBoundingBoxWithMask (cv::Mat &amp; image, const BoundingBox &amp; box, const std::string &amp; label, const cv::Scalar &amp; color, float maskAlpha=0.4f) Draw a bounding box with semi-transparent mask fill. void drawOrientedBoundingBox (cv::Mat &amp; image, const OrientedBoundingBox &amp; obb, const std::string &amp; label, const cv::Scalar &amp; color, int thickness=2) Draw an oriented bounding box on an image. void drawPoseSkeleton (cv::Mat &amp; image, const std::vector&lt; KeyPoint &gt; &amp; keypoints, const std::vector&lt; std::pair&lt; int, int &gt;&gt; &amp; skeleton, int kptRadius=4, float kptThreshold=0.5f, int lineThickness=2) Draw pose keypoints and skeleton on an image. void drawSegmentationMask (cv::Mat &amp; image, const cv::Mat &amp; mask, const cv::Scalar &amp; color, float alpha=0.5f) Draw a segmentation mask on an image. std::vector&lt; cv::Scalar &gt; generateColors (const std::vector&lt; std::string &gt; &amp; classNames, int seed=42) Generate consistent random colors for each class. const std::vector&lt; cv::Scalar &gt; &amp; getPosePalette () Get the Ultralytics pose palette colors."},{"location":"yolos/namespaceyolos_1_1drawing/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1drawing/#function-drawboundingbox","title":"function drawBoundingBox","text":"<p>Draw a single bounding box with label on an image. </p> <pre><code>inline void yolos::drawing::drawBoundingBox (\n    cv::Mat &amp; image,\n    const BoundingBox &amp; box,\n    const std::string &amp; label,\n    const cv::Scalar &amp; color,\n    int thickness=2\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>box</code> Bounding box </li> <li><code>label</code> Text label </li> <li><code>color</code> Box color </li> <li><code>thickness</code> Line thickness </li> </ul>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-drawboundingboxwithmask","title":"function drawBoundingBoxWithMask","text":"<p>Draw a bounding box with semi-transparent mask fill. </p> <pre><code>inline void yolos::drawing::drawBoundingBoxWithMask (\n    cv::Mat &amp; image,\n    const BoundingBox &amp; box,\n    const std::string &amp; label,\n    const cv::Scalar &amp; color,\n    float maskAlpha=0.4f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>box</code> Bounding box </li> <li><code>label</code> Text label </li> <li><code>color</code> Box color </li> <li><code>maskAlpha</code> Transparency of the mask fill (0-1) </li> </ul>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-draworientedboundingbox","title":"function drawOrientedBoundingBox","text":"<p>Draw an oriented bounding box on an image. </p> <pre><code>inline void yolos::drawing::drawOrientedBoundingBox (\n    cv::Mat &amp; image,\n    const OrientedBoundingBox &amp; obb,\n    const std::string &amp; label,\n    const cv::Scalar &amp; color,\n    int thickness=2\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>obb</code> Oriented bounding box </li> <li><code>label</code> Text label </li> <li><code>color</code> Box color </li> <li><code>thickness</code> Line thickness </li> </ul>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-drawposeskeleton","title":"function drawPoseSkeleton","text":"<p>Draw pose keypoints and skeleton on an image. </p> <pre><code>inline void yolos::drawing::drawPoseSkeleton (\n    cv::Mat &amp; image,\n    const std::vector&lt; KeyPoint &gt; &amp; keypoints,\n    const std::vector&lt; std::pair&lt; int, int &gt;&gt; &amp; skeleton,\n    int kptRadius=4,\n    float kptThreshold=0.5f,\n    int lineThickness=2\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>keypoints</code> Vector of keypoints </li> <li><code>skeleton</code> Skeleton connections </li> <li><code>kptRadius</code> Keypoint circle radius </li> <li><code>kptThreshold</code> Minimum confidence to draw keypoint </li> <li><code>lineThickness</code> Skeleton line thickness </li> </ul>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-drawsegmentationmask","title":"function drawSegmentationMask","text":"<p>Draw a segmentation mask on an image. </p> <pre><code>inline void yolos::drawing::drawSegmentationMask (\n    cv::Mat &amp; image,\n    const cv::Mat &amp; mask,\n    const cv::Scalar &amp; color,\n    float alpha=0.5f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>mask</code> Binary mask (CV_8UC1) </li> <li><code>color</code> Mask color </li> <li><code>alpha</code> Mask transparency (0-1) </li> </ul>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-generatecolors","title":"function generateColors","text":"<p>Generate consistent random colors for each class. </p> <pre><code>inline std::vector&lt; cv::Scalar &gt; yolos::drawing::generateColors (\n    const std::vector&lt; std::string &gt; &amp; classNames,\n    int seed=42\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>classNames</code> Vector of class names </li> <li><code>seed</code> Random seed for reproducibility </li> </ul> <p>Returns:</p> <p>Vector of BGR colors </p>"},{"location":"yolos/namespaceyolos_1_1drawing/#function-getposepalette","title":"function getPosePalette","text":"<p>Get the Ultralytics pose palette colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::drawing::getPosePalette () \n</code></pre> <p>Returns:</p> <p>Vector of BGR colors for pose visualization </p> <p>The documentation for this class was generated from the following file <code>include/yolos/core/drawing.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1nms/","title":"Namespace yolos::nms","text":"<p>Namespace List &gt; yolos &gt; nms</p>"},{"location":"yolos/namespaceyolos_1_1nms/#public-functions","title":"Public Functions","text":"Type Name void NMSBoxes (const std::vector&lt; BoundingBox &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, float scoreThreshold, float nmsThreshold, std::vector&lt; int &gt; &amp; indices) Perform Non-Maximum Suppression on bounding boxes. void NMSBoxesBatched (const std::vector&lt; BoundingBox &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, const std::vector&lt; int &gt; &amp; classIds, float scoreThreshold, float nmsThreshold, std::vector&lt; int &gt; &amp; indices) Perform class-aware NMS by offsetting boxes by class ID. void NMSBoxesF (const std::vector&lt; cv::Rect2f &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, float scoreThreshold, float nmsThreshold, std::vector&lt; int &gt; &amp; indices) Perform NMS on float-precision bounding boxes (for letterbox space) void NMSBoxesFBatched (const std::vector&lt; cv::Rect2f &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, const std::vector&lt; int &gt; &amp; classIds, float scoreThreshold, float nmsThreshold, std::vector&lt; int &gt; &amp; indices) Perform class-aware NMS on float-precision boxes. std::vector&lt; int &gt; NMSRotated (const std::vector&lt; OrientedBoundingBox &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, float nmsThreshold=0.45f, int maxDet=300) Perform NMS on oriented bounding boxes using rotated IoU. std::vector&lt; int &gt; NMSRotatedBatched (const std::vector&lt; OrientedBoundingBox &gt; &amp; boxes, const std::vector&lt; float &gt; &amp; scores, const std::vector&lt; int &gt; &amp; classIds, float nmsThreshold=0.45f, int maxDet=300) Perform class-aware NMS on oriented bounding boxes. float computeRotatedIoU (const OrientedBoundingBox &amp; box1, const OrientedBoundingBox &amp; box2) Compute IoU between two oriented bounding boxes using OpenCV."},{"location":"yolos/namespaceyolos_1_1nms/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsboxes","title":"function NMSBoxes","text":"<p>Perform Non-Maximum Suppression on bounding boxes. </p> <pre><code>inline void yolos::nms::NMSBoxes (\n    const std::vector&lt; BoundingBox &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    float scoreThreshold,\n    float nmsThreshold,\n    std::vector&lt; int &gt; &amp; indices\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>boxes</code> Vector of bounding boxes </li> <li><code>scores</code> Vector of confidence scores </li> <li><code>scoreThreshold</code> Minimum score to consider </li> <li><code>nmsThreshold</code> IoU threshold for suppression </li> <li><code>indices</code> Output indices of boxes that survived NMS </li> </ul>"},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsboxesbatched","title":"function NMSBoxesBatched","text":"<p>Perform class-aware NMS by offsetting boxes by class ID. </p> <pre><code>inline void yolos::nms::NMSBoxesBatched (\n    const std::vector&lt; BoundingBox &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    const std::vector&lt; int &gt; &amp; classIds,\n    float scoreThreshold,\n    float nmsThreshold,\n    std::vector&lt; int &gt; &amp; indices\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>boxes</code> Vector of bounding boxes </li> <li><code>scores</code> Vector of confidence scores </li> <li><code>classIds</code> Vector of class IDs </li> <li><code>scoreThreshold</code> Minimum score to consider </li> <li><code>nmsThreshold</code> IoU threshold for suppression </li> <li><code>indices</code> Output indices of boxes that survived NMS </li> </ul>"},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsboxesf","title":"function NMSBoxesF","text":"<p>Perform NMS on float-precision bounding boxes (for letterbox space) </p> <pre><code>inline void yolos::nms::NMSBoxesF (\n    const std::vector&lt; cv::Rect2f &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    float scoreThreshold,\n    float nmsThreshold,\n    std::vector&lt; int &gt; &amp; indices\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>boxes</code> Vector of cv::Rect2f boxes </li> <li><code>scores</code> Vector of confidence scores </li> <li><code>scoreThreshold</code> Minimum score to consider </li> <li><code>nmsThreshold</code> IoU threshold for suppression </li> <li><code>indices</code> Output indices of boxes that survived NMS </li> </ul>"},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsboxesfbatched","title":"function NMSBoxesFBatched","text":"<p>Perform class-aware NMS on float-precision boxes. </p> <pre><code>inline void yolos::nms::NMSBoxesFBatched (\n    const std::vector&lt; cv::Rect2f &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    const std::vector&lt; int &gt; &amp; classIds,\n    float scoreThreshold,\n    float nmsThreshold,\n    std::vector&lt; int &gt; &amp; indices\n) \n</code></pre>"},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsrotated","title":"function NMSRotated","text":"<p>Perform NMS on oriented bounding boxes using rotated IoU. </p> <pre><code>inline std::vector&lt; int &gt; yolos::nms::NMSRotated (\n    const std::vector&lt; OrientedBoundingBox &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    float nmsThreshold=0.45f,\n    int maxDet=300\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>boxes</code> Vector of oriented bounding boxes </li> <li><code>scores</code> Vector of confidence scores </li> <li><code>nmsThreshold</code> IoU threshold for suppression </li> <li><code>maxDet</code> Maximum number of detections to keep </li> </ul> <p>Returns:</p> <p>Indices of boxes that survived NMS </p>"},{"location":"yolos/namespaceyolos_1_1nms/#function-nmsrotatedbatched","title":"function NMSRotatedBatched","text":"<p>Perform class-aware NMS on oriented bounding boxes. </p> <pre><code>inline std::vector&lt; int &gt; yolos::nms::NMSRotatedBatched (\n    const std::vector&lt; OrientedBoundingBox &gt; &amp; boxes,\n    const std::vector&lt; float &gt; &amp; scores,\n    const std::vector&lt; int &gt; &amp; classIds,\n    float nmsThreshold=0.45f,\n    int maxDet=300\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>boxes</code> Vector of oriented bounding boxes </li> <li><code>scores</code> Vector of confidence scores </li> <li><code>classIds</code> Vector of class IDs </li> <li><code>nmsThreshold</code> IoU threshold for suppression </li> <li><code>maxDet</code> Maximum number of detections to keep </li> </ul> <p>Returns:</p> <p>Indices of boxes that survived NMS </p>"},{"location":"yolos/namespaceyolos_1_1nms/#function-computerotatediou","title":"function computeRotatedIoU","text":"<p>Compute IoU between two oriented bounding boxes using OpenCV. </p> <pre><code>inline float yolos::nms::computeRotatedIoU (\n    const OrientedBoundingBox &amp; box1,\n    const OrientedBoundingBox &amp; box2\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>box1</code> First oriented bounding box </li> <li><code>box2</code> Second oriented bounding box </li> </ul> <p>Returns:</p> <p>IoU value between 0 and 1 </p> <p>The documentation for this class was generated from the following file <code>include/yolos/core/nms.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1obb/","title":"Namespace yolos::obb","text":"<p>Namespace List &gt; yolos &gt; obb</p>"},{"location":"yolos/namespaceyolos_1_1obb/#classes","title":"Classes","text":"Type Name struct OBBResult OBB detection result containing oriented bounding box, confidence, and class ID. class YOLOOBBDetector YOLO oriented bounding box detector for rotated object detection. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/obb.hpp</code></p>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/","title":"Struct yolos::obb::OBBResult","text":"<p>ClassList &gt; yolos &gt; obb &gt; OBBResult</p> <p>OBB detection result containing oriented bounding box, confidence, and class ID. </p> <ul> <li><code>#include &lt;obb.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#public-attributes","title":"Public Attributes","text":"Type Name OrientedBoundingBox box Oriented bounding box (center-based with angle) int classId   = <code>{-1}</code>Class ID. float conf   = <code>{0.0f}</code>Confidence score."},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#public-functions","title":"Public Functions","text":"Type Name OBBResult () = default OBBResult (const OrientedBoundingBox &amp; box_, float conf_, int classId_)"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#variable-box","title":"variable box","text":"<p>Oriented bounding box (center-based with angle) </p> <pre><code>OrientedBoundingBox yolos::obb::OBBResult::box;\n</code></pre>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#variable-classid","title":"variable classId","text":"<p>Class ID. </p> <pre><code>int yolos::obb::OBBResult::classId;\n</code></pre>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#variable-conf","title":"variable conf","text":"<p>Confidence score. </p> <pre><code>float yolos::obb::OBBResult::conf;\n</code></pre>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#function-obbresult-12","title":"function OBBResult [1/2]","text":"<pre><code>yolos::obb::OBBResult::OBBResult () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1obb_1_1OBBResult/#function-obbresult-22","title":"function OBBResult [2/2]","text":"<pre><code>inline yolos::obb::OBBResult::OBBResult (\n    const OrientedBoundingBox &amp; box_,\n    float conf_,\n    int classId_\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/obb.hpp</code></p>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/","title":"Class yolos::obb::YOLOOBBDetector","text":"<p>ClassList &gt; yolos &gt; obb &gt; YOLOOBBDetector</p> <p>YOLO oriented bounding box detector for rotated object detection. </p> <ul> <li><code>#include &lt;obb.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#public-functions","title":"Public Functions","text":"Type Name YOLOOBBDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false) Constructor. std::vector&lt; OBBResult &gt; detect (const cv::Mat &amp; image, float confThreshold=0.25f, float iouThreshold=0.45f, int maxDet=300) Run OBB detection on an image (optimized with buffer reuse) void drawDetections (cv::Mat &amp; image, const std::vector&lt; OBBResult &gt; &amp; results, int thickness=2) constDraw OBB detections on an image. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLOOBBDetector () = default"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-attributes","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-functions","title":"Protected Functions","text":"Type Name std::vector&lt; OBBResult &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold, int maxDet) Postprocess OBB detection outputs. std::vector&lt; OBBResult &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, int maxDet) Postprocess YOLO26 OBB detection outputs (end-to-end, NMS-free) std::vector&lt; OBBResult &gt; postprocessV8 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, float iouThreshold, int maxDet) Postprocess YOLOv8/v11 OBB detection outputs (requires NMS)"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-yoloobbdetector","title":"function YOLOOBBDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::obb::YOLOOBBDetector::YOLOOBBDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-detect","title":"function detect","text":"<p>Run OBB detection on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.25f,\n    float iouThreshold=0.45f,\n    int maxDet=300\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> <li><code>maxDet</code> Maximum number of detections to return </li> </ul> <p>Returns:</p> <p>Vector of OBB detection results </p>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-drawdetections","title":"function drawDetections","text":"<p>Draw OBB detections on an image. </p> <pre><code>inline void yolos::obb::YOLOOBBDetector::drawDetections (\n    cv::Mat &amp; image,\n    const std::vector&lt; OBBResult &gt; &amp; results,\n    int thickness=2\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of OBB detection results </li> <li><code>thickness</code> Line thickness </li> </ul>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-getclasscolors","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::obb::YOLOOBBDetector::getClassColors () const\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::obb::YOLOOBBDetector::getClassNames () const\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-yoloobbdetector_1","title":"function ~YOLOOBBDetector","text":"<pre><code>virtual yolos::obb::YOLOOBBDetector::~YOLOOBBDetector () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#variable-buffer_","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::obb::YOLOOBBDetector::buffer_;\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#variable-classcolors_","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::obb::YOLOOBBDetector::classColors_;\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::obb::YOLOOBBDetector::classNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-postprocess","title":"function postprocess","text":"<p>Postprocess OBB detection outputs. </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold,\n    int maxDet\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-postprocessv26","title":"function postprocessV26","text":"<p>Postprocess YOLO26 OBB detection outputs (end-to-end, NMS-free) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    int maxDet\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1obb_1_1YOLOOBBDetector/#function-postprocessv8","title":"function postprocessV8","text":"<p>Postprocess YOLOv8/v11 OBB detection outputs (requires NMS) </p> <pre><code>inline std::vector&lt; OBBResult &gt; yolos::obb::YOLOOBBDetector::postprocessV8 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    float iouThreshold,\n    int maxDet\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/obb.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1pose/","title":"Namespace yolos::pose","text":"<p>Namespace List &gt; yolos &gt; pose</p>"},{"location":"yolos/namespaceyolos_1_1pose/#classes","title":"Classes","text":"Type Name struct PoseResult Pose estimation result containing bounding box, confidence, and keypoints. class YOLOPoseDetector YOLO pose estimation detector with keypoint detection. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/pose.hpp</code></p>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/","title":"Struct yolos::pose::PoseResult","text":"<p>ClassList &gt; yolos &gt; pose &gt; PoseResult</p> <p>Pose estimation result containing bounding box, confidence, and keypoints. </p> <ul> <li><code>#include &lt;pose.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#public-attributes","title":"Public Attributes","text":"Type Name BoundingBox box Bounding box around the person. int classId   = <code>{0}</code>Class ID (typically 0 for person) float conf   = <code>{0.0f}</code>Detection confidence. std::vector&lt; KeyPoint &gt; keypoints Detected keypoints (17 for COCO format)"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#public-functions","title":"Public Functions","text":"Type Name PoseResult () = default PoseResult (const BoundingBox &amp; box_, float conf_, int classId_, const std::vector&lt; KeyPoint &gt; &amp; kpts)"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#variable-box","title":"variable box","text":"<p>Bounding box around the person. </p> <pre><code>BoundingBox yolos::pose::PoseResult::box;\n</code></pre>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#variable-classid","title":"variable classId","text":"<p>Class ID (typically 0 for person) </p> <pre><code>int yolos::pose::PoseResult::classId;\n</code></pre>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#variable-conf","title":"variable conf","text":"<p>Detection confidence. </p> <pre><code>float yolos::pose::PoseResult::conf;\n</code></pre>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#variable-keypoints","title":"variable keypoints","text":"<p>Detected keypoints (17 for COCO format) </p> <pre><code>std::vector&lt;KeyPoint&gt; yolos::pose::PoseResult::keypoints;\n</code></pre>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#function-poseresult-12","title":"function PoseResult [1/2]","text":"<pre><code>yolos::pose::PoseResult::PoseResult () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1pose_1_1PoseResult/#function-poseresult-22","title":"function PoseResult [2/2]","text":"<pre><code>inline yolos::pose::PoseResult::PoseResult (\n    const BoundingBox &amp; box_,\n    float conf_,\n    int classId_,\n    const std::vector&lt; KeyPoint &gt; &amp; kpts\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/pose.hpp</code></p>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/","title":"Class yolos::pose::YOLOPoseDetector","text":"<p>ClassList &gt; yolos &gt; pose &gt; YOLOPoseDetector</p> <p>YOLO pose estimation detector with keypoint detection. </p> <ul> <li><code>#include &lt;pose.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#public-functions","title":"Public Functions","text":"Type Name YOLOPoseDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath=\"\", bool useGPU=false) Constructor. std::vector&lt; PoseResult &gt; detect (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.5f) Run pose detection on an image (optimized with buffer reuse) void drawPoses (cv::Mat &amp; image, const std::vector&lt; PoseResult &gt; &amp; results, int kptRadius=4, float kptThreshold=0.5f, int lineThickness=2) constDraw pose estimations on an image. void drawSkeletonsOnly (cv::Mat &amp; image, const std::vector&lt; PoseResult &gt; &amp; results, int kptRadius=4, float kptThreshold=0.5f, int lineThickness=2) constDraw only skeletons (no bounding boxes) const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. virtual ~YOLOPoseDetector () = default"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#public-static-functions","title":"Public Static Functions","text":"Type Name const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; getPoseSkeleton () Get COCO pose skeleton connections."},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-attributes","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name constexpr int FEATURES_PER_KEYPOINT   = <code>3</code> constexpr int NUM_KEYPOINTS   = <code>17</code>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-functions","title":"Protected Functions","text":"Type Name std::vector&lt; PoseResult &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess pose detection outputs. std::vector&lt; PoseResult &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold) Postprocess YOLO26 pose detection outputs (end-to-end, NMS-free) std::vector&lt; PoseResult &gt; postprocessV8 (const cv::Size &amp; originalSize, const cv::Size &amp; resizedShape, const float * rawOutput, const std::vector&lt; int64_t &gt; &amp; outputShape, float confThreshold, float iouThreshold) Postprocess YOLOv8/v11 pose detection outputs (requires NMS)"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-yoloposedetector","title":"function YOLOPoseDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::pose::YOLOPoseDetector::YOLOPoseDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath=\"\",\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file (optional for pose) </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-detect","title":"function detect","text":"<p>Run pose detection on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::detect (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.5f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of pose results </p>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-drawposes","title":"function drawPoses","text":"<p>Draw pose estimations on an image. </p> <pre><code>inline void yolos::pose::YOLOPoseDetector::drawPoses (\n    cv::Mat &amp; image,\n    const std::vector&lt; PoseResult &gt; &amp; results,\n    int kptRadius=4,\n    float kptThreshold=0.5f,\n    int lineThickness=2\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of pose results </li> <li><code>kptRadius</code> Keypoint circle radius </li> <li><code>kptThreshold</code> Minimum confidence to draw keypoint </li> <li><code>lineThickness</code> Skeleton line thickness </li> </ul>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-drawskeletonsonly","title":"function drawSkeletonsOnly","text":"<p>Draw only skeletons (no bounding boxes) </p> <pre><code>inline void yolos::pose::YOLOPoseDetector::drawSkeletonsOnly (\n    cv::Mat &amp; image,\n    const std::vector&lt; PoseResult &gt; &amp; results,\n    int kptRadius=4,\n    float kptThreshold=0.5f,\n    int lineThickness=2\n) const\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::pose::YOLOPoseDetector::getClassNames () const\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-yoloposedetector_1","title":"function ~YOLOPoseDetector","text":"<pre><code>virtual yolos::pose::YOLOPoseDetector::~YOLOPoseDetector () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#public-static-functions-documentation","title":"Public Static Functions Documentation","text":""},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-getposeskeleton","title":"function getPoseSkeleton","text":"<p>Get COCO pose skeleton connections. </p> <pre><code>static inline const std::vector&lt; std::pair&lt; int, int &gt; &gt; &amp; yolos::pose::YOLOPoseDetector::getPoseSkeleton () \n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#variable-buffer_","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::pose::YOLOPoseDetector::buffer_;\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#variable-classcolors_","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::pose::YOLOPoseDetector::classColors_;\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::pose::YOLOPoseDetector::classNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#variable-features_per_keypoint","title":"variable FEATURES_PER_KEYPOINT","text":"<pre><code>constexpr int yolos::pose::YOLOPoseDetector::FEATURES_PER_KEYPOINT;\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#variable-num_keypoints","title":"variable NUM_KEYPOINTS","text":"<pre><code>constexpr int yolos::pose::YOLOPoseDetector::NUM_KEYPOINTS;\n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-postprocess","title":"function postprocess","text":"<p>Postprocess pose detection outputs. </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-postprocessv26","title":"function postprocessV26","text":"<p>Postprocess YOLO26 pose detection outputs (end-to-end, NMS-free) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1pose_1_1YOLOPoseDetector/#function-postprocessv8","title":"function postprocessV8","text":"<p>Postprocess YOLOv8/v11 pose detection outputs (requires NMS) </p> <pre><code>inline std::vector&lt; PoseResult &gt; yolos::pose::YOLOPoseDetector::postprocessV8 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; resizedShape,\n    const float * rawOutput,\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/pose.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1preprocessing/","title":"Namespace yolos::preprocessing","text":"<p>Namespace List &gt; yolos &gt; preprocessing</p>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#classes","title":"Classes","text":"Type Name struct InferenceBuffer Pre-allocated inference buffer to avoid per-frame allocations."},{"location":"yolos/namespaceyolos_1_1preprocessing/#public-functions","title":"Public Functions","text":"Type Name void descaleCoordsBatch (float * coords, size_t count, float scale, float padX, float padY) Fast coordinate descaling (batch operation) void getLetterboxParams (const cv::Size &amp; originalShape, const cv::Size &amp; letterboxShape, float &amp; scale, float &amp; padX, float &amp; padY) Get letterbox padding and scale parameters. void getScalePad (const cv::Size &amp; originalSize, const cv::Size &amp; letterboxSize, float &amp; scale, float &amp; padX, float &amp; padY) Get scale and padding info from letterbox operation. void letterBox (const cv::Mat &amp; image, cv::Mat &amp; outImage, const cv::Size &amp; newShape, const cv::Scalar &amp; color=cv::Scalar(114, 114, 114), bool autoSize=true, bool scaleFill=false, bool scaleUp=true, int stride=32) Resize an image with letterboxing to maintain aspect ratio. void letterBoxCentered (const cv::Mat &amp; image, cv::Mat &amp; outImage, const cv::Size &amp; newShape=cv::Size(640, 640), bool autoSize=false, bool scaleFill=false, bool scaleUp=true, bool center=true, int stride=32, const cv::Scalar &amp; paddingValue=cv::Scalar(114, 114, 114), int interpolation=cv::INTER_LINEAR) Alternative letterbox with center option (matches Ultralytics) void letterBoxToBlob (const cv::Mat &amp; image, std::vector&lt; float &gt; &amp; blob, const cv::Size &amp; targetSize, cv::Size &amp; actualSize, float padColor=114.0f) Fast letterbox with direct blob output (avoids intermediate copies) void letterBoxToBlob (const cv::Mat &amp; image, InferenceBuffer &amp; buffer, const cv::Size &amp; targetSize, cv::Size &amp; actualSize, bool dynamicShape=false) Fast letterbox with buffer reuse. BoundingBox scaleCoords (const cv::Size &amp; letterboxShape, const BoundingBox &amp; coords, const cv::Size &amp; originalShape, bool clip=true) Scale detection coordinates from letterbox space back to original image size. KeyPoint scaleKeypoint (const cv::Size &amp; letterboxShape, const KeyPoint &amp; keypoint, const cv::Size &amp; originalShape, bool clip=true) Scale keypoint coordinates from letterbox space back to original image size."},{"location":"yolos/namespaceyolos_1_1preprocessing/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-descalecoordsbatch","title":"function descaleCoordsBatch","text":"<p>Fast coordinate descaling (batch operation) </p> <pre><code>inline void yolos::preprocessing::descaleCoordsBatch (\n    float * coords,\n    size_t count,\n    float scale,\n    float padX,\n    float padY\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>coords</code> Array of x,y coordinates to descale </li> <li><code>count</code> Number of coordinate pairs </li> <li><code>scale</code> Letterbox scale </li> <li><code>padX</code> X padding </li> <li><code>padY</code> Y padding </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-getletterboxparams","title":"function getLetterboxParams","text":"<p>Get letterbox padding and scale parameters. </p> <pre><code>inline void yolos::preprocessing::getLetterboxParams (\n    const cv::Size &amp; originalShape,\n    const cv::Size &amp; letterboxShape,\n    float &amp; scale,\n    float &amp; padX,\n    float &amp; padY\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>originalShape</code> Original image size </li> <li><code>letterboxShape</code> Letterboxed image size </li> <li><code>scale</code> Scale factor applied </li> <li><code>padX</code> Horizontal padding </li> <li><code>padY</code> Vertical padding </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-getscalepad","title":"function getScalePad","text":"<p>Get scale and padding info from letterbox operation. </p> <pre><code>inline void yolos::preprocessing::getScalePad (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; letterboxSize,\n    float &amp; scale,\n    float &amp; padX,\n    float &amp; padY\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>originalSize</code> Original image size </li> <li><code>letterboxSize</code> Letterboxed image size </li> <li><code>scale</code> Scale factor </li> <li><code>padX</code> X padding </li> <li><code>padY</code> Y padding </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-letterbox","title":"function letterBox","text":"<p>Resize an image with letterboxing to maintain aspect ratio. </p> <pre><code>inline void yolos::preprocessing::letterBox (\n    const cv::Mat &amp; image,\n    cv::Mat &amp; outImage,\n    const cv::Size &amp; newShape,\n    const cv::Scalar &amp; color=cv::Scalar(114, 114, 114),\n    bool autoSize=true,\n    bool scaleFill=false,\n    bool scaleUp=true,\n    int stride=32\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image </li> <li><code>outImage</code> Output resized and padded image </li> <li><code>newShape</code> Desired output size </li> <li><code>color</code> Padding color (default is gray 114,114,114) </li> <li><code>autoSize</code> If true, use minimum rectangle to resize </li> <li><code>scaleFill</code> Whether to scale to fill without keeping aspect ratio </li> <li><code>scaleUp</code> Whether to allow scaling up of the image </li> <li><code>stride</code> Stride size for padding alignment </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-letterboxcentered","title":"function letterBoxCentered","text":"<p>Alternative letterbox with center option (matches Ultralytics) </p> <pre><code>inline void yolos::preprocessing::letterBoxCentered (\n    const cv::Mat &amp; image,\n    cv::Mat &amp; outImage,\n    const cv::Size &amp; newShape=cv::Size(640, 640),\n    bool autoSize=false,\n    bool scaleFill=false,\n    bool scaleUp=true,\n    bool center=true,\n    int stride=32,\n    const cv::Scalar &amp; paddingValue=cv::Scalar(114, 114, 114),\n    int interpolation=cv::INTER_LINEAR\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image </li> <li><code>outImage</code> Output resized and padded image </li> <li><code>newShape</code> Desired output size (default 640x640) </li> <li><code>autoSize</code> If true, use minimum rectangle to resize </li> <li><code>scaleFill</code> Whether to scale to fill without keeping aspect ratio </li> <li><code>scaleUp</code> Whether to allow scaling up of the image </li> <li><code>center</code> If true, center the placed image </li> <li><code>stride</code> Stride of the model </li> <li><code>paddingValue</code> Padding value (default is 114) </li> <li><code>interpolation</code> Interpolation method </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-letterboxtoblob","title":"function letterBoxToBlob","text":"<p>Fast letterbox with direct blob output (avoids intermediate copies) </p> <pre><code>inline void yolos::preprocessing::letterBoxToBlob (\n    const cv::Mat &amp; image,\n    std::vector&lt; float &gt; &amp; blob,\n    const cv::Size &amp; targetSize,\n    cv::Size &amp; actualSize,\n    float padColor=114.0f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input BGR image </li> <li><code>blob</code> Output CHW float blob (pre-allocated) </li> <li><code>targetSize</code> Target size for inference </li> <li><code>actualSize</code> Actual output size after letterboxing </li> <li><code>padColor</code> Padding color value (0-255, default 114) </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-letterboxtoblob_1","title":"function letterBoxToBlob","text":"<p>Fast letterbox with buffer reuse. </p> <pre><code>inline void yolos::preprocessing::letterBoxToBlob (\n    const cv::Mat &amp; image,\n    InferenceBuffer &amp; buffer,\n    const cv::Size &amp; targetSize,\n    cv::Size &amp; actualSize,\n    bool dynamicShape=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input BGR image </li> <li><code>buffer</code> Pre-allocated inference buffer </li> <li><code>targetSize</code> Target size for inference </li> <li><code>actualSize</code> Actual output size </li> <li><code>dynamicShape</code> Whether to use dynamic shape </li> </ul>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-scalecoords","title":"function scaleCoords","text":"<p>Scale detection coordinates from letterbox space back to original image size. </p> <pre><code>inline BoundingBox yolos::preprocessing::scaleCoords (\n    const cv::Size &amp; letterboxShape,\n    const BoundingBox &amp; coords,\n    const cv::Size &amp; originalShape,\n    bool clip=true\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>letterboxShape</code> Shape of the letterboxed image used for inference </li> <li><code>coords</code> Bounding box in letterbox coordinates </li> <li><code>originalShape</code> Original image size before letterboxing </li> <li><code>clip</code> Whether to clip coordinates to image boundaries </li> </ul> <p>Returns:</p> <p>Scaled bounding box in original image coordinates </p>"},{"location":"yolos/namespaceyolos_1_1preprocessing/#function-scalekeypoint","title":"function scaleKeypoint","text":"<p>Scale keypoint coordinates from letterbox space back to original image size. </p> <pre><code>inline KeyPoint yolos::preprocessing::scaleKeypoint (\n    const cv::Size &amp; letterboxShape,\n    const KeyPoint &amp; keypoint,\n    const cv::Size &amp; originalShape,\n    bool clip=true\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>letterboxShape</code> Shape of the letterboxed image </li> <li><code>keypoint</code> Keypoint in letterbox coordinates </li> <li><code>originalShape</code> Original image size </li> <li><code>clip</code> Whether to clip coordinates to image boundaries </li> </ul> <p>Returns:</p> <p>Scaled keypoint in original image coordinates </p> <p>The documentation for this class was generated from the following file <code>include/yolos/core/preprocessing.hpp</code></p>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/","title":"Struct yolos::preprocessing::InferenceBuffer","text":"<p>ClassList &gt; yolos &gt; preprocessing &gt; InferenceBuffer</p> <p>Pre-allocated inference buffer to avoid per-frame allocations. </p> <ul> <li><code>#include &lt;preprocessing.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#public-attributes","title":"Public Attributes","text":"Type Name std::vector&lt; float &gt; blob CHW format blob for ONNX. cv::Size lastInputSize Last input size (for reuse check) cv::Size lastTargetSize Last target size. cv::Mat resized Letterboxed image. cv::Mat rgbFloat RGB float image."},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#public-functions","title":"Public Functions","text":"Type Name void ensureCapacity (int height, int width, int channels=3) Ensure blob has required capacity."},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#variable-blob","title":"variable blob","text":"<p>CHW format blob for ONNX. </p> <pre><code>std::vector&lt;float&gt; yolos::preprocessing::InferenceBuffer::blob;\n</code></pre>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#variable-lastinputsize","title":"variable lastInputSize","text":"<p>Last input size (for reuse check) </p> <pre><code>cv::Size yolos::preprocessing::InferenceBuffer::lastInputSize;\n</code></pre>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#variable-lasttargetsize","title":"variable lastTargetSize","text":"<p>Last target size. </p> <pre><code>cv::Size yolos::preprocessing::InferenceBuffer::lastTargetSize;\n</code></pre>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#variable-resized","title":"variable resized","text":"<p>Letterboxed image. </p> <pre><code>cv::Mat yolos::preprocessing::InferenceBuffer::resized;\n</code></pre>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#variable-rgbfloat","title":"variable rgbFloat","text":"<p>RGB float image. </p> <pre><code>cv::Mat yolos::preprocessing::InferenceBuffer::rgbFloat;\n</code></pre>"},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1preprocessing_1_1InferenceBuffer/#function-ensurecapacity","title":"function ensureCapacity","text":"<p>Ensure blob has required capacity. </p> <pre><code>inline void yolos::preprocessing::InferenceBuffer::ensureCapacity (\n    int height,\n    int width,\n    int channels=3\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/preprocessing.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1seg/","title":"Namespace yolos::seg","text":"<p>Namespace List &gt; yolos &gt; seg</p>"},{"location":"yolos/namespaceyolos_1_1seg/#classes","title":"Classes","text":"Type Name struct Segmentation Segmentation result containing bounding box, confidence, class ID, and mask. class YOLOSegDetector YOLO segmentation detector with mask prediction. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/segmentation.hpp</code></p>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/","title":"Struct yolos::seg::Segmentation","text":"<p>ClassList &gt; yolos &gt; seg &gt; Segmentation</p> <p>Segmentation result containing bounding box, confidence, class ID, and mask.</p> <ul> <li><code>#include &lt;segmentation.hpp&gt;</code></li> </ul>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#public-attributes","title":"Public Attributes","text":"Type Name BoundingBox box Axis-aligned bounding box. int classId   = <code>{0}</code>Class ID. float conf   = <code>{0.0f}</code>Confidence score. cv::Mat mask Binary mask (CV_8UC1) in original image coordinates."},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#public-functions","title":"Public Functions","text":"Type Name Segmentation () = default Segmentation (const BoundingBox &amp; box_, float conf_, int classId_, const cv::Mat &amp; mask_)"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#variable-box","title":"variable box","text":"<p>Axis-aligned bounding box. </p> <pre><code>BoundingBox yolos::seg::Segmentation::box;\n</code></pre>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#variable-classid","title":"variable classId","text":"<p>Class ID. </p> <pre><code>int yolos::seg::Segmentation::classId;\n</code></pre>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#variable-conf","title":"variable conf","text":"<p>Confidence score. </p> <pre><code>float yolos::seg::Segmentation::conf;\n</code></pre>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#variable-mask","title":"variable mask","text":"<p>Binary mask (CV_8UC1) in original image coordinates. </p> <pre><code>cv::Mat yolos::seg::Segmentation::mask;\n</code></pre>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#function-segmentation-12","title":"function Segmentation [1/2]","text":"<pre><code>yolos::seg::Segmentation::Segmentation () = default\n</code></pre>"},{"location":"yolos/structyolos_1_1seg_1_1Segmentation/#function-segmentation-22","title":"function Segmentation [2/2]","text":"<pre><code>inline yolos::seg::Segmentation::Segmentation (\n    const BoundingBox &amp; box_,\n    float conf_,\n    int classId_,\n    const cv::Mat &amp; mask_\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/segmentation.hpp</code></p>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/","title":"Class yolos::seg::YOLOSegDetector","text":"<p>ClassList &gt; yolos &gt; seg &gt; YOLOSegDetector</p> <p>YOLO segmentation detector with mask prediction. </p> <ul> <li><code>#include &lt;segmentation.hpp&gt;</code></li> </ul> <p>Inherits the following classes: yolos::OrtSessionBase</p>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#public-functions","title":"Public Functions","text":"Type Name YOLOSegDetector (const std::string &amp; modelPath, const std::string &amp; labelsPath, bool useGPU=false) Constructor. void drawMasksOnly (cv::Mat &amp; image, const std::vector&lt; Segmentation &gt; &amp; results, float maskAlpha=0.5f) constDraw only segmentation masks (no boxes) void drawSegmentations (cv::Mat &amp; image, const std::vector&lt; Segmentation &gt; &amp; results, float maskAlpha=0.5f) constDraw segmentations with boxes and labels on an image. const std::vector&lt; cv::Scalar &gt; &amp; getClassColors () constGet class colors. const std::vector&lt; std::string &gt; &amp; getClassNames () constGet class names. std::vector&lt; Segmentation &gt; segment (const cv::Mat &amp; image, float confThreshold=0.4f, float iouThreshold=0.45f) Run segmentation on an image (optimized with buffer reuse) virtual ~YOLOSegDetector () = default"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#public-functions-inherited-from-yolosortsessionbase","title":"Public Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name OrtSessionBase (const std::string &amp; modelPath, bool useGPU=false, int numThreads=0) Constructor - loads and initializes the ONNX model. OrtSessionBase (const OrtSessionBase &amp;) = delete OrtSessionBase (OrtSessionBase &amp;&amp;) = default const std::string &amp; getDevice () noexcept constGet the device being used for inference. cv::Size getInputShape () noexcept constGet the input image shape expected by the model. size_t getNumInputNodes () noexcept constGet the number of input nodes. size_t getNumOutputNodes () noexcept constGet the number of output nodes. bool isDynamicBatchSize () noexcept constCheck if batch size is dynamic. bool isDynamicInputShape () noexcept constCheck if input shape is dynamic. OrtSessionBase &amp; operator= (const OrtSessionBase &amp;) = delete OrtSessionBase &amp; operator= (OrtSessionBase &amp;&amp;) = default virtual ~OrtSessionBase () = default"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-attributes","title":"Protected Attributes","text":"Type Name preprocessing::InferenceBuffer buffer_ std::vector&lt; cv::Scalar &gt; classColors_ std::vector&lt; std::string &gt; classNames_"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-attributes-inherited-from-yolosortsessionbase","title":"Protected Attributes inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name std::string device_   = <code>{\"cpu\"}</code> Ort::Env env_   = <code>{nullptr}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; inputNameAllocs_ std::vector&lt; const char * &gt; inputNames_ cv::Size inputShape_ bool isDynamicBatchSize_   = <code>{false}</code> bool isDynamicInputShape_   = <code>{false}</code> size_t numInputNodes_   = <code>{0}</code> size_t numOutputNodes_   = <code>{0}</code> std::vector&lt; Ort::AllocatedStringPtr &gt; outputNameAllocs_ std::vector&lt; const char * &gt; outputNames_ Ort::SessionOptions sessionOptions_   = <code>{nullptr}</code> Ort::Session session_   = <code>{nullptr}</code>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name constexpr float MASK_THRESHOLD   = <code>0.5f</code>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-functions","title":"Protected Functions","text":"Type Name std::vector&lt; Segmentation &gt; postprocess (const cv::Size &amp; originalSize, const cv::Size &amp; letterboxSize, const std::vector&lt; Ort::Value &gt; &amp; outputTensors, float confThreshold, float iouThreshold) Postprocess segmentation outputs. std::vector&lt; Segmentation &gt; postprocessV26 (const cv::Size &amp; originalSize, const cv::Size &amp; letterboxSize, const float * output0, const float * output1, const std::vector&lt; int64_t &gt; &amp; shape0, const std::vector&lt; int64_t &gt; &amp; shape1, float confThreshold) Postprocess YOLO26-seg format outputs (end-to-end, no NMS needed) Output0 shape: [1, num_detections, 38] where 38 = 4 (x1,y1,x2,y2) + 1 (conf) + 1 (class_id) + 32 (mask_coeffs)"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-functions-inherited-from-yolosortsessionbase","title":"Protected Functions inherited from yolos::OrtSessionBase","text":"<p>See yolos::OrtSessionBase</p> Type Name Ort::Value createInputTensor (float * blob, const std::vector&lt; int64_t &gt; &amp; inputTensorShape) Create an input tensor from a blob. std::vector&lt; Ort::Value &gt; runInference (Ort::Value &amp; inputTensor) Run inference with the given input tensor."},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-yolosegdetector","title":"function YOLOSegDetector","text":"<p>Constructor. </p> <pre><code>inline yolos::seg::YOLOSegDetector::YOLOSegDetector (\n    const std::string &amp; modelPath,\n    const std::string &amp; labelsPath,\n    bool useGPU=false\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>modelPath</code> Path to the ONNX model file </li> <li><code>labelsPath</code> Path to the class names file </li> <li><code>useGPU</code> Whether to use GPU for inference </li> </ul>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-drawmasksonly","title":"function drawMasksOnly","text":"<p>Draw only segmentation masks (no boxes) </p> <pre><code>inline void yolos::seg::YOLOSegDetector::drawMasksOnly (\n    cv::Mat &amp; image,\n    const std::vector&lt; Segmentation &gt; &amp; results,\n    float maskAlpha=0.5f\n) const\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-drawsegmentations","title":"function drawSegmentations","text":"<p>Draw segmentations with boxes and labels on an image. </p> <pre><code>inline void yolos::seg::YOLOSegDetector::drawSegmentations (\n    cv::Mat &amp; image,\n    const std::vector&lt; Segmentation &gt; &amp; results,\n    float maskAlpha=0.5f\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Image to draw on </li> <li><code>results</code> Vector of segmentation results </li> <li><code>maskAlpha</code> Mask transparency (0-1) </li> </ul>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-getclasscolors","title":"function getClassColors","text":"<p>Get class colors. </p> <pre><code>inline const std::vector&lt; cv::Scalar &gt; &amp; yolos::seg::YOLOSegDetector::getClassColors () const\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-getclassnames","title":"function getClassNames","text":"<p>Get class names. </p> <pre><code>inline const std::vector&lt; std::string &gt; &amp; yolos::seg::YOLOSegDetector::getClassNames () const\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-segment","title":"function segment","text":"<p>Run segmentation on an image (optimized with buffer reuse) </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::segment (\n    const cv::Mat &amp; image,\n    float confThreshold=0.4f,\n    float iouThreshold=0.45f\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>image</code> Input image (BGR format) </li> <li><code>confThreshold</code> Confidence threshold </li> <li><code>iouThreshold</code> IoU threshold for NMS </li> </ul> <p>Returns:</p> <p>Vector of segmentation results </p>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-yolosegdetector_1","title":"function ~YOLOSegDetector","text":"<pre><code>virtual yolos::seg::YOLOSegDetector::~YOLOSegDetector () = default\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#variable-buffer_","title":"variable buffer_","text":"<pre><code>preprocessing::InferenceBuffer yolos::seg::YOLOSegDetector::buffer_;\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#variable-classcolors_","title":"variable classColors_","text":"<pre><code>std::vector&lt;cv::Scalar&gt; yolos::seg::YOLOSegDetector::classColors_;\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#variable-classnames_","title":"variable classNames_","text":"<pre><code>std::vector&lt;std::string&gt; yolos::seg::YOLOSegDetector::classNames_;\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#variable-mask_threshold","title":"variable MASK_THRESHOLD","text":"<pre><code>constexpr float yolos::seg::YOLOSegDetector::MASK_THRESHOLD;\n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-postprocess","title":"function postprocess","text":"<p>Postprocess segmentation outputs. </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::postprocess (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; letterboxSize,\n    const std::vector&lt; Ort::Value &gt; &amp; outputTensors,\n    float confThreshold,\n    float iouThreshold\n) \n</code></pre>"},{"location":"yolos/classyolos_1_1seg_1_1YOLOSegDetector/#function-postprocessv26","title":"function postprocessV26","text":"<p>Postprocess YOLO26-seg format outputs (end-to-end, no NMS needed) Output0 shape: [1, num_detections, 38] where 38 = 4 (x1,y1,x2,y2) + 1 (conf) + 1 (class_id) + 32 (mask_coeffs) </p> <pre><code>inline std::vector&lt; Segmentation &gt; yolos::seg::YOLOSegDetector::postprocessV26 (\n    const cv::Size &amp; originalSize,\n    const cv::Size &amp; letterboxSize,\n    const float * output0,\n    const float * output1,\n    const std::vector&lt; int64_t &gt; &amp; shape0,\n    const std::vector&lt; int64_t &gt; &amp; shape1,\n    float confThreshold\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/segmentation.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1utils/","title":"Namespace yolos::utils","text":"<p>Namespace List &gt; yolos &gt; utils</p>"},{"location":"yolos/namespaceyolos_1_1utils/#public-functions","title":"Public Functions","text":"Type Name std::enable_if&lt; std::is_arithmetic&lt; T &gt;::value, T &gt;::type clamp (const T &amp; value, const T &amp; low, const T &amp; high) Clamp a value to a specified range [low, high]. std::vector&lt; std::string &gt; getClassNames (const std::string &amp; path) Load class names from a file (one class name per line) float sigmoid (float x) Apply sigmoid activation: 1 / (1 + exp(-x)) void sigmoidInplace (std::vector&lt; float &gt; &amp; values) Apply sigmoid activation to a vector in-place. size_t vectorProduct (const std::vector&lt; int64_t &gt; &amp; shape) Compute the product of elements in a vector."},{"location":"yolos/namespaceyolos_1_1utils/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1utils/#function-clamp","title":"function clamp","text":"<p>Clamp a value to a specified range [low, high]. </p> <pre><code>template&lt;typename T&gt;\ninline std::enable_if&lt; std::is_arithmetic&lt; T &gt;::value, T &gt;::type yolos::utils::clamp (\n    const T &amp; value,\n    const T &amp; low,\n    const T &amp; high\n) \n</code></pre> <p>Template parameters:</p> <ul> <li><code>T</code> Arithmetic type (int, float, etc.) </li> </ul> <p>Parameters:</p> <ul> <li><code>value</code> The value to clamp </li> <li><code>low</code> Lower bound </li> <li><code>high</code> Upper bound </li> </ul> <p>Returns:</p> <p>Clamped value </p>"},{"location":"yolos/namespaceyolos_1_1utils/#function-getclassnames","title":"function getClassNames","text":"<p>Load class names from a file (one class name per line) </p> <pre><code>inline std::vector&lt; std::string &gt; yolos::utils::getClassNames (\n    const std::string &amp; path\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code> Path to the class names file </li> </ul> <p>Returns:</p> <p>Vector of class names </p>"},{"location":"yolos/namespaceyolos_1_1utils/#function-sigmoid","title":"function sigmoid","text":"<p>Apply sigmoid activation: 1 / (1 + exp(-x)) </p> <pre><code>inline float yolos::utils::sigmoid (\n    float x\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>x</code> Input value </li> </ul> <p>Returns:</p> <p>Sigmoid of x </p>"},{"location":"yolos/namespaceyolos_1_1utils/#function-sigmoidinplace","title":"function sigmoidInplace","text":"<p>Apply sigmoid activation to a vector in-place. </p> <pre><code>inline void yolos::utils::sigmoidInplace (\n    std::vector&lt; float &gt; &amp; values\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>values</code> Vector of values to transform </li> </ul>"},{"location":"yolos/namespaceyolos_1_1utils/#function-vectorproduct","title":"function vectorProduct","text":"<p>Compute the product of elements in a vector. </p> <pre><code>inline size_t yolos::utils::vectorProduct (\n    const std::vector&lt; int64_t &gt; &amp; shape\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>shape</code> Vector of dimensions </li> </ul> <p>Returns:</p> <p>Product of all elements </p> <p>The documentation for this class was generated from the following file <code>include/yolos/core/utils.hpp</code></p>"},{"location":"yolos/namespaceyolos_1_1version/","title":"Namespace yolos::version","text":"<p>Namespace List &gt; yolos &gt; version</p>"},{"location":"yolos/namespaceyolos_1_1version/#public-functions","title":"Public Functions","text":"Type Name YOLOVersion detectClassificationVersion (const std::vector&lt; int64_t &gt; &amp; outputShape) Detect YOLO version for classification model. YOLOVersion detectFromOutputShape (const std::vector&lt; int64_t &gt; &amp; outputShape, size_t numOutputs=1) Detect YOLO version from detection model output tensor shape. bool requiresNMS (YOLOVersion version) Check if version requires NMS post-processing. std::string toString (YOLOVersion version) Convert YOLOVersion enum to string."},{"location":"yolos/namespaceyolos_1_1version/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"yolos/namespaceyolos_1_1version/#function-detectclassificationversion","title":"function detectClassificationVersion","text":"<p>Detect YOLO version for classification model. </p> <pre><code>inline YOLOVersion yolos::version::detectClassificationVersion (\n    const std::vector&lt; int64_t &gt; &amp; outputShape\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>outputShape</code> The shape of the output tensor </li> </ul> <p>Returns:</p> <p>Detected YOLOVersion (V11 or V12 for classification) </p>"},{"location":"yolos/namespaceyolos_1_1version/#function-detectfromoutputshape","title":"function detectFromOutputShape","text":"<p>Detect YOLO version from detection model output tensor shape. </p> <pre><code>inline YOLOVersion yolos::version::detectFromOutputShape (\n    const std::vector&lt; int64_t &gt; &amp; outputShape,\n    size_t numOutputs=1\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>outputShape</code> The shape of the first output tensor [batch, dim1, dim2, ...] </li> <li><code>numOutputs</code> Number of output tensors from the model </li> </ul> <p>Returns:</p> <p>Detected YOLOVersion </p>"},{"location":"yolos/namespaceyolos_1_1version/#function-requiresnms","title":"function requiresNMS","text":"<p>Check if version requires NMS post-processing. </p> <pre><code>inline bool yolos::version::requiresNMS (\n    YOLOVersion version\n) \n</code></pre>"},{"location":"yolos/namespaceyolos_1_1version/#function-tostring","title":"function toString","text":"<p>Convert YOLOVersion enum to string. </p> <pre><code>inline std::string yolos::version::toString (\n    YOLOVersion version\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>include/yolos/core/version.hpp</code></p>"},{"location":"yolos/dir_d44c64559bbebec7f509842c48db8b23/","title":"Dir include","text":"<p>FileList &gt; include</p>"},{"location":"yolos/dir_d44c64559bbebec7f509842c48db8b23/#directories","title":"Directories","text":"Type Name dir yolos <p>The documentation for this class was generated from the following file <code>include/</code></p>"},{"location":"yolos/dir_0663062e3f7bb1f439b575391d32cc63/","title":"Dir include/yolos","text":"<p>FileList &gt; include &gt; yolos</p>"},{"location":"yolos/dir_0663062e3f7bb1f439b575391d32cc63/#files","title":"Files","text":"Type Name file yolos.hpp"},{"location":"yolos/dir_0663062e3f7bb1f439b575391d32cc63/#directories","title":"Directories","text":"Type Name dir core dir tasks <p>The documentation for this class was generated from the following file <code>include/yolos/</code></p>"},{"location":"yolos/dir_a763ec46eda5c5a329ecdb0f0bec1eed/","title":"Dir include/yolos/core","text":"<p>FileList &gt; core</p>"},{"location":"yolos/dir_a763ec46eda5c5a329ecdb0f0bec1eed/#files","title":"Files","text":"Type Name file drawing.hpp file nms.hpp file preprocessing.hpp file session_base.hpp file types.hpp file utils.hpp file version.hpp <p>The documentation for this class was generated from the following file <code>include/yolos/core/</code></p>"},{"location":"yolos/drawing_8hpp/","title":"File drawing.hpp","text":"<p>FileList &gt; core &gt; drawing.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;random&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> </ul>"},{"location":"yolos/drawing_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace drawing <p>The documentation for this class was generated from the following file <code>include/yolos/core/drawing.hpp</code></p>"},{"location":"yolos/drawing_8hpp_source/","title":"File drawing.hpp","text":"<p>File List &gt; core &gt; drawing.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Drawing Utilities\n// ============================================================================\n// Visualization functions for detection results including bounding boxes,\n// labels, masks, and pose skeletons.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n#include &lt;random&gt;\n#include &lt;unordered_map&gt;\n#include &lt;cmath&gt;\n\n#include \"yolos/core/types.hpp\"\n\nnamespace yolos {\nnamespace drawing {\n\n// ============================================================================\n// Color Generation\n// ============================================================================\n\ninline std::vector&lt;cv::Scalar&gt; generateColors(const std::vector&lt;std::string&gt;&amp; classNames, int seed = 42) {\n    // Static cache to avoid regenerating colors\n    static std::unordered_map&lt;size_t, std::vector&lt;cv::Scalar&gt;&gt; colorCache;\n\n    // Compute hash key from class names\n    size_t hashKey = 0;\n    for (const auto&amp; name : classNames) {\n        hashKey ^= std::hash&lt;std::string&gt;{}(name) + 0x9e3779b9 + (hashKey &lt;&lt; 6) + (hashKey &gt;&gt; 2);\n    }\n\n    // Check cache\n    auto it = colorCache.find(hashKey);\n    if (it != colorCache.end()) {\n        return it-&gt;second;\n    }\n\n    // Generate colors\n    std::vector&lt;cv::Scalar&gt; colors;\n    colors.reserve(classNames.size());\n\n    std::mt19937 rng(seed);\n    std::uniform_int_distribution&lt;int&gt; dist(0, 255);\n\n    for (size_t i = 0; i &lt; classNames.size(); ++i) {\n        colors.emplace_back(cv::Scalar(dist(rng), dist(rng), dist(rng)));\n    }\n\n    colorCache[hashKey] = colors;\n    return colors;\n}\n\ninline const std::vector&lt;cv::Scalar&gt;&amp; getPosePalette() {\n    static const std::vector&lt;cv::Scalar&gt; palette = {\n        cv::Scalar(0, 128, 255),    // 0\n        cv::Scalar(51, 153, 255),   // 1\n        cv::Scalar(102, 178, 255),  // 2\n        cv::Scalar(0, 230, 230),    // 3\n        cv::Scalar(255, 153, 255),  // 4\n        cv::Scalar(255, 204, 153),  // 5\n        cv::Scalar(255, 102, 255),  // 6\n        cv::Scalar(255, 51, 255),   // 7\n        cv::Scalar(255, 178, 102),  // 8\n        cv::Scalar(255, 153, 51),   // 9\n        cv::Scalar(153, 153, 255),  // 10\n        cv::Scalar(102, 102, 255),  // 11\n        cv::Scalar(51, 51, 255),    // 12\n        cv::Scalar(153, 255, 153),  // 13\n        cv::Scalar(102, 255, 102),  // 14\n        cv::Scalar(51, 255, 51),    // 15\n        cv::Scalar(0, 255, 0),      // 16\n        cv::Scalar(255, 0, 0),      // 17\n        cv::Scalar(0, 0, 255),      // 18\n        cv::Scalar(255, 255, 255)   // 19\n    };\n    return palette;\n}\n\n// ============================================================================\n// Bounding Box Drawing\n// ============================================================================\n\ninline void drawBoundingBox(cv::Mat&amp; image,\n                           const BoundingBox&amp; box,\n                           const std::string&amp; label,\n                           const cv::Scalar&amp; color,\n                           int thickness = 2) {\n    // Draw rectangle\n    cv::rectangle(image,\n                  cv::Point(box.x, box.y),\n                  cv::Point(box.x + box.width, box.y + box.height),\n                  color, thickness, cv::LINE_AA);\n\n    // Draw label background and text\n    if (!label.empty()) {\n        int fontFace = cv::FONT_HERSHEY_SIMPLEX;\n        double fontScale = std::min(image.rows, image.cols) * 0.0008;\n        fontScale = std::max(fontScale, 0.4);\n        int textThickness = std::max(1, static_cast&lt;int&gt;(std::min(image.rows, image.cols) * 0.002));\n        int baseline = 0;\n\n        cv::Size textSize = cv::getTextSize(label, fontFace, fontScale, textThickness, &amp;baseline);\n\n        int labelY = std::max(box.y, textSize.height + 5);\n        cv::Point labelTopLeft(box.x, labelY - textSize.height - 5);\n        cv::Point labelBottomRight(box.x + textSize.width + 5, labelY + baseline - 5);\n\n        cv::rectangle(image, labelTopLeft, labelBottomRight, color, cv::FILLED);\n        cv::putText(image, label, cv::Point(box.x + 2, labelY - 2),\n                    fontFace, fontScale, cv::Scalar(255, 255, 255), textThickness, cv::LINE_AA);\n    }\n}\n\ninline void drawBoundingBoxWithMask(cv::Mat&amp; image,\n                                    const BoundingBox&amp; box,\n                                    const std::string&amp; label,\n                                    const cv::Scalar&amp; color,\n                                    float maskAlpha = 0.4f) {\n    // Draw semi-transparent fill\n    cv::Mat overlay = image.clone();\n    cv::rectangle(overlay,\n                  cv::Rect(box.x, box.y, box.width, box.height),\n                  color, cv::FILLED);\n    cv::addWeighted(overlay, maskAlpha, image, 1.0f - maskAlpha, 0, image);\n\n    // Draw box border and label\n    drawBoundingBox(image, box, label, color, 2);\n}\n\n// ============================================================================\n// Oriented Bounding Box Drawing\n// ============================================================================\n\ninline void drawOrientedBoundingBox(cv::Mat&amp; image,\n                                    const OrientedBoundingBox&amp; obb,\n                                    const std::string&amp; label,\n                                    const cv::Scalar&amp; color,\n                                    int thickness = 2) {\n    // Create rotated rectangle\n    cv::RotatedRect rotatedRect(\n        cv::Point2f(obb.x, obb.y),\n        cv::Size2f(obb.width, obb.height),\n        obb.angle * 180.0f / static_cast&lt;float&gt;(CV_PI)\n    );\n\n    // Get vertices and draw\n    cv::Point2f vertices[4];\n    rotatedRect.points(vertices);\n\n    for (int i = 0; i &lt; 4; ++i) {\n        cv::line(image, vertices[i], vertices[(i + 1) % 4], color, thickness, cv::LINE_AA);\n    }\n\n    // Draw label\n    if (!label.empty()) {\n        int fontFace = cv::FONT_HERSHEY_DUPLEX;\n        double fontScale = 0.5;\n        int textThickness = 1;\n        int baseline;\n\n        cv::Size labelSize = cv::getTextSize(label, fontFace, fontScale, textThickness, &amp;baseline);\n\n        int x = static_cast&lt;int&gt;(obb.x - obb.width / 2);\n        int y = static_cast&lt;int&gt;(obb.y - obb.height / 2) - 5;\n\n        x = std::max(0, std::min(x, image.cols - labelSize.width));\n        y = std::max(labelSize.height, std::min(y, image.rows - baseline));\n\n        cv::Scalar labelBgColor = color * 0.6;\n        cv::rectangle(image,\n                      cv::Rect(x, y - labelSize.height, labelSize.width, labelSize.height + baseline),\n                      labelBgColor, cv::FILLED);\n        cv::putText(image, label, cv::Point(x, y),\n                    fontFace, fontScale, cv::Scalar::all(255), textThickness, cv::LINE_AA);\n    }\n}\n\n// ============================================================================\n// Pose Drawing\n// ============================================================================\n\ninline void drawPoseSkeleton(cv::Mat&amp; image,\n                             const std::vector&lt;KeyPoint&gt;&amp; keypoints,\n                             const std::vector&lt;std::pair&lt;int, int&gt;&gt;&amp; skeleton,\n                             int kptRadius = 4,\n                             float kptThreshold = 0.5f,\n                             int lineThickness = 2) {\n    const auto&amp; palette = getPosePalette();\n\n    // Keypoint color indices (for 17 COCO keypoints)\n    static const std::vector&lt;int&gt; kptColorIndices = {16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9};\n    // Limb color indices\n    static const std::vector&lt;int&gt; limbColorIndices = {9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16};\n\n    // Prepare keypoint positions\n    std::vector&lt;cv::Point&gt; kptPoints(keypoints.size(), cv::Point(-1, -1));\n    std::vector&lt;bool&gt; valid(keypoints.size(), false);\n\n    // Draw keypoints\n    for (size_t i = 0; i &lt; keypoints.size(); ++i) {\n        if (keypoints[i].confidence &gt;= kptThreshold) {\n            int x = static_cast&lt;int&gt;(std::round(keypoints[i].x));\n            int y = static_cast&lt;int&gt;(std::round(keypoints[i].y));\n            kptPoints[i] = cv::Point(x, y);\n            valid[i] = true;\n\n            int colorIdx = (i &lt; kptColorIndices.size()) ? kptColorIndices[i] : 0;\n            cv::circle(image, cv::Point(x, y), kptRadius, palette[colorIdx], -1, cv::LINE_AA);\n        }\n    }\n\n    // Draw skeleton\n    for (size_t j = 0; j &lt; skeleton.size(); ++j) {\n        int src = skeleton[j].first;\n        int dst = skeleton[j].second;\n\n        if (src &lt; static_cast&lt;int&gt;(keypoints.size()) &amp;&amp;\n            dst &lt; static_cast&lt;int&gt;(keypoints.size()) &amp;&amp;\n            valid[src] &amp;&amp; valid[dst]) {\n            int limbColorIdx = (j &lt; limbColorIndices.size()) ? limbColorIndices[j] : 0;\n            cv::line(image, kptPoints[src], kptPoints[dst],\n                     palette[limbColorIdx], lineThickness, cv::LINE_AA);\n        }\n    }\n}\n\n// ============================================================================\n// Segmentation Mask Drawing\n// ============================================================================\n\ninline void drawSegmentationMask(cv::Mat&amp; image,\n                                 const cv::Mat&amp; mask,\n                                 const cv::Scalar&amp; color,\n                                 float alpha = 0.5f) {\n    if (mask.empty()) {\n        return;\n    }\n\n    cv::Mat maskGray;\n    if (mask.channels() == 3) {\n        cv::cvtColor(mask, maskGray, cv::COLOR_BGR2GRAY);\n    } else {\n        maskGray = mask;\n    }\n\n    cv::Mat maskBinary;\n    cv::threshold(maskGray, maskBinary, 127, 255, cv::THRESH_BINARY);\n\n    cv::Mat coloredMask;\n    cv::cvtColor(maskBinary, coloredMask, cv::COLOR_GRAY2BGR);\n    coloredMask.setTo(color, maskBinary);\n\n    cv::addWeighted(image, 1.0, coloredMask, alpha, 0, image);\n}\n\n} // namespace drawing\n} // namespace yolos\n</code></pre>"},{"location":"yolos/nms_8hpp/","title":"File nms.hpp","text":"<p>FileList &gt; core &gt; nms.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;numeric&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> </ul>"},{"location":"yolos/nms_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace nms <p>The documentation for this class was generated from the following file <code>include/yolos/core/nms.hpp</code></p>"},{"location":"yolos/nms_8hpp_source/","title":"File nms.hpp","text":"<p>File List &gt; core &gt; nms.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Non-Maximum Suppression\n// ============================================================================\n// NMS implementations for axis-aligned and oriented bounding boxes.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;algorithm&gt;\n#include &lt;vector&gt;\n#include &lt;numeric&gt;\n#include &lt;cmath&gt;\n\n#include &lt;opencv2/opencv.hpp&gt;\n\n#include \"yolos/core/types.hpp\"\n\nnamespace yolos {\nnamespace nms {\n\n// ============================================================================\n// Standard NMS for Axis-Aligned Bounding Boxes\n// ============================================================================\n\ninline void NMSBoxes(const std::vector&lt;BoundingBox&gt;&amp; boxes,\n                     const std::vector&lt;float&gt;&amp; scores,\n                     float scoreThreshold,\n                     float nmsThreshold,\n                     std::vector&lt;int&gt;&amp; indices) {\n    indices.clear();\n\n    const size_t numBoxes = boxes.size();\n    if (numBoxes == 0) {\n        return;\n    }\n\n    // Step 1: Filter boxes by score threshold and create sorted indices\n    std::vector&lt;int&gt; sortedIndices;\n    sortedIndices.reserve(numBoxes);\n    for (size_t i = 0; i &lt; numBoxes; ++i) {\n        if (scores[i] &gt;= scoreThreshold) {\n            sortedIndices.push_back(static_cast&lt;int&gt;(i));\n        }\n    }\n\n    if (sortedIndices.empty()) {\n        return;\n    }\n\n    // Sort by score in descending order\n    std::sort(sortedIndices.begin(), sortedIndices.end(),\n              [&amp;scores](int a, int b) { return scores[a] &gt; scores[b]; });\n\n    // Step 2: Precompute areas\n    std::vector&lt;float&gt; areas(numBoxes, 0.0f);\n    for (size_t i = 0; i &lt; numBoxes; ++i) {\n        areas[i] = static_cast&lt;float&gt;(boxes[i].width * boxes[i].height);\n    }\n\n    // Step 3: Suppression\n    std::vector&lt;bool&gt; suppressed(numBoxes, false);\n\n    for (size_t i = 0; i &lt; sortedIndices.size(); ++i) {\n        int currentIdx = sortedIndices[i];\n        if (suppressed[currentIdx]) {\n            continue;\n        }\n\n        indices.push_back(currentIdx);\n\n        const BoundingBox&amp; currentBox = boxes[currentIdx];\n        const float x1_max = static_cast&lt;float&gt;(currentBox.x);\n        const float y1_max = static_cast&lt;float&gt;(currentBox.y);\n        const float x2_max = static_cast&lt;float&gt;(currentBox.x + currentBox.width);\n        const float y2_max = static_cast&lt;float&gt;(currentBox.y + currentBox.height);\n        const float areaCurrent = areas[currentIdx];\n\n        for (size_t j = i + 1; j &lt; sortedIndices.size(); ++j) {\n            int compareIdx = sortedIndices[j];\n            if (suppressed[compareIdx]) {\n                continue;\n            }\n\n            const BoundingBox&amp; compareBox = boxes[compareIdx];\n            const float x1 = std::max(x1_max, static_cast&lt;float&gt;(compareBox.x));\n            const float y1 = std::max(y1_max, static_cast&lt;float&gt;(compareBox.y));\n            const float x2 = std::min(x2_max, static_cast&lt;float&gt;(compareBox.x + compareBox.width));\n            const float y2 = std::min(y2_max, static_cast&lt;float&gt;(compareBox.y + compareBox.height));\n\n            const float interWidth = x2 - x1;\n            const float interHeight = y2 - y1;\n\n            if (interWidth &lt;= 0 || interHeight &lt;= 0) {\n                continue;\n            }\n\n            const float intersection = interWidth * interHeight;\n            const float unionArea = areaCurrent + areas[compareIdx] - intersection;\n            const float iou = (unionArea &gt; 0.0f) ? (intersection / unionArea) : 0.0f;\n\n            if (iou &gt; nmsThreshold) {\n                suppressed[compareIdx] = true;\n            }\n        }\n    }\n}\n\n// ============================================================================\n// Float-Precision NMS for Letterbox Coordinates\n// ============================================================================\n\ninline void NMSBoxesF(const std::vector&lt;cv::Rect2f&gt;&amp; boxes,\n                      const std::vector&lt;float&gt;&amp; scores,\n                      float scoreThreshold,\n                      float nmsThreshold,\n                      std::vector&lt;int&gt;&amp; indices) {\n    indices.clear();\n\n    const size_t numBoxes = boxes.size();\n    if (numBoxes == 0) {\n        return;\n    }\n\n    // Step 1: Filter boxes by score threshold and create sorted indices\n    std::vector&lt;int&gt; sortedIndices;\n    sortedIndices.reserve(numBoxes);\n    for (size_t i = 0; i &lt; numBoxes; ++i) {\n        if (scores[i] &gt;= scoreThreshold) {\n            sortedIndices.push_back(static_cast&lt;int&gt;(i));\n        }\n    }\n\n    if (sortedIndices.empty()) {\n        return;\n    }\n\n    // Sort by score in descending order\n    std::sort(sortedIndices.begin(), sortedIndices.end(),\n              [&amp;scores](int a, int b) { return scores[a] &gt; scores[b]; });\n\n    // Step 2: Precompute areas\n    std::vector&lt;float&gt; areas(numBoxes, 0.0f);\n    for (size_t i = 0; i &lt; numBoxes; ++i) {\n        areas[i] = boxes[i].width * boxes[i].height;\n    }\n\n    // Step 3: Suppression\n    std::vector&lt;bool&gt; suppressed(numBoxes, false);\n\n    for (size_t i = 0; i &lt; sortedIndices.size(); ++i) {\n        int currentIdx = sortedIndices[i];\n        if (suppressed[currentIdx]) {\n            continue;\n        }\n\n        indices.push_back(currentIdx);\n\n        const cv::Rect2f&amp; currentBox = boxes[currentIdx];\n        const float x1_max = currentBox.x;\n        const float y1_max = currentBox.y;\n        const float x2_max = currentBox.x + currentBox.width;\n        const float y2_max = currentBox.y + currentBox.height;\n        const float areaCurrent = areas[currentIdx];\n\n        for (size_t j = i + 1; j &lt; sortedIndices.size(); ++j) {\n            int compareIdx = sortedIndices[j];\n            if (suppressed[compareIdx]) {\n                continue;\n            }\n\n            const cv::Rect2f&amp; compareBox = boxes[compareIdx];\n            const float x1 = std::max(x1_max, compareBox.x);\n            const float y1 = std::max(y1_max, compareBox.y);\n            const float x2 = std::min(x2_max, compareBox.x + compareBox.width);\n            const float y2 = std::min(y2_max, compareBox.y + compareBox.height);\n\n            const float interWidth = x2 - x1;\n            const float interHeight = y2 - y1;\n\n            if (interWidth &lt;= 0 || interHeight &lt;= 0) {\n                continue;\n            }\n\n            const float intersection = interWidth * interHeight;\n            const float unionArea = areaCurrent + areas[compareIdx] - intersection;\n            const float iou = (unionArea &gt; 0.0f) ? (intersection / unionArea) : 0.0f;\n\n            if (iou &gt; nmsThreshold) {\n                suppressed[compareIdx] = true;\n            }\n        }\n    }\n}\n\ninline void NMSBoxesFBatched(const std::vector&lt;cv::Rect2f&gt;&amp; boxes,\n                             const std::vector&lt;float&gt;&amp; scores,\n                             const std::vector&lt;int&gt;&amp; classIds,\n                             float scoreThreshold,\n                             float nmsThreshold,\n                             std::vector&lt;int&gt;&amp; indices) {\n    // Create offset boxes to separate classes\n    std::vector&lt;cv::Rect2f&gt; offsetBoxes = boxes;\n    const float offset = 7680.0f; // Large offset to prevent cross-class overlap\n\n    for (size_t i = 0; i &lt; offsetBoxes.size(); ++i) {\n        offsetBoxes[i].x += classIds[i] * offset;\n        offsetBoxes[i].y += classIds[i] * offset;\n    }\n\n    // Apply standard NMS on offset boxes\n    NMSBoxesF(offsetBoxes, scores, scoreThreshold, nmsThreshold, indices);\n}\n\n// ============================================================================\n// Rotated NMS for Oriented Bounding Boxes\n// ============================================================================\n\ninline float computeRotatedIoU(const OrientedBoundingBox&amp; box1, const OrientedBoundingBox&amp; box2) {\n    // Convert to OpenCV RotatedRect (angle in degrees)\n    cv::RotatedRect rect1(\n        cv::Point2f(box1.x, box1.y),\n        cv::Size2f(box1.width, box1.height),\n        box1.angle * 180.0f / static_cast&lt;float&gt;(CV_PI)\n    );\n\n    cv::RotatedRect rect2(\n        cv::Point2f(box2.x, box2.y),\n        cv::Size2f(box2.width, box2.height),\n        box2.angle * 180.0f / static_cast&lt;float&gt;(CV_PI)\n    );\n\n    // Compute intersection\n    std::vector&lt;cv::Point2f&gt; intersectionPoints;\n    int result = cv::rotatedRectangleIntersection(rect1, rect2, intersectionPoints);\n\n    if (result == cv::INTERSECT_NONE) {\n        return 0.0f;\n    }\n\n    float intersectionArea = 0.0f;\n    if (intersectionPoints.size() &gt; 2) {\n        intersectionArea = static_cast&lt;float&gt;(cv::contourArea(intersectionPoints));\n    }\n\n    float area1 = box1.width * box1.height;\n    float area2 = box2.width * box2.height;\n    float unionArea = area1 + area2 - intersectionArea;\n\n    if (unionArea &lt; 1e-7f) {\n        return 0.0f;\n    }\n\n    return intersectionArea / unionArea;\n}\n\ninline std::vector&lt;int&gt; NMSRotated(const std::vector&lt;OrientedBoundingBox&gt;&amp; boxes,\n                                   const std::vector&lt;float&gt;&amp; scores,\n                                   float nmsThreshold = 0.45f,\n                                   int maxDet = 300) {\n    if (boxes.empty()) {\n        return {};\n    }\n\n    // Create indices sorted by score (descending)\n    std::vector&lt;int&gt; indices(boxes.size());\n    std::iota(indices.begin(), indices.end(), 0);\n\n    std::sort(indices.begin(), indices.end(),\n              [&amp;scores](int a, int b) { return scores[a] &gt; scores[b]; });\n\n    std::vector&lt;bool&gt; suppressed(boxes.size(), false);\n    std::vector&lt;int&gt; keep;\n\n    for (size_t i = 0; i &lt; indices.size(); ++i) {\n        int idx = indices[i];\n\n        if (suppressed[idx]) {\n            continue;\n        }\n\n        keep.push_back(idx);\n\n        if (static_cast&lt;int&gt;(keep.size()) &gt;= maxDet) {\n            break;\n        }\n\n        // Suppress boxes with high IoU\n        for (size_t j = i + 1; j &lt; indices.size(); ++j) {\n            int idx2 = indices[j];\n\n            if (suppressed[idx2]) {\n                continue;\n            }\n\n            float iou = computeRotatedIoU(boxes[idx], boxes[idx2]);\n\n            if (iou &gt;= nmsThreshold) {\n                suppressed[idx2] = true;\n            }\n        }\n    }\n\n    return keep;\n}\n\n// ============================================================================\n// Batched NMS (per-class NMS)\n// ============================================================================\n\ninline void NMSBoxesBatched(const std::vector&lt;BoundingBox&gt;&amp; boxes,\n                            const std::vector&lt;float&gt;&amp; scores,\n                            const std::vector&lt;int&gt;&amp; classIds,\n                            float scoreThreshold,\n                            float nmsThreshold,\n                            std::vector&lt;int&gt;&amp; indices) {\n    // Create offset boxes to separate classes\n    std::vector&lt;BoundingBox&gt; offsetBoxes = boxes;\n    const int offset = 7680; // Large offset to prevent cross-class overlap\n\n    for (size_t i = 0; i &lt; offsetBoxes.size(); ++i) {\n        offsetBoxes[i].x += classIds[i] * offset;\n        offsetBoxes[i].y += classIds[i] * offset;\n    }\n\n    // Apply standard NMS on offset boxes\n    NMSBoxes(offsetBoxes, scores, scoreThreshold, nmsThreshold, indices);\n}\n\ninline std::vector&lt;int&gt; NMSRotatedBatched(const std::vector&lt;OrientedBoundingBox&gt;&amp; boxes,\n                                          const std::vector&lt;float&gt;&amp; scores,\n                                          const std::vector&lt;int&gt;&amp; classIds,\n                                          float nmsThreshold = 0.45f,\n                                          int maxDet = 300) {\n    if (boxes.empty()) {\n        return {};\n    }\n\n    // Create offset boxes to separate classes\n    std::vector&lt;OrientedBoundingBox&gt; offsetBoxes = boxes;\n    const float offset = 7680.0f; // Large offset to prevent cross-class overlap\n\n    for (size_t i = 0; i &lt; offsetBoxes.size(); ++i) {\n        offsetBoxes[i].x += classIds[i] * offset;\n        offsetBoxes[i].y += classIds[i] * offset;\n    }\n\n    // Apply rotated NMS on offset boxes\n    return NMSRotated(offsetBoxes, scores, nmsThreshold, maxDet);\n}\n\n} // namespace nms\n} // namespace yolos\n</code></pre>"},{"location":"yolos/preprocessing_8hpp/","title":"File preprocessing.hpp","text":"<p>FileList &gt; core &gt; preprocessing.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> </ul>"},{"location":"yolos/preprocessing_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace preprocessing"},{"location":"yolos/preprocessing_8hpp/#classes","title":"Classes","text":"Type Name struct InferenceBuffer Pre-allocated inference buffer to avoid per-frame allocations. <p>The documentation for this class was generated from the following file <code>include/yolos/core/preprocessing.hpp</code></p>"},{"location":"yolos/preprocessing_8hpp_source/","title":"File preprocessing.hpp","text":"<p>File List &gt; core &gt; preprocessing.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Preprocessing Utilities\n// ============================================================================\n// Optimized image preprocessing functions for YOLO inference including\n// letterbox resizing, coordinate scaling, and blob conversion.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;cmath&gt;\n#include &lt;vector&gt;\n\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/utils.hpp\"\n\nnamespace yolos {\nnamespace preprocessing {\n\n// ============================================================================\n// Pre-allocated Buffer for Inference\n// ============================================================================\n\nstruct InferenceBuffer {\n    std::vector&lt;float&gt; blob;         \n    cv::Mat resized;                 \n    cv::Mat rgbFloat;                \n    cv::Size lastInputSize;          \n    cv::Size lastTargetSize;         \n\n    void ensureCapacity(int height, int width, int channels = 3) {\n        size_t required = static_cast&lt;size_t&gt;(height * width * channels);\n        if (blob.size() &lt; required) {\n            blob.resize(required);\n        }\n    }\n};\n\n// ============================================================================\n// LetterBox Resizing\n// ============================================================================\n\ninline void letterBox(const cv::Mat&amp; image,\n                      cv::Mat&amp; outImage,\n                      const cv::Size&amp; newShape,\n                      const cv::Scalar&amp; color = cv::Scalar(114, 114, 114),\n                      bool autoSize = true,\n                      bool scaleFill = false,\n                      bool scaleUp = true,\n                      int stride = 32) {\n\n    // Calculate the scaling ratio to fit the image within the new shape\n    float ratio = std::min(static_cast&lt;float&gt;(newShape.height) / image.rows,\n                          static_cast&lt;float&gt;(newShape.width) / image.cols);\n\n    // Prevent scaling up if not allowed\n    if (!scaleUp) {\n        ratio = std::min(ratio, 1.0f);\n    }\n\n    // Calculate new dimensions after scaling (use round to match Ultralytics)\n    int newUnpadW = static_cast&lt;int&gt;(std::round(image.cols * ratio));\n    int newUnpadH = static_cast&lt;int&gt;(std::round(image.rows * ratio));\n\n    // Calculate padding needed to reach the desired shape\n    int dw = newShape.width - newUnpadW;\n    int dh = newShape.height - newUnpadH;\n\n    if (autoSize) {\n        // Ensure padding is a multiple of stride for model compatibility\n        dw = dw % stride;\n        dh = dh % stride;\n    } else if (scaleFill) {\n        // Scale to fill without maintaining aspect ratio\n        newUnpadW = newShape.width;\n        newUnpadH = newShape.height;\n        dw = 0;\n        dh = 0;\n    }\n\n    // Calculate separate padding for left/right and top/bottom\n    int padLeft = dw / 2;\n    int padRight = dw - padLeft;\n    int padTop = dh / 2;\n    int padBottom = dh - padTop;\n\n    // Resize the image if dimensions differ\n    if (image.cols != newUnpadW || image.rows != newUnpadH) {\n        cv::resize(image, outImage, cv::Size(newUnpadW, newUnpadH), 0, 0, cv::INTER_LINEAR);\n    } else {\n        outImage = image.clone();\n    }\n\n    // Apply padding to reach the desired shape\n    cv::copyMakeBorder(outImage, outImage, padTop, padBottom, padLeft, padRight,\n                       cv::BORDER_CONSTANT, color);\n}\n\ninline void letterBoxCentered(const cv::Mat&amp; image,\n                              cv::Mat&amp; outImage,\n                              const cv::Size&amp; newShape = cv::Size(640, 640),\n                              bool autoSize = false,\n                              bool scaleFill = false,\n                              bool scaleUp = true,\n                              bool center = true,\n                              int stride = 32,\n                              const cv::Scalar&amp; paddingValue = cv::Scalar(114, 114, 114),\n                              int interpolation = cv::INTER_LINEAR) {\n\n    float ratio = std::min(static_cast&lt;float&gt;(newShape.height) / image.rows,\n                          static_cast&lt;float&gt;(newShape.width) / image.cols);\n\n    if (!scaleUp) {\n        ratio = std::min(ratio, 1.0f);\n    }\n\n    // Use round to match Ultralytics\n    int newUnpadW = static_cast&lt;int&gt;(std::round(image.cols * ratio));\n    int newUnpadH = static_cast&lt;int&gt;(std::round(image.rows * ratio));\n\n    int dw = newShape.width - newUnpadW;\n    int dh = newShape.height - newUnpadH;\n\n    if (autoSize) {\n        dw = dw % stride;\n        dh = dh % stride;\n    } else if (scaleFill) {\n        newUnpadW = newShape.width;\n        newUnpadH = newShape.height;\n        dw = 0;\n        dh = 0;\n    }\n\n    if (center) {\n        dw /= 2;\n        dh /= 2;\n    }\n\n    if (image.cols != newUnpadW || image.rows != newUnpadH) {\n        cv::resize(image, outImage, cv::Size(newUnpadW, newUnpadH), 0, 0, interpolation);\n    } else {\n        outImage = image.clone();\n    }\n\n    int top = center ? static_cast&lt;int&gt;(std::round(dh - 0.1f)) : 0;\n    int bottom = static_cast&lt;int&gt;(std::round(dh + 0.1f));\n    int left = center ? static_cast&lt;int&gt;(std::round(dw - 0.1f)) : 0;\n    int right = static_cast&lt;int&gt;(std::round(dw + 0.1f));\n\n    cv::copyMakeBorder(outImage, outImage, top, bottom, left, right,\n                       cv::BORDER_CONSTANT, paddingValue);\n}\n\n// ============================================================================\n// Coordinate Scaling\n// ============================================================================\n\ninline BoundingBox scaleCoords(const cv::Size&amp; letterboxShape,\n                               const BoundingBox&amp; coords,\n                               const cv::Size&amp; originalShape,\n                               bool clip = true) {\n\n    float gain = std::min(static_cast&lt;float&gt;(letterboxShape.height) / originalShape.height,\n                         static_cast&lt;float&gt;(letterboxShape.width) / originalShape.width);\n\n    int padX = static_cast&lt;int&gt;(std::round((letterboxShape.width - originalShape.width * gain) / 2.0f));\n    int padY = static_cast&lt;int&gt;(std::round((letterboxShape.height - originalShape.height * gain) / 2.0f));\n\n    BoundingBox result;\n    result.x = static_cast&lt;int&gt;(std::round((coords.x - padX) / gain));\n    result.y = static_cast&lt;int&gt;(std::round((coords.y - padY) / gain));\n    result.width = static_cast&lt;int&gt;(std::round(coords.width / gain));\n    result.height = static_cast&lt;int&gt;(std::round(coords.height / gain));\n\n    if (clip) {\n        result.x = utils::clamp(result.x, 0, originalShape.width);\n        result.y = utils::clamp(result.y, 0, originalShape.height);\n        result.width = utils::clamp(result.width, 0, originalShape.width - result.x);\n        result.height = utils::clamp(result.height, 0, originalShape.height - result.y);\n    }\n\n    return result;\n}\n\ninline KeyPoint scaleKeypoint(const cv::Size&amp; letterboxShape,\n                              const KeyPoint&amp; keypoint,\n                              const cv::Size&amp; originalShape,\n                              bool clip = true) {\n\n    float gain = std::min(static_cast&lt;float&gt;(letterboxShape.height) / originalShape.height,\n                         static_cast&lt;float&gt;(letterboxShape.width) / originalShape.width);\n\n    float padX = (letterboxShape.width - originalShape.width * gain) / 2.0f;\n    float padY = (letterboxShape.height - originalShape.height * gain) / 2.0f;\n\n    KeyPoint result;\n    result.x = (keypoint.x - padX) / gain;\n    result.y = (keypoint.y - padY) / gain;\n    result.confidence = keypoint.confidence;\n\n    if (clip) {\n        result.x = utils::clamp(result.x, 0.0f, static_cast&lt;float&gt;(originalShape.width - 1));\n        result.y = utils::clamp(result.y, 0.0f, static_cast&lt;float&gt;(originalShape.height - 1));\n    }\n\n    return result;\n}\n\ninline void getLetterboxParams(const cv::Size&amp; originalShape,\n                               const cv::Size&amp; letterboxShape,\n                               float&amp; scale,\n                               float&amp; padX,\n                               float&amp; padY) {\n    scale = std::min(static_cast&lt;float&gt;(letterboxShape.height) / originalShape.height,\n                    static_cast&lt;float&gt;(letterboxShape.width) / originalShape.width);\n    padX = (letterboxShape.width - originalShape.width * scale) / 2.0f;\n    padY = (letterboxShape.height - originalShape.height * scale) / 2.0f;\n}\n\n// ============================================================================\n// Optimized Single-Pass Preprocessing\n// ============================================================================\n\ninline void letterBoxToBlob(const cv::Mat&amp; image,\n                            std::vector&lt;float&gt;&amp; blob,\n                            const cv::Size&amp; targetSize,\n                            cv::Size&amp; actualSize,\n                            float padColor = 114.0f) {\n\n    const int srcH = image.rows;\n    const int srcW = image.cols;\n    const int dstH = targetSize.height;\n    const int dstW = targetSize.width;\n\n    // Calculate scale and padding (match Ultralytics exactly)\n    const float scale = std::min(static_cast&lt;float&gt;(dstH) / srcH,\n                                  static_cast&lt;float&gt;(dstW) / srcW);\n\n    // Ultralytics uses round() for new dimensions\n    const int newH = static_cast&lt;int&gt;(std::round(srcH * scale));\n    const int newW = static_cast&lt;int&gt;(std::round(srcW * scale));\n\n    // Ultralytics uses asymmetric padding with -0.1/+0.1 adjustment\n    const float dh = (dstH - newH) / 2.0f;\n    const float dw = (dstW - newW) / 2.0f;\n    const int padTop = static_cast&lt;int&gt;(std::round(dh - 0.1f));\n    const int padLeft = static_cast&lt;int&gt;(std::round(dw - 0.1f));\n\n    actualSize = cv::Size(dstW, dstH);\n\n    // Ensure blob capacity\n    const size_t totalSize = static_cast&lt;size_t&gt;(dstH * dstW * 3);\n    if (blob.size() &lt; totalSize) {\n        blob.resize(totalSize);\n    }\n\n    // Fill with padding color (normalized)\n    const float padNorm = padColor / 255.0f;\n    std::fill(blob.begin(), blob.end(), padNorm);\n\n    // Resize image\n    cv::Mat resized;\n    if (newW != srcW || newH != srcH) {\n        cv::resize(image, resized, cv::Size(newW, newH), 0, 0, cv::INTER_LINEAR);\n    } else {\n        resized = image;\n    }\n\n    // Convert BGR to RGB and normalize directly into blob (CHW format)\n    float* rChannel = blob.data();\n    float* gChannel = blob.data() + dstH * dstW;\n    float* bChannel = blob.data() + 2 * dstH * dstW;\n\n    constexpr float scale255 = 1.0f / 255.0f;\n\n    for (int y = 0; y &lt; newH; ++y) {\n        const int dstY = y + padTop;\n        const uchar* row = resized.ptr&lt;uchar&gt;(y);\n\n        for (int x = 0; x &lt; newW; ++x) {\n            const int dstX = x + padLeft;\n            const int dstIdx = dstY * dstW + dstX;\n            const int srcIdx = x * 3;\n\n            // BGR to RGB conversion + normalization\n            bChannel[dstIdx] = row[srcIdx + 0] * scale255;\n            gChannel[dstIdx] = row[srcIdx + 1] * scale255;\n            rChannel[dstIdx] = row[srcIdx + 2] * scale255;\n        }\n    }\n}\n\ninline void letterBoxToBlob(const cv::Mat&amp; image,\n                            InferenceBuffer&amp; buffer,\n                            const cv::Size&amp; targetSize,\n                            cv::Size&amp; actualSize,\n                            bool dynamicShape = false) {\n\n    const int srcH = image.rows;\n    const int srcW = image.cols;\n    int dstH = targetSize.height;\n    int dstW = targetSize.width;\n\n    // Calculate scale (match Ultralytics exactly)\n    const float scale = std::min(static_cast&lt;float&gt;(dstH) / srcH,\n                                  static_cast&lt;float&gt;(dstW) / srcW);\n\n    // Ultralytics uses round() for new dimensions\n    int newH = static_cast&lt;int&gt;(std::round(srcH * scale));\n    int newW = static_cast&lt;int&gt;(std::round(srcW * scale));\n\n    // For dynamic shape, adjust to stride-aligned minimum size\n    if (dynamicShape) {\n        constexpr int stride = 32;\n        dstH = ((newH + stride - 1) / stride) * stride;\n        dstW = ((newW + stride - 1) / stride) * stride;\n    }\n\n    actualSize = cv::Size(dstW, dstH);\n    buffer.ensureCapacity(dstH, dstW, 3);\n\n    // Ultralytics uses asymmetric padding with -0.1/+0.1 adjustment\n    const float dh = (dstH - newH) / 2.0f;\n    const float dw = (dstW - newW) / 2.0f;\n    const int padTop = static_cast&lt;int&gt;(std::round(dh - 0.1f));\n    const int padLeft = static_cast&lt;int&gt;(std::round(dw - 0.1f));\n\n    // Fill with padding (normalized 114/255)\n    constexpr float padNorm = 114.0f / 255.0f;\n    std::fill(buffer.blob.begin(), buffer.blob.begin() + dstH * dstW * 3, padNorm);\n\n    // Resize if needed\n    if (newW != srcW || newH != srcH) {\n        cv::resize(image, buffer.resized, cv::Size(newW, newH), 0, 0, cv::INTER_LINEAR);\n    } else {\n        buffer.resized = image;  // Reference, no copy\n    }\n\n    // Direct BGR-&gt;RGB + normalize to CHW blob\n    float* rChannel = buffer.blob.data();\n    float* gChannel = buffer.blob.data() + dstH * dstW;\n    float* bChannel = buffer.blob.data() + 2 * dstH * dstW;\n\n    constexpr float scale255 = 1.0f / 255.0f;\n\n    for (int y = 0; y &lt; newH; ++y) {\n        const int dstY = y + padTop;\n        const uchar* row = buffer.resized.ptr&lt;uchar&gt;(y);\n        const int rowOffset = dstY * dstW + padLeft;\n\n        for (int x = 0; x &lt; newW; ++x) {\n            const int dstIdx = rowOffset + x;\n            const int srcIdx = x * 3;\n\n            bChannel[dstIdx] = row[srcIdx + 0] * scale255;\n            gChannel[dstIdx] = row[srcIdx + 1] * scale255;\n            rChannel[dstIdx] = row[srcIdx + 2] * scale255;\n        }\n    }\n\n    buffer.lastInputSize = cv::Size(srcW, srcH);\n    buffer.lastTargetSize = actualSize;\n}\n\ninline void getScalePad(const cv::Size&amp; originalSize,\n                        const cv::Size&amp; letterboxSize,\n                        float&amp; scale,\n                        float&amp; padX,\n                        float&amp; padY) {\n    scale = std::min(static_cast&lt;float&gt;(letterboxSize.height) / originalSize.height,\n                     static_cast&lt;float&gt;(letterboxSize.width) / originalSize.width);\n\n    // Use round() for new dimensions (matches Ultralytics)\n    int newW = static_cast&lt;int&gt;(std::round(originalSize.width * scale));\n    int newH = static_cast&lt;int&gt;(std::round(originalSize.height * scale));\n\n    // For descaling, use UNROUNDED padding values (matches Ultralytics behavior)\n    padX = (letterboxSize.width - newW) / 2.0f;\n    padY = (letterboxSize.height - newH) / 2.0f;\n}\n\ninline void descaleCoordsBatch(float* coords, size_t count,\n                               float scale, float padX, float padY) {\n    const float invScale = 1.0f / scale;\n    for (size_t i = 0; i &lt; count; ++i) {\n        coords[i * 2 + 0] = (coords[i * 2 + 0] - padX) * invScale;\n        coords[i * 2 + 1] = (coords[i * 2 + 1] - padY) * invScale;\n    }\n}\n\n} // namespace preprocessing\n} // namespace yolos\n</code></pre>"},{"location":"yolos/session__base_8hpp/","title":"File session_base.hpp","text":"<p>FileList &gt; core &gt; session_base.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;onnxruntime_cxx_api.h&gt;</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;thread&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> </ul>"},{"location":"yolos/session__base_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos"},{"location":"yolos/session__base_8hpp/#classes","title":"Classes","text":"Type Name class OrtSessionBase Base class for ONNX Runtime session management Handles model loading, session configuration, and common inference setup. <p>The documentation for this class was generated from the following file <code>include/yolos/core/session_base.hpp</code></p>"},{"location":"yolos/session__base_8hpp_source/","title":"File session_base.hpp","text":"<p>File List &gt; core &gt; session_base.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO ONNX Session Base\n// ============================================================================\n// Common ONNX Runtime session setup and management for all YOLO detectors.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;onnxruntime_cxx_api.h&gt;\n#include &lt;opencv2/opencv.hpp&gt;\n\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;string&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n\nnamespace yolos {\n\n// ============================================================================\n// OrtSessionBase - Common ONNX Runtime session management\n// ============================================================================\n\nclass OrtSessionBase {\npublic:\n    OrtSessionBase(const std::string&amp; modelPath, bool useGPU = false, int numThreads = 0)\n        : env_(ORT_LOGGING_LEVEL_WARNING, \"YOLOS\") {\n\n        initSession(modelPath, useGPU, numThreads);\n    }\n\n    virtual ~OrtSessionBase() = default;\n\n    // Prevent copying\n    OrtSessionBase(const OrtSessionBase&amp;) = delete;\n    OrtSessionBase&amp; operator=(const OrtSessionBase&amp;) = delete;\n\n    // Allow moving\n    OrtSessionBase(OrtSessionBase&amp;&amp;) = default;\n    OrtSessionBase&amp; operator=(OrtSessionBase&amp;&amp;) = default;\n\n    [[nodiscard]] cv::Size getInputShape() const noexcept { return inputShape_; }\n\n    [[nodiscard]] bool isDynamicInputShape() const noexcept { return isDynamicInputShape_; }\n\n    [[nodiscard]] bool isDynamicBatchSize() const noexcept { return isDynamicBatchSize_; }\n\n    [[nodiscard]] const std::string&amp; getDevice() const noexcept { return device_; }\n\n    [[nodiscard]] size_t getNumInputNodes() const noexcept { return numInputNodes_; }\n\n    [[nodiscard]] size_t getNumOutputNodes() const noexcept { return numOutputNodes_; }\n\nprotected:\n    Ort::Env env_{nullptr};\n    Ort::SessionOptions sessionOptions_{nullptr};\n    Ort::Session session_{nullptr};\n\n    // Input/output node names\n    std::vector&lt;Ort::AllocatedStringPtr&gt; inputNameAllocs_;\n    std::vector&lt;const char*&gt; inputNames_;\n    std::vector&lt;Ort::AllocatedStringPtr&gt; outputNameAllocs_;\n    std::vector&lt;const char*&gt; outputNames_;\n\n    size_t numInputNodes_{0};\n    size_t numOutputNodes_{0};\n\n    cv::Size inputShape_;\n    bool isDynamicInputShape_{false};\n    bool isDynamicBatchSize_{false};\n    std::string device_{\"cpu\"};\n\n    std::vector&lt;Ort::Value&gt; runInference(Ort::Value&amp; inputTensor) {\n        return session_.Run(\n            Ort::RunOptions{nullptr},\n            inputNames_.data(),\n            &amp;inputTensor,\n            numInputNodes_,\n            outputNames_.data(),\n            numOutputNodes_\n        );\n    }\n\n    Ort::Value createInputTensor(float* blob, const std::vector&lt;int64_t&gt;&amp; inputTensorShape) {\n        static Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\n        size_t inputTensorSize = utils::vectorProduct(inputTensorShape);\n\n        return Ort::Value::CreateTensor&lt;float&gt;(\n            memoryInfo,\n            blob,\n            inputTensorSize,\n            inputTensorShape.data(),\n            inputTensorShape.size()\n        );\n    }\n\nprivate:\n    void initSession(const std::string&amp; modelPath, bool useGPU, int numThreads) {\n        sessionOptions_ = Ort::SessionOptions();\n\n        // Set thread count\n        int threads = (numThreads &gt; 0) ? numThreads : std::min(6, static_cast&lt;int&gt;(std::thread::hardware_concurrency()));\n        sessionOptions_.SetIntraOpNumThreads(threads);\n        sessionOptions_.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);\n\n        // Configure execution provider\n        std::vector&lt;std::string&gt; availableProviders = Ort::GetAvailableProviders();\n        auto cudaIt = std::find(availableProviders.begin(), availableProviders.end(), \"CUDAExecutionProvider\");\n\n        if (useGPU &amp;&amp; cudaIt != availableProviders.end()) {\n            OrtCUDAProviderOptions cudaOptions{};\n            sessionOptions_.AppendExecutionProvider_CUDA(cudaOptions);\n            device_ = \"gpu\";\n            std::cout &lt;&lt; \"[INFO] Inference device: GPU (CUDA)\" &lt;&lt; std::endl;\n        } else {\n            if (useGPU) {\n                std::cout &lt;&lt; \"[WARNING] GPU requested but CUDA not available. Falling back to CPU.\" &lt;&lt; std::endl;\n            }\n            device_ = \"cpu\";\n            std::cout &lt;&lt; \"[INFO] Inference device: CPU\" &lt;&lt; std::endl;\n        }\n\n        // Load model\n#ifdef _WIN32\n        std::wstring wModelPath(modelPath.begin(), modelPath.end());\n        session_ = Ort::Session(env_, wModelPath.c_str(), sessionOptions_);\n#else\n        session_ = Ort::Session(env_, modelPath.c_str(), sessionOptions_);\n#endif\n\n        // Get node counts\n        numInputNodes_ = session_.GetInputCount();\n        numOutputNodes_ = session_.GetOutputCount();\n\n        Ort::AllocatorWithDefaultOptions allocator;\n\n        // Get input node names\n        for (size_t i = 0; i &lt; numInputNodes_; ++i) {\n            auto inputName = session_.GetInputNameAllocated(i, allocator);\n            inputNameAllocs_.push_back(std::move(inputName));\n            inputNames_.push_back(inputNameAllocs_.back().get());\n        }\n\n        // Get output node names\n        for (size_t i = 0; i &lt; numOutputNodes_; ++i) {\n            auto outputName = session_.GetOutputNameAllocated(i, allocator);\n            outputNameAllocs_.push_back(std::move(outputName));\n            outputNames_.push_back(outputNameAllocs_.back().get());\n        }\n\n        // Get input shape\n        Ort::TypeInfo inputTypeInfo = session_.GetInputTypeInfo(0);\n        std::vector&lt;int64_t&gt; inputTensorShape = inputTypeInfo.GetTensorTypeAndShapeInfo().GetShape();\n\n        if (inputTensorShape.size() &gt;= 4) {\n            isDynamicBatchSize_ = (inputTensorShape[0] == -1);\n            isDynamicInputShape_ = (inputTensorShape[2] == -1 || inputTensorShape[3] == -1);\n\n            int height = (inputTensorShape[2] == -1) ? 640 : static_cast&lt;int&gt;(inputTensorShape[2]);\n            int width = (inputTensorShape[3] == -1) ? 640 : static_cast&lt;int&gt;(inputTensorShape[3]);\n            inputShape_ = cv::Size(width, height);\n        } else {\n            throw std::runtime_error(\"Invalid input tensor shape. Expected 4D tensor [N, C, H, W].\");\n        }\n\n        std::cout &lt;&lt; \"[INFO] Model loaded: \" &lt;&lt; modelPath &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"[INFO] Input shape: \" &lt;&lt; inputShape_.width &lt;&lt; \"x\" &lt;&lt; inputShape_.height\n                  &lt;&lt; (isDynamicInputShape_ ? \" (dynamic)\" : \"\") &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"[INFO] Inputs: \" &lt;&lt; numInputNodes_ &lt;&lt; \", Outputs: \" &lt;&lt; numOutputNodes_ &lt;&lt; std::endl;\n    }\n};\n\n} // namespace yolos\n</code></pre>"},{"location":"yolos/types_8hpp/","title":"File types.hpp","text":"<p>FileList &gt; core &gt; types.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> </ul>"},{"location":"yolos/types_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos"},{"location":"yolos/types_8hpp/#classes","title":"Classes","text":"Type Name struct BoundingBox struct KeyPoint struct OrientedBoundingBox <p>The documentation for this class was generated from the following file <code>include/yolos/core/types.hpp</code></p>"},{"location":"yolos/types_8hpp_source/","title":"File types.hpp","text":"<p>File List &gt; core &gt; types.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Core Types\n// ============================================================================\n// Single source of truth for shared data structures used across all YOLO tasks.\n// \n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;cmath&gt;\n\nnamespace yolos {\n\n// ============================================================================\n// BoundingBox - Axis-aligned bounding box for detection, segmentation, pose\n// ============================================================================\nstruct BoundingBox {\n    int x{0};       \n    int y{0};       \n    int width{0};   \n    int height{0};  \n\n    BoundingBox() = default;\n\n    BoundingBox(int x_, int y_, int width_, int height_)\n        : x(x_), y(y_), width(width_), height(height_) {}\n\n    [[nodiscard]] float area() const noexcept {\n        return static_cast&lt;float&gt;(width * height);\n    }\n\n    [[nodiscard]] BoundingBox intersect(const BoundingBox&amp; other) const noexcept {\n        int xStart = std::max(x, other.x);\n        int yStart = std::max(y, other.y);\n        int xEnd = std::min(x + width, other.x + other.width);\n        int yEnd = std::min(y + height, other.y + other.height);\n        int iw = std::max(0, xEnd - xStart);\n        int ih = std::max(0, yEnd - yStart);\n        return BoundingBox(xStart, yStart, iw, ih);\n    }\n\n    [[nodiscard]] float iou(const BoundingBox&amp; other) const noexcept {\n        BoundingBox inter = intersect(other);\n        float interArea = inter.area();\n        float unionArea = area() + other.area() - interArea;\n        return (unionArea &gt; 0.0f) ? (interArea / unionArea) : 0.0f;\n    }\n};\n\n// ============================================================================\n// OrientedBoundingBox - Rotated bounding box for OBB detection\n// ============================================================================\nstruct OrientedBoundingBox {\n    float x{0.0f};       \n    float y{0.0f};       \n    float width{0.0f};   \n    float height{0.0f};  \n    float angle{0.0f};   \n\n    OrientedBoundingBox() = default;\n\n    OrientedBoundingBox(float x_, float y_, float width_, float height_, float angle_)\n        : x(x_), y(y_), width(width_), height(height_), angle(angle_) {}\n\n    [[nodiscard]] float area() const noexcept {\n        return width * height;\n    }\n};\n\n// ============================================================================\n// KeyPoint - Single keypoint for pose estimation\n// ============================================================================\nstruct KeyPoint {\n    float x{0.0f};          \n    float y{0.0f};          \n    float confidence{0.0f}; \n\n    KeyPoint() = default;\n\n    KeyPoint(float x_, float y_, float conf_ = 0.0f)\n        : x(x_), y(y_), confidence(conf_) {}\n};\n\n// ============================================================================\n// Skeleton connections for COCO pose format (17 keypoints)\n// ============================================================================\ninline const std::vector&lt;std::pair&lt;int, int&gt;&gt;&amp; getPoseSkeleton() {\n    static const std::vector&lt;std::pair&lt;int, int&gt;&gt; POSE_SKELETON = {\n        // Face connections\n        {0, 1}, {0, 2}, {1, 3}, {2, 4},\n        // Head-to-shoulder connections\n        {3, 5}, {4, 6},\n        // Arms\n        {5, 7}, {7, 9}, {6, 8}, {8, 10},\n        // Body\n        {5, 6}, {5, 11}, {6, 12}, {11, 12},\n        // Legs\n        {11, 13}, {13, 15}, {12, 14}, {14, 16}\n    };\n    return POSE_SKELETON;\n}\n\n} // namespace yolos\n</code></pre>"},{"location":"yolos/utils_8hpp/","title":"File utils.hpp","text":"<p>FileList &gt; core &gt; utils.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;numeric&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;type_traits&gt;</code></li> <li><code>#include &lt;cstdint&gt;</code></li> </ul>"},{"location":"yolos/utils_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace utils <p>The documentation for this class was generated from the following file <code>include/yolos/core/utils.hpp</code></p>"},{"location":"yolos/utils_8hpp_source/","title":"File utils.hpp","text":"<p>File List &gt; core &gt; utils.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Core Utilities\n// ============================================================================\n// Common utility functions used across all YOLO tasks.\n// All functions are marked inline to prevent ODR violations.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;algorithm&gt;\n#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;numeric&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n#include &lt;type_traits&gt;\n#include &lt;cstdint&gt;\n\nnamespace yolos {\nnamespace utils {\n\n// ============================================================================\n// Math Utilities\n// ============================================================================\n\ntemplate &lt;typename T&gt;\ninline typename std::enable_if&lt;std::is_arithmetic&lt;T&gt;::value, T&gt;::type\nclamp(const T&amp; value, const T&amp; low, const T&amp; high) {\n    // Ensure range is valid; swap if necessary\n    T validLow = low &lt; high ? low : high;\n    T validHigh = low &lt; high ? high : low;\n\n    if (value &lt; validLow) return validLow;\n    if (value &gt; validHigh) return validHigh;\n    return value;\n}\n\ninline size_t vectorProduct(const std::vector&lt;int64_t&gt;&amp; shape) {\n    if (shape.empty()) return 0;\n    return std::accumulate(shape.begin(), shape.end(), 1ULL, std::multiplies&lt;size_t&gt;());\n}\n\n// ============================================================================\n// File I/O Utilities\n// ============================================================================\n\ninline std::vector&lt;std::string&gt; getClassNames(const std::string&amp; path) {\n    std::vector&lt;std::string&gt; classNames;\n    std::ifstream infile(path);\n\n    if (!infile) {\n        std::cerr &lt;&lt; \"[ERROR] Failed to open class names file: \" &lt;&lt; path &lt;&lt; std::endl;\n        return classNames;\n    }\n\n    std::string line;\n    while (std::getline(infile, line)) {\n        // Remove carriage return if present (Windows compatibility)\n        if (!line.empty() &amp;&amp; line.back() == '\\r') {\n            line.pop_back();\n        }\n        if (!line.empty()) {\n            classNames.emplace_back(line);\n        }\n    }\n\n    return classNames;\n}\n\n// ============================================================================\n// Sigmoid Activation\n// ============================================================================\n\ninline float sigmoid(float x) {\n    return 1.0f / (1.0f + std::exp(-x));\n}\n\ninline void sigmoidInplace(std::vector&lt;float&gt;&amp; values) {\n    for (auto&amp; v : values) {\n        v = sigmoid(v);\n    }\n}\n\n} // namespace utils\n} // namespace yolos\n</code></pre>"},{"location":"yolos/version_8hpp/","title":"File version.hpp","text":"<p>FileList &gt; core &gt; version.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;cstdint&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> </ul>"},{"location":"yolos/version_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace version <p>The documentation for this class was generated from the following file <code>include/yolos/core/version.hpp</code></p>"},{"location":"yolos/version_8hpp_source/","title":"File version.hpp","text":"<p>File List &gt; core &gt; version.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Version Detection\n// ============================================================================\n// Defines YOLO model version enum and utilities for runtime version detection\n// based on output tensor shapes.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;vector&gt;\n#include &lt;cstdint&gt;\n#include &lt;string&gt;\n\nnamespace yolos {\n\n// ============================================================================\n// YOLOVersion Enum\n// ============================================================================\nenum class YOLOVersion {\n    Auto,   \n    V7,     \n    V8,     \n    V10,    \n    V11,    \n    V12,    \n    V26,    \n    NAS     \n};\n\n// ============================================================================\n// Version Detection Utilities\n// ============================================================================\nnamespace version {\n\ninline std::string toString(YOLOVersion version) {\n    switch (version) {\n        case YOLOVersion::Auto: return \"Auto\";\n        case YOLOVersion::V7:   return \"YOLOv7\";\n        case YOLOVersion::V8:   return \"YOLOv8\";\n        case YOLOVersion::V10:  return \"YOLOv10\";\n        case YOLOVersion::V11:  return \"YOLOv11\";\n        case YOLOVersion::V12:  return \"YOLOv12\";\n        case YOLOVersion::V26:  return \"YOLOv26\";\n        case YOLOVersion::NAS:  return \"YOLO-NAS\";\n        default: return \"Unknown\";\n    }\n}\n\ninline YOLOVersion detectFromOutputShape(const std::vector&lt;int64_t&gt;&amp; outputShape, size_t numOutputs = 1) {\n    // YOLO-NAS has 2 outputs: boxes and scores\n    if (numOutputs == 2) {\n        return YOLOVersion::NAS;\n    }\n\n    // Must have at least 3 dimensions for detection models\n    if (outputShape.size() &lt; 3) {\n        return YOLOVersion::V11; // Default fallback\n    }\n\n    const int64_t dim1 = outputShape[1];\n    const int64_t dim2 = outputShape[2];\n\n    // YOLOv10: [batch, num_boxes, 6] - end-to-end format\n    if (dim2 == 6) {\n        return YOLOVersion::V10;\n    }\n\n    // YOLO-NAS single output: [batch, num_boxes, 4] for boxes only\n    if (dim2 == 4 &amp;&amp; numOutputs == 1) {\n        return YOLOVersion::NAS;\n    }\n\n    // YOLOv7: [batch, num_boxes, num_features] where num_boxes &gt; num_features\n    // V7 uses format [batch, 25200, 85] typically\n    if (dim1 &gt; dim2) {\n        return YOLOVersion::V7;\n    }\n\n    // YOLOv8/v11: [batch, num_features, num_boxes] where num_features &lt; num_boxes\n    // Typical: [1, 84, 8400] for 80 classes\n    return YOLOVersion::V11;\n}\n\ninline YOLOVersion detectClassificationVersion(const std::vector&lt;int64_t&gt;&amp; outputShape) {\n    // Classification models typically have [batch, num_classes] output\n    // V11 and V12 have same format, default to V11\n    return YOLOVersion::V11;\n}\n\ninline bool requiresNMS(YOLOVersion version) {\n    // YOLOv10 and YOLOv26 have end-to-end NMS built into the model\n    return version != YOLOVersion::V10 &amp;&amp; version != YOLOVersion::V26;\n}\n\n} // namespace version\n\n} // namespace yolos\n</code></pre>"},{"location":"yolos/dir_2bef6d8bc01c1b0d186aba6b16825c1e/","title":"Dir include/yolos/tasks","text":"<p>FileList &gt; include &gt; yolos &gt; tasks</p>"},{"location":"yolos/dir_2bef6d8bc01c1b0d186aba6b16825c1e/#files","title":"Files","text":"Type Name file classification.hpp file detection.hpp file obb.hpp file pose.hpp file segmentation.hpp <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/</code></p>"},{"location":"yolos/classification_8hpp/","title":"File classification.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; tasks &gt; classification.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;onnxruntime_cxx_api.h&gt;</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;iomanip&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;numeric&gt;</code></li> <li><code>#include &lt;sstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;thread&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> </ul>"},{"location":"yolos/classification_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace cls"},{"location":"yolos/classification_8hpp/#classes","title":"Classes","text":"Type Name struct ClassificationResult Classification result containing class ID, confidence, and class name. class YOLO11Classifier YOLOv11 classifier. class YOLO12Classifier YOLOv12 classifier. class YOLO26Classifier YOLO26 classifier. class YOLOClassifier YOLO classifier for image classification. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/classification.hpp</code></p>"},{"location":"yolos/classification_8hpp_source/","title":"File classification.hpp","text":"<p>File List &gt; include &gt; yolos &gt; tasks &gt; classification.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Image Classification\n// ============================================================================\n// Image classification using YOLO models (v11, v12, YOLO26).\n// Supports efficient classification with Ultralytics-style preprocessing.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;onnxruntime_cxx_api.h&gt;\n\n#include &lt;algorithm&gt;\n#include &lt;fstream&gt;\n#include &lt;iomanip&gt;\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;numeric&gt;\n#include &lt;sstream&gt;\n#include &lt;string&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n\nnamespace yolos {\nnamespace cls {\n\n// ============================================================================\n// Classification Result Structure\n// ============================================================================\n\nstruct ClassificationResult {\n    int classId{-1};          \n    float confidence{0.0f};   \n    std::string className{};  \n\n    ClassificationResult() = default;\n    ClassificationResult(int id, float conf, std::string name)\n        : classId(id), confidence(conf), className(std::move(name)) {}\n};\n\n// ============================================================================\n// Drawing Utility for Classification\n// ============================================================================\n\ninline void drawClassificationResult(cv::Mat&amp; image,\n                                     const ClassificationResult&amp; result,\n                                     const cv::Point&amp; position = cv::Point(10, 30),\n                                     const cv::Scalar&amp; textColor = cv::Scalar(0, 255, 0),\n                                     const cv::Scalar&amp; bgColor = cv::Scalar(0, 0, 0)) {\n    if (image.empty() || result.classId == -1) return;\n\n    std::ostringstream ss;\n    ss &lt;&lt; result.className &lt;&lt; \": \" &lt;&lt; std::fixed &lt;&lt; std::setprecision(1) &lt;&lt; result.confidence * 100 &lt;&lt; \"%\";\n    std::string text = ss.str();\n\n    int fontFace = cv::FONT_HERSHEY_SIMPLEX;\n    double fontScale = std::min(image.rows, image.cols) * 0.001;\n    fontScale = std::max(fontScale, 0.5);\n    int thickness = std::max(1, static_cast&lt;int&gt;(fontScale * 2));\n    int baseline = 0;\n\n    cv::Size textSize = cv::getTextSize(text, fontFace, fontScale, thickness, &amp;baseline);\n\n    cv::Point textPos = position;\n    textPos.y = std::max(textPos.y, textSize.height + 5);\n\n    cv::Point bgTopLeft(textPos.x - 2, textPos.y - textSize.height - 5);\n    cv::Point bgBottomRight(textPos.x + textSize.width + 2, textPos.y + 5);\n\n    bgTopLeft.x = utils::clamp(bgTopLeft.x, 0, image.cols - 1);\n    bgTopLeft.y = utils::clamp(bgTopLeft.y, 0, image.rows - 1);\n    bgBottomRight.x = utils::clamp(bgBottomRight.x, 0, image.cols - 1);\n    bgBottomRight.y = utils::clamp(bgBottomRight.y, 0, image.rows - 1);\n\n    cv::rectangle(image, bgTopLeft, bgBottomRight, bgColor, cv::FILLED);\n    cv::putText(image, text, textPos, fontFace, fontScale, textColor, thickness, cv::LINE_AA);\n}\n\n// ============================================================================\n// YOLOClassifier Base Class\n// ============================================================================\n\nclass YOLOClassifier {\npublic:\n    YOLOClassifier(const std::string&amp; modelPath,\n                   const std::string&amp; labelsPath,\n                   bool useGPU = false,\n                   const cv::Size&amp; targetInputShape = cv::Size(224, 224))\n        : inputImageShape_(targetInputShape),\n          env_(ORT_LOGGING_LEVEL_WARNING, \"YOLOClassifier\") {\n\n        initSession(modelPath, useGPU);\n        classNames_ = utils::getClassNames(labelsPath);\n    }\n\n    virtual ~YOLOClassifier() = default;\n\n    ClassificationResult classify(const cv::Mat&amp; image) {\n        if (image.empty()) return {};\n\n        // Preprocess\n        std::vector&lt;int64_t&gt; inputTensorShape;\n        preprocess(image, inputTensorShape);\n\n        // Create input tensor\n        size_t inputTensorSize = utils::vectorProduct(inputTensorShape);\n        static Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\n        Ort::Value inputTensor = Ort::Value::CreateTensor&lt;float&gt;(\n            memoryInfo, inputBuffer_.data(), inputTensorSize,\n            inputTensorShape.data(), inputTensorShape.size());\n\n        // Run inference\n        std::vector&lt;Ort::Value&gt; outputTensors = session_.Run(\n            Ort::RunOptions{nullptr},\n            inputNames_.data(), &amp;inputTensor, numInputNodes_,\n            outputNames_.data(), numOutputNodes_);\n\n        if (outputTensors.empty()) return {};\n\n        return postprocess(outputTensors);\n    }\n\n    void drawResult(cv::Mat&amp; image, const ClassificationResult&amp; result,\n                    const cv::Point&amp; position = cv::Point(10, 30)) const {\n        drawClassificationResult(image, result, position);\n    }\n\n    [[nodiscard]] cv::Size getInputShape() const { return inputImageShape_; }\n\n    [[nodiscard]] bool isDynamicInputShape() const { return isDynamicInputShape_; }\n\n    [[nodiscard]] const std::vector&lt;std::string&gt;&amp; getClassNames() const { return classNames_; }\n\nprotected:\n    cv::Size inputImageShape_;\n    Ort::Env env_{nullptr};\n    Ort::SessionOptions sessionOptions_{nullptr};\n    Ort::Session session_{nullptr};\n    bool isDynamicInputShape_{false};\n    std::vector&lt;float&gt; inputBuffer_;\n\n    std::vector&lt;Ort::AllocatedStringPtr&gt; inputNameAllocs_;\n    std::vector&lt;const char*&gt; inputNames_;\n    std::vector&lt;Ort::AllocatedStringPtr&gt; outputNameAllocs_;\n    std::vector&lt;const char*&gt; outputNames_;\n\n    size_t numInputNodes_{0};\n    size_t numOutputNodes_{0};\n    int numClasses_{0};\n    std::vector&lt;std::string&gt; classNames_;\n\n    void initSession(const std::string&amp; modelPath, bool useGPU) {\n        sessionOptions_ = Ort::SessionOptions();\n        sessionOptions_.SetIntraOpNumThreads(std::min(4, static_cast&lt;int&gt;(std::thread::hardware_concurrency())));\n        sessionOptions_.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);\n\n        std::vector&lt;std::string&gt; providers = Ort::GetAvailableProviders();\n        if (useGPU &amp;&amp; std::find(providers.begin(), providers.end(), \"CUDAExecutionProvider\") != providers.end()) {\n            OrtCUDAProviderOptions cudaOptions{};\n            sessionOptions_.AppendExecutionProvider_CUDA(cudaOptions);\n            std::cout &lt;&lt; \"[INFO] Classification using GPU (CUDA)\" &lt;&lt; std::endl;\n        } else {\n            std::cout &lt;&lt; \"[INFO] Classification using CPU\" &lt;&lt; std::endl;\n        }\n\n#ifdef _WIN32\n        std::wstring wModelPath(modelPath.begin(), modelPath.end());\n        session_ = Ort::Session(env_, wModelPath.c_str(), sessionOptions_);\n#else\n        session_ = Ort::Session(env_, modelPath.c_str(), sessionOptions_);\n#endif\n\n        Ort::AllocatorWithDefaultOptions allocator;\n\n        numInputNodes_ = session_.GetInputCount();\n        numOutputNodes_ = session_.GetOutputCount();\n\n        // Input node\n        auto inputName = session_.GetInputNameAllocated(0, allocator);\n        inputNameAllocs_.push_back(std::move(inputName));\n        inputNames_.push_back(inputNameAllocs_.back().get());\n\n        Ort::TypeInfo inputTypeInfo = session_.GetInputTypeInfo(0);\n        std::vector&lt;int64_t&gt; inputShape = inputTypeInfo.GetTensorTypeAndShapeInfo().GetShape();\n        if (inputShape.size() == 4) {\n            isDynamicInputShape_ = (inputShape[2] == -1 || inputShape[3] == -1);\n            if (!isDynamicInputShape_) {\n                inputImageShape_ = cv::Size(static_cast&lt;int&gt;(inputShape[3]), static_cast&lt;int&gt;(inputShape[2]));\n            }\n        }\n\n        // Output node\n        auto outputName = session_.GetOutputNameAllocated(0, allocator);\n        outputNameAllocs_.push_back(std::move(outputName));\n        outputNames_.push_back(outputNameAllocs_.back().get());\n\n        Ort::TypeInfo outputTypeInfo = session_.GetOutputTypeInfo(0);\n        std::vector&lt;int64_t&gt; outputShape = outputTypeInfo.GetTensorTypeAndShapeInfo().GetShape();\n        if (outputShape.size() &gt;= 2) {\n            numClasses_ = static_cast&lt;int&gt;(outputShape.back());\n        } else if (outputShape.size() == 1) {\n            numClasses_ = static_cast&lt;int&gt;(outputShape[0]);\n        }\n\n        std::cout &lt;&lt; \"[INFO] Classification model loaded: \" &lt;&lt; modelPath &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"[INFO] Input shape: \" &lt;&lt; inputImageShape_.width &lt;&lt; \"x\" &lt;&lt; inputImageShape_.height &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"[INFO] Number of classes: \" &lt;&lt; numClasses_ &lt;&lt; std::endl;\n    }\n\n    void preprocess(const cv::Mat&amp; image, std::vector&lt;int64_t&gt;&amp; inputTensorShape) {\n        int targetSize = inputImageShape_.width;\n        int h = image.rows;\n        int w = image.cols;\n\n        // Resize: shortest side to target_size, maintaining aspect ratio\n        // Use truncation (not round) to match torchvision.transforms.Resize behavior\n        int newH, newW;\n        if (h &lt; w) {\n            newH = targetSize;\n            newW = static_cast&lt;int&gt;(w * targetSize / h);  // Truncate like Python int()\n        } else {\n            newW = targetSize;\n            newH = static_cast&lt;int&gt;(h * targetSize / w);  // Truncate like Python int()\n        }\n\n        cv::Mat rgbImage;\n        cv::cvtColor(image, rgbImage, cv::COLOR_BGR2RGB);\n\n        cv::Mat resized;\n        cv::resize(rgbImage, resized, cv::Size(newW, newH), 0, 0, cv::INTER_LINEAR);\n\n        // Center crop to target_size x target_size\n        int yStart = std::max(0, (newH - targetSize) / 2);\n        int xStart = std::max(0, (newW - targetSize) / 2);\n        cv::Mat cropped = resized(cv::Rect(xStart, yStart, targetSize, targetSize));\n\n        // Normalize to [0, 1]\n        cv::Mat floatImage;\n        cropped.convertTo(floatImage, CV_32F, 1.0 / 255.0);\n\n        inputTensorShape = {1, 3, floatImage.rows, floatImage.cols};\n        const int finalH = floatImage.rows;\n        const int finalW = floatImage.cols;\n        size_t tensorSize = 3 * finalH * finalW;\n        inputBuffer_.resize(tensorSize);\n\n        // Convert HWC to CHW format\n        std::vector&lt;cv::Mat&gt; channels(3);\n        cv::split(floatImage, channels);\n        for (int c = 0; c &lt; 3; ++c) {\n            std::memcpy(inputBuffer_.data() + c * finalH * finalW,\n                       channels[c].ptr&lt;float&gt;(), finalH * finalW * sizeof(float));\n        }\n    }\n\n    ClassificationResult postprocess(const std::vector&lt;Ort::Value&gt;&amp; outputTensors) {\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        int numScores = numClasses_ &gt; 0 ? numClasses_ : static_cast&lt;int&gt;(classNames_.size());\n        if (numScores &lt;= 0) return {};\n\n        // Find max score (YOLO classification ONNX export includes softmax, outputs are probabilities)\n        int bestClassId = 0;\n        float maxProb = rawOutput[0];\n\n        for (int i = 1; i &lt; numScores; ++i) {\n            if (rawOutput[i] &gt; maxProb) {\n                maxProb = rawOutput[i];\n                bestClassId = i;\n            }\n        }\n\n        std::string className = (bestClassId &gt;= 0 &amp;&amp; static_cast&lt;size_t&gt;(bestClassId) &lt; classNames_.size())\n                               ? classNames_[bestClassId]\n                               : (\"Class_\" + std::to_string(bestClassId));\n\n        return ClassificationResult(bestClassId, maxProb, className);\n    }\n};\n\n// ============================================================================\n// Version-Specific Classifier Subclasses\n// ============================================================================\n\nclass YOLO11Classifier : public YOLOClassifier {\npublic:\n    YOLO11Classifier(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLOClassifier(modelPath, labelsPath, useGPU) {}\n};\n\nclass YOLO12Classifier : public YOLOClassifier {\npublic:\n    YOLO12Classifier(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLOClassifier(modelPath, labelsPath, useGPU) {}\n};\n\nclass YOLO26Classifier : public YOLOClassifier {\npublic:\n    YOLO26Classifier(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLOClassifier(modelPath, labelsPath, useGPU) {}\n};\n\n// ============================================================================\n// Factory Function\n// ============================================================================\n\ninline std::unique_ptr&lt;YOLOClassifier&gt; createClassifier(const std::string&amp; modelPath,\n                                                        const std::string&amp; labelsPath,\n                                                        YOLOVersion version = YOLOVersion::V11,\n                                                        bool useGPU = false) {\n    switch (version) {\n        case YOLOVersion::V26:\n            return std::make_unique&lt;YOLO26Classifier&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::V12:\n            return std::make_unique&lt;YOLO12Classifier&gt;(modelPath, labelsPath, useGPU);\n        default:\n            return std::make_unique&lt;YOLO11Classifier&gt;(modelPath, labelsPath, useGPU);\n    }\n}\n\n} // namespace cls\n} // namespace yolos\n</code></pre>"},{"location":"yolos/detection_8hpp/","title":"File detection.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; tasks &gt; detection.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;cfloat&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> <li><code>#include \"yolos/core/preprocessing.hpp\"</code></li> <li><code>#include \"yolos/core/nms.hpp\"</code></li> <li><code>#include \"yolos/core/drawing.hpp\"</code></li> <li><code>#include \"yolos/core/session_base.hpp\"</code></li> </ul>"},{"location":"yolos/detection_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace det"},{"location":"yolos/detection_8hpp/#classes","title":"Classes","text":"Type Name struct Detection Detection result containing bounding box, confidence, and class ID. class YOLO26Detector YOLOv26 detector (forces V26 end-to-end postprocessing) class YOLODetector Base YOLO detector with runtime version auto-detection. class YOLONASDetector YOLO-NAS detector (forces NAS postprocessing) class YOLOv10Detector YOLOv10 detector (forces V10 end-to-end postprocessing) class YOLOv11Detector YOLOv11 detector (forces standard postprocessing) class YOLOv7Detector YOLOv7 detector (forces V7 postprocessing) class YOLOv8Detector YOLOv8 detector (forces standard postprocessing) <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/detection.hpp</code></p>"},{"location":"yolos/detection_8hpp_source/","title":"File detection.hpp","text":"<p>File List &gt; include &gt; yolos &gt; tasks &gt; detection.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Object Detection\n// ============================================================================\n// Object detection using YOLO models with support for multiple versions\n// (v7, v8, v10, v11, NAS) through runtime auto-detection or explicit selection.\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;memory&gt;\n#include &lt;cfloat&gt;\n\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n#include \"yolos/core/preprocessing.hpp\"\n#include \"yolos/core/nms.hpp\"\n#include \"yolos/core/drawing.hpp\"\n#include \"yolos/core/session_base.hpp\"\n\nnamespace yolos {\nnamespace det {\n\n// ============================================================================\n// Detection Result Structure\n// ============================================================================\n\nstruct Detection {\n    BoundingBox box;    \n    float conf{0.0f};   \n    int classId{-1};    \n\n    Detection() = default;\n    Detection(const BoundingBox&amp; box_, float conf_, int classId_)\n        : box(box_), conf(conf_), classId(classId_) {}\n};\n\n// ============================================================================\n// YOLODetector Base Class\n// ============================================================================\n\nclass YOLODetector : public OrtSessionBase {\npublic:\n    YOLODetector(const std::string&amp; modelPath,\n                 const std::string&amp; labelsPath,\n                 bool useGPU = false,\n                 YOLOVersion version = YOLOVersion::Auto)\n        : OrtSessionBase(modelPath, useGPU),\n          version_(version) {\n        classNames_ = utils::getClassNames(labelsPath);\n        classColors_ = drawing::generateColors(classNames_);\n\n        // Pre-allocate inference buffer\n        buffer_.ensureCapacity(inputShape_.height, inputShape_.width, 3);\n    }\n\n    virtual ~YOLODetector() = default;\n\n    virtual std::vector&lt;Detection&gt; detect(const cv::Mat&amp; image,\n                                          float confThreshold = 0.4f,\n                                          float iouThreshold = 0.45f) {\n        // Optimized preprocessing with buffer reuse\n        cv::Size actualSize;\n        preprocessing::letterBoxToBlob(image, buffer_, inputShape_, actualSize, isDynamicInputShape_);\n\n        // Create input tensor (uses pre-allocated blob)\n        std::vector&lt;int64_t&gt; inputTensorShape = {1, 3, actualSize.height, actualSize.width};\n        Ort::Value inputTensor = createInputTensor(buffer_.blob.data(), inputTensorShape);\n\n        // Run inference\n        std::vector&lt;Ort::Value&gt; outputTensors = runInference(inputTensor);\n\n        // Determine version if auto\n        YOLOVersion effectiveVersion = version_;\n        if (effectiveVersion == YOLOVersion::Auto) {\n            effectiveVersion = detectVersion(outputTensors);\n        }\n\n        // Postprocess based on version\n        return postprocess(image.size(), actualSize, outputTensors, effectiveVersion, confThreshold, iouThreshold);\n    }\n\n    void drawDetections(cv::Mat&amp; image, const std::vector&lt;Detection&gt;&amp; detections) const {\n        for (const auto&amp; det : detections) {\n            if (det.classId &gt;= 0 &amp;&amp; static_cast&lt;size_t&gt;(det.classId) &lt; classNames_.size()) {\n                std::string label = classNames_[det.classId] + \": \" +\n                                   std::to_string(static_cast&lt;int&gt;(det.conf * 100)) + \"%\";\n                const cv::Scalar&amp; color = classColors_[det.classId % classColors_.size()];\n                drawing::drawBoundingBox(image, det.box, label, color);\n            }\n        }\n    }\n\n    void drawDetectionsWithMask(cv::Mat&amp; image, const std::vector&lt;Detection&gt;&amp; detections, float alpha = 0.4f) const {\n        for (const auto&amp; det : detections) {\n            if (det.classId &gt;= 0 &amp;&amp; static_cast&lt;size_t&gt;(det.classId) &lt; classNames_.size()) {\n                std::string label = classNames_[det.classId] + \": \" +\n                                   std::to_string(static_cast&lt;int&gt;(det.conf * 100)) + \"%\";\n                const cv::Scalar&amp; color = classColors_[det.classId % classColors_.size()];\n                drawing::drawBoundingBoxWithMask(image, det.box, label, color, alpha);\n            }\n        }\n    }\n\n    [[nodiscard]] const std::vector&lt;std::string&gt;&amp; getClassNames() const { return classNames_; }\n\n    [[nodiscard]] const std::vector&lt;cv::Scalar&gt;&amp; getClassColors() const { return classColors_; }\n\nprotected:\n    YOLOVersion version_{YOLOVersion::Auto};\n    std::vector&lt;std::string&gt; classNames_;\n    std::vector&lt;cv::Scalar&gt; classColors_;\n\n    // Pre-allocated buffer for inference (avoids per-frame allocations)\n    mutable preprocessing::InferenceBuffer buffer_;\n\n    YOLOVersion detectVersion(const std::vector&lt;Ort::Value&gt;&amp; outputTensors) {\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n        return version::detectFromOutputShape(outputShape, outputTensors.size());\n    }\n\n    virtual std::vector&lt;Detection&gt; postprocess(const cv::Size&amp; originalSize,\n                                               const cv::Size&amp; resizedShape,\n                                               const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                               YOLOVersion version,\n                                               float confThreshold,\n                                               float iouThreshold) {\n        switch (version) {\n            case YOLOVersion::V7:\n                return postprocessV7(originalSize, resizedShape, outputTensors, confThreshold, iouThreshold);\n            case YOLOVersion::V10:\n            case YOLOVersion::V26:\n                return postprocessV10(originalSize, resizedShape, outputTensors, confThreshold, iouThreshold);\n            case YOLOVersion::NAS:\n                return postprocessNAS(originalSize, resizedShape, outputTensors, confThreshold, iouThreshold);\n            default:\n                return postprocessStandard(originalSize, resizedShape, outputTensors, confThreshold, iouThreshold);\n        }\n    }\n\n    virtual std::vector&lt;Detection&gt; postprocessStandard(const cv::Size&amp; originalSize,\n                                                       const cv::Size&amp; resizedShape,\n                                                       const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                                       float confThreshold,\n                                                       float iouThreshold) {\n        std::vector&lt;Detection&gt; detections;\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        const size_t numFeatures = outputShape[1];\n        const size_t numDetections = outputShape[2];\n\n        if (numDetections == 0) return detections;\n\n        const int numClasses = static_cast&lt;int&gt;(numFeatures) - 4;\n        if (numClasses &lt;= 0) return detections;\n\n        // Pre-compute scale and padding once\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        std::vector&lt;BoundingBox&gt; boxes;\n        std::vector&lt;float&gt; confs;\n        std::vector&lt;int&gt; classIds;\n        boxes.reserve(256);  // Reasonable initial capacity\n        confs.reserve(256);\n        classIds.reserve(256);\n\n        for (size_t d = 0; d &lt; numDetections; ++d) {\n            // Quick reject: check if any class score could exceed threshold\n            // by checking box coordinates are valid first\n            const float centerX = rawOutput[0 * numDetections + d];\n            const float centerY = rawOutput[1 * numDetections + d];\n            const float width = rawOutput[2 * numDetections + d];\n            const float height = rawOutput[3 * numDetections + d];\n\n            // Find max class score\n            int classId = 0;\n            float maxScore = rawOutput[4 * numDetections + d];\n            for (int c = 1; c &lt; numClasses; ++c) {\n                const float score = rawOutput[(4 + c) * numDetections + d];\n                if (score &gt; maxScore) {\n                    maxScore = score;\n                    classId = c;\n                }\n            }\n\n            if (maxScore &gt; confThreshold) {\n                // Convert center to corner and descale in one step\n                const float left = (centerX - width * 0.5f - padX) * invScale;\n                const float top = (centerY - height * 0.5f - padY) * invScale;\n                const float w = width * invScale;\n                const float h = height * invScale;\n\n                // Clip to image bounds\n                BoundingBox box;\n                box.x = utils::clamp(static_cast&lt;int&gt;(left), 0, originalSize.width - 1);\n                box.y = utils::clamp(static_cast&lt;int&gt;(top), 0, originalSize.height - 1);\n                box.width = utils::clamp(static_cast&lt;int&gt;(w), 1, originalSize.width - box.x);\n                box.height = utils::clamp(static_cast&lt;int&gt;(h), 1, originalSize.height - box.y);\n\n                boxes.push_back(box);\n                confs.push_back(maxScore);\n                classIds.push_back(classId);\n            }\n        }\n\n        // Batched NMS (handles class offsets internally)\n        std::vector&lt;int&gt; indices;\n        nms::NMSBoxesBatched(boxes, confs, classIds, confThreshold, iouThreshold, indices);\n\n        detections.reserve(indices.size());\n        for (int idx : indices) {\n            detections.emplace_back(boxes[idx], confs[idx], classIds[idx]);\n        }\n\n        return detections;\n    }\n\n    virtual std::vector&lt;Detection&gt; postprocessV7(const cv::Size&amp; originalSize,\n                                                 const cv::Size&amp; resizedShape,\n                                                 const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                                 float confThreshold,\n                                                 float iouThreshold) {\n        std::vector&lt;Detection&gt; detections;\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        const size_t numDetections = outputShape[1];\n        const size_t numFeatures = outputShape[2];\n\n        if (numDetections == 0) return detections;\n\n        const int numClasses = static_cast&lt;int&gt;(numFeatures) - 5;\n        if (numClasses &lt;= 0) return detections;\n\n        // Pre-compute scale and padding\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        std::vector&lt;BoundingBox&gt; boxes;\n        std::vector&lt;float&gt; confs;\n        std::vector&lt;int&gt; classIds;\n        boxes.reserve(256);\n        confs.reserve(256);\n        classIds.reserve(256);\n\n        for (size_t d = 0; d &lt; numDetections; ++d) {\n            const float objConf = rawOutput[d * numFeatures + 4];\n            if (objConf &lt;= confThreshold) continue;\n\n            const float centerX = rawOutput[d * numFeatures + 0];\n            const float centerY = rawOutput[d * numFeatures + 1];\n            const float width = rawOutput[d * numFeatures + 2];\n            const float height = rawOutput[d * numFeatures + 3];\n\n            int classId = 0;\n            float maxScore = rawOutput[d * numFeatures + 5];\n            for (int c = 1; c &lt; numClasses; ++c) {\n                const float score = rawOutput[d * numFeatures + 5 + c];\n                if (score &gt; maxScore) {\n                    maxScore = score;\n                    classId = c;\n                }\n            }\n\n            // Convert and descale in one step\n            const float left = (centerX - width * 0.5f - padX) * invScale;\n            const float top = (centerY - height * 0.5f - padY) * invScale;\n\n            BoundingBox box;\n            box.x = utils::clamp(static_cast&lt;int&gt;(left), 0, originalSize.width - 1);\n            box.y = utils::clamp(static_cast&lt;int&gt;(top), 0, originalSize.height - 1);\n            box.width = utils::clamp(static_cast&lt;int&gt;(width * invScale), 1, originalSize.width - box.x);\n            box.height = utils::clamp(static_cast&lt;int&gt;(height * invScale), 1, originalSize.height - box.y);\n\n            boxes.push_back(box);\n            confs.push_back(objConf);\n            classIds.push_back(classId);\n        }\n\n        std::vector&lt;int&gt; indices;\n        nms::NMSBoxesBatched(boxes, confs, classIds, confThreshold, iouThreshold, indices);\n\n        detections.reserve(indices.size());\n        for (int idx : indices) {\n            detections.emplace_back(boxes[idx], confs[idx], classIds[idx]);\n        }\n\n        return detections;\n    }\n\n    virtual std::vector&lt;Detection&gt; postprocessV10(const cv::Size&amp; originalSize,\n                                                  const cv::Size&amp; resizedShape,\n                                                  const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                                  float confThreshold,\n                                                  float /*iouThreshold*/) {\n        std::vector&lt;Detection&gt; detections;\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        const int numDetections = static_cast&lt;int&gt;(outputShape[1]);\n\n        // Pre-compute scale and padding\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        detections.reserve(numDetections);\n\n        for (int i = 0; i &lt; numDetections; ++i) {\n            const float confidence = rawOutput[i * 6 + 4];\n            if (confidence &lt;= confThreshold) continue;\n\n            const float x1 = (rawOutput[i * 6 + 0] - padX) * invScale;\n            const float y1 = (rawOutput[i * 6 + 1] - padY) * invScale;\n            const float x2 = (rawOutput[i * 6 + 2] - padX) * invScale;\n            const float y2 = (rawOutput[i * 6 + 3] - padY) * invScale;\n            const int classId = static_cast&lt;int&gt;(rawOutput[i * 6 + 5]);\n\n            BoundingBox box;\n            box.x = utils::clamp(static_cast&lt;int&gt;(x1), 0, originalSize.width - 1);\n            box.y = utils::clamp(static_cast&lt;int&gt;(y1), 0, originalSize.height - 1);\n            box.width = utils::clamp(static_cast&lt;int&gt;(x2 - x1), 1, originalSize.width - box.x);\n            box.height = utils::clamp(static_cast&lt;int&gt;(y2 - y1), 1, originalSize.height - box.y);\n\n            detections.emplace_back(box, confidence, classId);\n        }\n\n        return detections;\n    }\n\n    virtual std::vector&lt;Detection&gt; postprocessNAS(const cv::Size&amp; originalSize,\n                                                  const cv::Size&amp; resizedShape,\n                                                  const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                                  float confThreshold,\n                                                  float iouThreshold) {\n        std::vector&lt;Detection&gt; detections;\n\n        if (outputTensors.size() &lt; 2) {\n            return postprocessStandard(originalSize, resizedShape, outputTensors, confThreshold, iouThreshold);\n        }\n\n        const float* boxOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const float* scoreOutput = outputTensors[1].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; boxShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n        const std::vector&lt;int64_t&gt; scoreShape = outputTensors[1].GetTensorTypeAndShapeInfo().GetShape();\n\n        const int numDetections = static_cast&lt;int&gt;(boxShape[1]);\n        const int numClasses = static_cast&lt;int&gt;(scoreShape[2]);\n\n        // Pre-compute scale and padding\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        std::vector&lt;BoundingBox&gt; boxes;\n        std::vector&lt;float&gt; confs;\n        std::vector&lt;int&gt; classIds;\n        boxes.reserve(256);\n        confs.reserve(256);\n        classIds.reserve(256);\n\n        for (int i = 0; i &lt; numDetections; ++i) {\n            // Find max class first (allows early continue if below threshold)\n            int classId = 0;\n            float maxScore = scoreOutput[i * numClasses];\n            for (int c = 1; c &lt; numClasses; ++c) {\n                const float score = scoreOutput[i * numClasses + c];\n                if (score &gt; maxScore) {\n                    maxScore = score;\n                    classId = c;\n                }\n            }\n\n            if (maxScore &lt;= confThreshold) continue;\n\n            const float x1 = (boxOutput[i * 4 + 0] - padX) * invScale;\n            const float y1 = (boxOutput[i * 4 + 1] - padY) * invScale;\n            const float x2 = (boxOutput[i * 4 + 2] - padX) * invScale;\n            const float y2 = (boxOutput[i * 4 + 3] - padY) * invScale;\n\n            BoundingBox box;\n            box.x = utils::clamp(static_cast&lt;int&gt;(x1), 0, originalSize.width - 1);\n            box.y = utils::clamp(static_cast&lt;int&gt;(y1), 0, originalSize.height - 1);\n            box.width = utils::clamp(static_cast&lt;int&gt;(x2 - x1), 1, originalSize.width - box.x);\n            box.height = utils::clamp(static_cast&lt;int&gt;(y2 - y1), 1, originalSize.height - box.y);\n\n            boxes.push_back(box);\n            confs.push_back(maxScore);\n            classIds.push_back(classId);\n        }\n\n        std::vector&lt;int&gt; indices;\n        nms::NMSBoxesBatched(boxes, confs, classIds, confThreshold, iouThreshold, indices);\n\n        detections.reserve(indices.size());\n        for (int idx : indices) {\n            detections.emplace_back(boxes[idx], confs[idx], classIds[idx]);\n        }\n\n        return detections;\n    }\n};\n\n// ============================================================================\n// Version-Specific Detector Subclasses\n// ============================================================================\n\nclass YOLOv7Detector : public YOLODetector {\npublic:\n    YOLOv7Detector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::V7) {}\n};\n\nclass YOLOv8Detector : public YOLODetector {\npublic:\n    YOLOv8Detector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::V8) {}\n};\n\nclass YOLOv10Detector : public YOLODetector {\npublic:\n    YOLOv10Detector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::V10) {}\n};\n\nclass YOLOv11Detector : public YOLODetector {\npublic:\n    YOLOv11Detector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::V11) {}\n};\n\nclass YOLONASDetector : public YOLODetector {\npublic:\n    YOLONASDetector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::NAS) {}\n};\n\nclass YOLO26Detector : public YOLODetector {\npublic:\n    YOLO26Detector(const std::string&amp; modelPath, const std::string&amp; labelsPath, bool useGPU = false)\n        : YOLODetector(modelPath, labelsPath, useGPU, YOLOVersion::V26) {}\n};\n\n// ============================================================================\n// Factory Function\n// ============================================================================\n\ninline std::unique_ptr&lt;YOLODetector&gt; createDetector(const std::string&amp; modelPath,\n                                                    const std::string&amp; labelsPath,\n                                                    YOLOVersion version = YOLOVersion::Auto,\n                                                    bool useGPU = false) {\n    switch (version) {\n        case YOLOVersion::V7:\n            return std::make_unique&lt;YOLOv7Detector&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::V8:\n            return std::make_unique&lt;YOLOv8Detector&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::V10:\n            return std::make_unique&lt;YOLOv10Detector&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::V11:\n            return std::make_unique&lt;YOLOv11Detector&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::V26:\n            return std::make_unique&lt;YOLO26Detector&gt;(modelPath, labelsPath, useGPU);\n        case YOLOVersion::NAS:\n            return std::make_unique&lt;YOLONASDetector&gt;(modelPath, labelsPath, useGPU);\n        default:\n            return std::make_unique&lt;YOLODetector&gt;(modelPath, labelsPath, useGPU, YOLOVersion::Auto);\n    }\n}\n\n} // namespace det\n} // namespace yolos\n</code></pre>"},{"location":"yolos/obb_8hpp/","title":"File obb.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; tasks &gt; obb.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;opencv2/imgproc.hpp&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;cfloat&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> <li><code>#include \"yolos/core/preprocessing.hpp\"</code></li> <li><code>#include \"yolos/core/nms.hpp\"</code></li> <li><code>#include \"yolos/core/drawing.hpp\"</code></li> <li><code>#include \"yolos/core/session_base.hpp\"</code></li> </ul>"},{"location":"yolos/obb_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace obb"},{"location":"yolos/obb_8hpp/#classes","title":"Classes","text":"Type Name struct OBBResult OBB detection result containing oriented bounding box, confidence, and class ID. class YOLOOBBDetector YOLO oriented bounding box detector for rotated object detection. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/obb.hpp</code></p>"},{"location":"yolos/obb_8hpp_source/","title":"File obb.hpp","text":"<p>File List &gt; include &gt; yolos &gt; tasks &gt; obb.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Oriented Bounding Box Detection (OBB)\n// ============================================================================\n// Object detection with rotated/oriented bounding boxes for aerial imagery\n// and other scenarios requiring rotation-aware detection.\n// Supports YOLOv8-obb, YOLOv11-obb, and YOLO26-obb models.\n//\n// Authors: \n// YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// 2- Mohamed Samir, www.linkedin.com/in/mohamed-samir-7a730b237/\n// 3- Khaled Gabr, https://www.linkedin.com/in/khalidgabr/\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;opencv2/imgproc.hpp&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;memory&gt;\n#include &lt;cfloat&gt;\n#include &lt;cmath&gt;\n\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n#include \"yolos/core/preprocessing.hpp\"\n#include \"yolos/core/nms.hpp\"\n#include \"yolos/core/drawing.hpp\"\n#include \"yolos/core/session_base.hpp\"\n\nnamespace yolos {\nnamespace obb {\n\n// ============================================================================\n// OBB Detection Result Structure\n// ============================================================================\n\nstruct OBBResult {\n    OrientedBoundingBox box;  \n    float conf{0.0f};         \n    int classId{-1};          \n\n    OBBResult() = default;\n    OBBResult(const OrientedBoundingBox&amp; box_, float conf_, int classId_)\n        : box(box_), conf(conf_), classId(classId_) {}\n};\n\n// ============================================================================\n// YOLOOBBDetector Class\n// ============================================================================\n\nclass YOLOOBBDetector : public OrtSessionBase {\npublic:\n    YOLOOBBDetector(const std::string&amp; modelPath,\n                    const std::string&amp; labelsPath,\n                    bool useGPU = false)\n        : OrtSessionBase(modelPath, useGPU) {\n        classNames_ = utils::getClassNames(labelsPath);\n        classColors_ = drawing::generateColors(classNames_);\n\n        // Pre-allocate inference buffer\n        buffer_.ensureCapacity(inputShape_.height, inputShape_.width, 3);\n    }\n\n    virtual ~YOLOOBBDetector() = default;\n\n    std::vector&lt;OBBResult&gt; detect(const cv::Mat&amp; image,\n                                  float confThreshold = 0.25f,\n                                  float iouThreshold = 0.45f,\n                                  int maxDet = 300) {\n        // Optimized preprocessing with buffer reuse\n        cv::Size actualSize;\n        preprocessing::letterBoxToBlob(image, buffer_, inputShape_, actualSize, isDynamicInputShape_);\n\n        // Create input tensor (uses pre-allocated blob)\n        std::vector&lt;int64_t&gt; inputTensorShape = {1, 3, actualSize.height, actualSize.width};\n        Ort::Value inputTensor = createInputTensor(buffer_.blob.data(), inputTensorShape);\n\n        // Run inference\n        std::vector&lt;Ort::Value&gt; outputTensors = runInference(inputTensor);\n\n        // Postprocess\n        return postprocess(image.size(), actualSize, outputTensors, confThreshold, iouThreshold, maxDet);\n    }\n\n    void drawDetections(cv::Mat&amp; image,\n                        const std::vector&lt;OBBResult&gt;&amp; results,\n                        int thickness = 2) const {\n        for (const auto&amp; det : results) {\n            if (det.classId &gt;= 0 &amp;&amp; static_cast&lt;size_t&gt;(det.classId) &lt; classNames_.size()) {\n                std::string label = classNames_[det.classId] + \": \" +\n                                   std::to_string(static_cast&lt;int&gt;(det.conf * 100)) + \"%\";\n                const cv::Scalar&amp; color = classColors_[det.classId % classColors_.size()];\n                drawing::drawOrientedBoundingBox(image, det.box, label, color, thickness);\n            }\n        }\n    }\n\n    [[nodiscard]] const std::vector&lt;std::string&gt;&amp; getClassNames() const { return classNames_; }\n\n    [[nodiscard]] const std::vector&lt;cv::Scalar&gt;&amp; getClassColors() const { return classColors_; }\n\nprotected:\n    std::vector&lt;std::string&gt; classNames_;\n    std::vector&lt;cv::Scalar&gt; classColors_;\n\n    // Pre-allocated buffer for inference\n    mutable preprocessing::InferenceBuffer buffer_;\n\n    std::vector&lt;OBBResult&gt; postprocess(const cv::Size&amp; originalSize,\n                                       const cv::Size&amp; resizedShape,\n                                       const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                       float confThreshold,\n                                       float iouThreshold,\n                                       int maxDet) {\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        // Detect output format based on shape:\n        // YOLOv8/v11: [1, num_features, num_detections] - requires NMS\n        // YOLO26:     [1, 300, 7] - end-to-end, NMS-free\n        if (outputShape.size() == 3 &amp;&amp; outputShape[2] == 7) {\n            // YOLO26 end-to-end format: [1, num_detections, 7]\n            return postprocessV26(originalSize, resizedShape, rawOutput, outputShape, confThreshold, maxDet);\n        } else {\n            // YOLOv8/v11 format: [1, num_features, num_detections]\n            return postprocessV8(originalSize, resizedShape, rawOutput, outputShape, confThreshold, iouThreshold, maxDet);\n        }\n    }\n\n    std::vector&lt;OBBResult&gt; postprocessV8(const cv::Size&amp; originalSize,\n                                         const cv::Size&amp; resizedShape,\n                                         const float* rawOutput,\n                                         const std::vector&lt;int64_t&gt;&amp; outputShape,\n                                         float confThreshold,\n                                         float iouThreshold,\n                                         int maxDet) {\n        std::vector&lt;OBBResult&gt; results;\n\n        const int numFeatures = static_cast&lt;int&gt;(outputShape[1]);\n        const int numDetections = static_cast&lt;int&gt;(outputShape[2]);\n\n        if (numDetections == 0) return results;\n\n        // Layout: [x, y, w, h, scores..., angle]\n        const int numLabels = numFeatures - 5;\n        if (numLabels &lt;= 0) return results;\n\n        // Pre-compute letterbox parameters for descaling AFTER NMS\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        // Transpose output for easier access\n        cv::Mat output = cv::Mat(numFeatures, numDetections, CV_32F, const_cast&lt;float*&gt;(rawOutput));\n        output = output.t();\n\n        // Collect boxes in LETTERBOX coordinates (NMS applied before descaling)\n        std::vector&lt;OrientedBoundingBox&gt; letterboxBoxes;\n        std::vector&lt;float&gt; confidences;\n        std::vector&lt;int&gt; classIds;\n        letterboxBoxes.reserve(256);\n        confidences.reserve(256);\n        classIds.reserve(256);\n\n        for (int i = 0; i &lt; numDetections; ++i) {\n            const float* row = output.ptr&lt;float&gt;(i);\n\n            // Find best class first (enables early continue)\n            float maxScore = row[4];\n            int classId = 0;\n            for (int j = 1; j &lt; numLabels; ++j) {\n                const float score = row[4 + j];\n                if (score &gt; maxScore) {\n                    maxScore = score;\n                    classId = j;\n                }\n            }\n\n            if (maxScore &lt;= confThreshold) continue;\n\n            const float x = row[0];\n            const float y = row[1];\n            const float w = row[2];\n            const float h = row[3];\n            const float angle = row[4 + numLabels];\n\n            // Store in LETTERBOX coordinates for NMS\n            letterboxBoxes.emplace_back(x, y, w, h, angle);\n            confidences.push_back(maxScore);\n            classIds.push_back(classId);\n        }\n\n        if (letterboxBoxes.empty()) return results;\n\n        // Apply class-aware rotated NMS on LETTERBOX coordinates\n        std::vector&lt;int&gt; keepIndices = nms::NMSRotatedBatched(letterboxBoxes, confidences, classIds, iouThreshold, maxDet);\n\n        results.reserve(keepIndices.size());\n        for (int idx : keepIndices) {\n            // NOW descale box coordinates from letterbox to original\n            const OrientedBoundingBox&amp; lbBox = letterboxBoxes[idx];\n            const float cx = (lbBox.x - padX) * invScale;\n            const float cy = (lbBox.y - padY) * invScale;\n            const float bw = lbBox.width * invScale;\n            const float bh = lbBox.height * invScale;\n\n            results.emplace_back(OrientedBoundingBox(cx, cy, bw, bh, lbBox.angle), confidences[idx], classIds[idx]);\n        }\n\n        return results;\n    }\n\n    std::vector&lt;OBBResult&gt; postprocessV26(const cv::Size&amp; originalSize,\n                                          const cv::Size&amp; resizedShape,\n                                          const float* rawOutput,\n                                          const std::vector&lt;int64_t&gt;&amp; outputShape,\n                                          float confThreshold,\n                                          int maxDet) {\n        std::vector&lt;OBBResult&gt; results;\n\n        const size_t numDetections = outputShape[1];  // 300\n        const size_t numFeatures = outputShape[2];    // 7\n\n        // Pre-compute letterbox parameters\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        for (size_t d = 0; d &lt; numDetections &amp;&amp; static_cast&lt;int&gt;(results.size()) &lt; maxDet; ++d) {\n            const size_t base = d * numFeatures;\n\n            // YOLO26 OBB format: [x, y, w, h, conf, class_id, angle]\n            const float x = rawOutput[base + 0];      // center x\n            const float y = rawOutput[base + 1];      // center y\n            const float w = rawOutput[base + 2];      // width\n            const float h = rawOutput[base + 3];      // height\n            const float conf = rawOutput[base + 4];   // confidence\n            const int classId = static_cast&lt;int&gt;(rawOutput[base + 5]);  // class id\n            const float angle = rawOutput[base + 6];  // angle in radians\n\n            if (conf &lt; confThreshold) continue;\n\n            // Convert to original image coordinates\n            const float cx = (x - padX) * invScale;\n            const float cy = (y - padY) * invScale;\n            const float bw = w * invScale;\n            const float bh = h * invScale;\n\n            results.emplace_back(OrientedBoundingBox(cx, cy, bw, bh, angle), conf, classId);\n        }\n\n        return results;\n    }\n};\n\n} // namespace obb\n} // namespace yolos\n</code></pre>"},{"location":"yolos/pose_8hpp/","title":"File pose.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; tasks &gt; pose.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> <li><code>#include \"yolos/core/preprocessing.hpp\"</code></li> <li><code>#include \"yolos/core/nms.hpp\"</code></li> <li><code>#include \"yolos/core/drawing.hpp\"</code></li> <li><code>#include \"yolos/core/session_base.hpp\"</code></li> </ul>"},{"location":"yolos/pose_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace pose"},{"location":"yolos/pose_8hpp/#classes","title":"Classes","text":"Type Name struct PoseResult Pose estimation result containing bounding box, confidence, and keypoints. class YOLOPoseDetector YOLO pose estimation detector with keypoint detection. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/pose.hpp</code></p>"},{"location":"yolos/pose_8hpp_source/","title":"File pose.hpp","text":"<p>File List &gt; include &gt; yolos &gt; tasks &gt; pose.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Pose Estimation\n// ============================================================================\n// Human pose estimation using YOLO models with keypoint detection.\n// Supports YOLOv8-pose, YOLOv11-pose, and YOLO26-pose models.\n//\n// Authors: \n// YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// 2- Mohamed Samir, www.linkedin.com/in/mohamed-samir-7a730b237/\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;memory&gt;\n#include &lt;cmath&gt;\n\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n#include \"yolos/core/preprocessing.hpp\"\n#include \"yolos/core/nms.hpp\"\n#include \"yolos/core/drawing.hpp\"\n#include \"yolos/core/session_base.hpp\"\n\nnamespace yolos {\nnamespace pose {\n\n// ============================================================================\n// Pose Result Structure\n// ============================================================================\n\nstruct PoseResult {\n    BoundingBox box;               \n    float conf{0.0f};              \n    int classId{0};                \n    std::vector&lt;KeyPoint&gt; keypoints; \n\n    PoseResult() = default;\n    PoseResult(const BoundingBox&amp; box_, float conf_, int classId_, const std::vector&lt;KeyPoint&gt;&amp; kpts)\n        : box(box_), conf(conf_), classId(classId_), keypoints(kpts) {}\n};\n\n// ============================================================================\n// YOLOPoseDetector Class\n// ============================================================================\n\nclass YOLOPoseDetector : public OrtSessionBase {\npublic:\n    YOLOPoseDetector(const std::string&amp; modelPath,\n                     const std::string&amp; labelsPath = \"\",\n                     bool useGPU = false)\n        : OrtSessionBase(modelPath, useGPU) {\n\n        if (!labelsPath.empty()) {\n            classNames_ = utils::getClassNames(labelsPath);\n        } else {\n            classNames_ = {\"person\"};\n        }\n        classColors_ = drawing::generateColors(classNames_);\n\n        // Pre-allocate inference buffer\n        buffer_.ensureCapacity(inputShape_.height, inputShape_.width, 3);\n    }\n\n    virtual ~YOLOPoseDetector() = default;\n\n    std::vector&lt;PoseResult&gt; detect(const cv::Mat&amp; image,\n                                   float confThreshold = 0.4f,\n                                   float iouThreshold = 0.5f) {\n        // Optimized preprocessing with buffer reuse\n        cv::Size actualSize;\n        preprocessing::letterBoxToBlob(image, buffer_, inputShape_, actualSize, isDynamicInputShape_);\n\n        // Create input tensor (uses pre-allocated blob)\n        std::vector&lt;int64_t&gt; inputTensorShape = {1, 3, actualSize.height, actualSize.width};\n        Ort::Value inputTensor = createInputTensor(buffer_.blob.data(), inputTensorShape);\n\n        // Run inference\n        std::vector&lt;Ort::Value&gt; outputTensors = runInference(inputTensor);\n\n        // Postprocess\n        return postprocess(image.size(), actualSize, outputTensors, confThreshold, iouThreshold);\n    }\n\n    void drawPoses(cv::Mat&amp; image,\n                   const std::vector&lt;PoseResult&gt;&amp; results,\n                   int kptRadius = 4,\n                   float kptThreshold = 0.5f,\n                   int lineThickness = 2) const {\n\n        for (const auto&amp; pose : results) {\n            // Draw bounding box\n            cv::rectangle(image,\n                         cv::Point(pose.box.x, pose.box.y),\n                         cv::Point(pose.box.x + pose.box.width, pose.box.y + pose.box.height),\n                         cv::Scalar(0, 255, 0), lineThickness);\n\n            // Draw keypoints and skeleton\n            drawing::drawPoseSkeleton(image, pose.keypoints, getPoseSkeleton(),\n                                     kptRadius, kptThreshold, lineThickness);\n        }\n    }\n\n    void drawSkeletonsOnly(cv::Mat&amp; image,\n                           const std::vector&lt;PoseResult&gt;&amp; results,\n                           int kptRadius = 4,\n                           float kptThreshold = 0.5f,\n                           int lineThickness = 2) const {\n        for (const auto&amp; pose : results) {\n            drawing::drawPoseSkeleton(image, pose.keypoints, getPoseSkeleton(),\n                                     kptRadius, kptThreshold, lineThickness);\n        }\n    }\n\n    [[nodiscard]] const std::vector&lt;std::string&gt;&amp; getClassNames() const { return classNames_; }\n\n    [[nodiscard]] static const std::vector&lt;std::pair&lt;int, int&gt;&gt;&amp; getPoseSkeleton() {\n        static const std::vector&lt;std::pair&lt;int, int&gt;&gt; skeleton = {\n            {0, 1}, {0, 2}, {1, 3}, {2, 4},       // Face\n            {3, 5}, {4, 6},                       // Head to shoulders\n            {5, 7}, {7, 9}, {6, 8}, {8, 10},      // Arms\n            {5, 6}, {5, 11}, {6, 12}, {11, 12},   // Body\n            {11, 13}, {13, 15}, {12, 14}, {14, 16} // Legs\n        };\n        return skeleton;\n    }\n\nprotected:\n    std::vector&lt;std::string&gt; classNames_;\n    std::vector&lt;cv::Scalar&gt; classColors_;\n    static constexpr int NUM_KEYPOINTS = 17;\n    static constexpr int FEATURES_PER_KEYPOINT = 3;\n\n    // Pre-allocated buffer for inference\n    mutable preprocessing::InferenceBuffer buffer_;\n\n    std::vector&lt;PoseResult&gt; postprocess(const cv::Size&amp; originalSize,\n                                        const cv::Size&amp; resizedShape,\n                                        const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                        float confThreshold,\n                                        float iouThreshold) {\n        const float* rawOutput = outputTensors[0].GetTensorData&lt;float&gt;();\n        const std::vector&lt;int64_t&gt; outputShape = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n\n        // Detect output format based on shape:\n        // YOLOv8/v11: [1, 56, num_detections] - requires NMS\n        // YOLO26:     [1, 300, 57] - end-to-end, NMS-free\n        const int expectedFeaturesV8 = 4 + 1 + NUM_KEYPOINTS * FEATURES_PER_KEYPOINT;  // 56\n        const int expectedFeaturesV26 = 4 + 1 + 1 + NUM_KEYPOINTS * FEATURES_PER_KEYPOINT;  // 57\n\n        if (outputShape.size() == 3 &amp;&amp; outputShape[2] == expectedFeaturesV26) {\n            // YOLO26 end-to-end format: [1, num_detections, 57]\n            return postprocessV26(originalSize, resizedShape, rawOutput, outputShape, confThreshold);\n        } else if (outputShape.size() == 3 &amp;&amp; outputShape[1] == expectedFeaturesV8) {\n            // YOLOv8/v11 format: [1, 56, num_detections]\n            return postprocessV8(originalSize, resizedShape, rawOutput, outputShape, confThreshold, iouThreshold);\n        } else {\n            std::cerr &lt;&lt; \"[ERROR] Unsupported pose model output shape: [\" \n                      &lt;&lt; outputShape[0] &lt;&lt; \", \" &lt;&lt; outputShape[1] &lt;&lt; \", \" &lt;&lt; outputShape[2] &lt;&lt; \"]\" &lt;&lt; std::endl;\n            return {};\n        }\n    }\n\n    std::vector&lt;PoseResult&gt; postprocessV8(const cv::Size&amp; originalSize,\n                                          const cv::Size&amp; resizedShape,\n                                          const float* rawOutput,\n                                          const std::vector&lt;int64_t&gt;&amp; outputShape,\n                                          float confThreshold,\n                                          float iouThreshold) {\n        std::vector&lt;PoseResult&gt; results;\n\n        const size_t numDetections = outputShape[2];\n\n        // Pre-compute scale and padding\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        std::vector&lt;BoundingBox&gt; boxes;\n        std::vector&lt;float&gt; confidences;\n        std::vector&lt;std::vector&lt;KeyPoint&gt;&gt; allKeypoints;\n        boxes.reserve(64);\n        confidences.reserve(64);\n        allKeypoints.reserve(64);\n\n        for (size_t d = 0; d &lt; numDetections; ++d) {\n            const float objConfidence = rawOutput[4 * numDetections + d];\n            if (objConfidence &lt; confThreshold) continue;\n\n            // Decode bounding box (cx, cy, w, h format)\n            const float cx = rawOutput[0 * numDetections + d];\n            const float cy = rawOutput[1 * numDetections + d];\n            const float w = rawOutput[2 * numDetections + d];\n            const float h = rawOutput[3 * numDetections + d];\n\n            // Convert to original image coordinates\n            BoundingBox box;\n            box.x = utils::clamp(static_cast&lt;int&gt;((cx - w * 0.5f - padX) * invScale), 0, originalSize.width - 1);\n            box.y = utils::clamp(static_cast&lt;int&gt;((cy - h * 0.5f - padY) * invScale), 0, originalSize.height - 1);\n            box.width = utils::clamp(static_cast&lt;int&gt;(w * invScale), 1, originalSize.width - box.x);\n            box.height = utils::clamp(static_cast&lt;int&gt;(h * invScale), 1, originalSize.height - box.y);\n\n            // Extract keypoints\n            std::vector&lt;KeyPoint&gt; keypoints;\n            keypoints.reserve(NUM_KEYPOINTS);\n            for (int k = 0; k &lt; NUM_KEYPOINTS; ++k) {\n                const int offset = 5 + k * FEATURES_PER_KEYPOINT;\n                KeyPoint kpt;\n                kpt.x = (rawOutput[offset * numDetections + d] - padX) * invScale;\n                kpt.y = (rawOutput[(offset + 1) * numDetections + d] - padY) * invScale;\n                const float rawConf = rawOutput[(offset + 2) * numDetections + d];\n                kpt.confidence = 1.0f / (1.0f + std::exp(-rawConf)); // Sigmoid\n\n                // Clip keypoints to image boundaries\n                kpt.x = utils::clamp(kpt.x, 0.0f, static_cast&lt;float&gt;(originalSize.width - 1));\n                kpt.y = utils::clamp(kpt.y, 0.0f, static_cast&lt;float&gt;(originalSize.height - 1));\n\n                keypoints.push_back(kpt);\n            }\n\n            boxes.push_back(box);\n            confidences.push_back(objConfidence);\n            allKeypoints.push_back(std::move(keypoints));\n        }\n\n        if (boxes.empty()) return results;\n\n        // Apply NMS\n        std::vector&lt;int&gt; indices;\n        nms::NMSBoxes(boxes, confidences, confThreshold, iouThreshold, indices);\n\n        results.reserve(indices.size());\n        for (int idx : indices) {\n            results.emplace_back(boxes[idx], confidences[idx], 0, allKeypoints[idx]);\n        }\n\n        return results;\n    }\n\n    std::vector&lt;PoseResult&gt; postprocessV26(const cv::Size&amp; originalSize,\n                                           const cv::Size&amp; resizedShape,\n                                           const float* rawOutput,\n                                           const std::vector&lt;int64_t&gt;&amp; outputShape,\n                                           float confThreshold) {\n        std::vector&lt;PoseResult&gt; results;\n\n        const size_t numDetections = outputShape[1];  // 300\n        const size_t numFeatures = outputShape[2];    // 57\n\n        // Pre-compute scale and padding\n        float scale, padX, padY;\n        preprocessing::getScalePad(originalSize, resizedShape, scale, padX, padY);\n        const float invScale = 1.0f / scale;\n\n        for (size_t d = 0; d &lt; numDetections; ++d) {\n            const size_t base = d * numFeatures;\n\n            // YOLO26 format: [x1, y1, x2, y2, conf, class_id, kpt1_x, kpt1_y, kpt1_conf, ...]\n            const float x1 = rawOutput[base + 0];\n            const float y1 = rawOutput[base + 1];\n            const float x2 = rawOutput[base + 2];\n            const float y2 = rawOutput[base + 3];\n            const float conf = rawOutput[base + 4];\n            // const int classId = static_cast&lt;int&gt;(rawOutput[base + 5]);  // Always 0 for person\n\n            if (conf &lt; confThreshold) continue;\n\n            // Convert to original image coordinates\n            BoundingBox box;\n            box.x = utils::clamp(static_cast&lt;int&gt;((x1 - padX) * invScale), 0, originalSize.width - 1);\n            box.y = utils::clamp(static_cast&lt;int&gt;((y1 - padY) * invScale), 0, originalSize.height - 1);\n            const int x2_scaled = utils::clamp(static_cast&lt;int&gt;((x2 - padX) * invScale), 0, originalSize.width - 1);\n            const int y2_scaled = utils::clamp(static_cast&lt;int&gt;((y2 - padY) * invScale), 0, originalSize.height - 1);\n            box.width = std::max(1, x2_scaled - box.x);\n            box.height = std::max(1, y2_scaled - box.y);\n\n            // Extract keypoints (starting at index 6)\n            std::vector&lt;KeyPoint&gt; keypoints;\n            keypoints.reserve(NUM_KEYPOINTS);\n            for (int k = 0; k &lt; NUM_KEYPOINTS; ++k) {\n                const size_t kptBase = base + 6 + k * FEATURES_PER_KEYPOINT;\n                KeyPoint kpt;\n                kpt.x = (rawOutput[kptBase + 0] - padX) * invScale;\n                kpt.y = (rawOutput[kptBase + 1] - padY) * invScale;\n                kpt.confidence = rawOutput[kptBase + 2];  // Already sigmoid-applied in end-to-end\n\n                // Clip keypoints to image boundaries\n                kpt.x = utils::clamp(kpt.x, 0.0f, static_cast&lt;float&gt;(originalSize.width - 1));\n                kpt.y = utils::clamp(kpt.y, 0.0f, static_cast&lt;float&gt;(originalSize.height - 1));\n\n                keypoints.push_back(kpt);\n            }\n\n            results.emplace_back(box, conf, 0, std::move(keypoints));\n        }\n\n        return results;\n    }\n};\n\n} // namespace pose\n} // namespace yolos\n</code></pre>"},{"location":"yolos/segmentation_8hpp/","title":"File segmentation.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; tasks &gt; segmentation.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> <li><code>#include \"yolos/core/preprocessing.hpp\"</code></li> <li><code>#include \"yolos/core/nms.hpp\"</code></li> <li><code>#include \"yolos/core/drawing.hpp\"</code></li> <li><code>#include \"yolos/core/session_base.hpp\"</code></li> </ul>"},{"location":"yolos/segmentation_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos namespace seg"},{"location":"yolos/segmentation_8hpp/#classes","title":"Classes","text":"Type Name struct Segmentation Segmentation result containing bounding box, confidence, class ID, and mask. class YOLOSegDetector YOLO segmentation detector with mask prediction. <p>The documentation for this class was generated from the following file <code>include/yolos/tasks/segmentation.hpp</code></p>"},{"location":"yolos/segmentation_8hpp_source/","title":"File segmentation.hpp","text":"<p>File List &gt; include &gt; yolos &gt; tasks &gt; segmentation.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLO Instance Segmentation\n// ============================================================================\n// Instance segmentation using YOLO models with mask prediction.\n// Supports YOLOv8-seg and YOLOv11-seg models.\n//\n// Authors: \n// YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// 2- Mohamed Samir, www.linkedin.com/in/mohamed-samir-7a730b237/\n// ============================================================================\n\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;memory&gt;\n\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n#include \"yolos/core/preprocessing.hpp\"\n#include \"yolos/core/nms.hpp\"\n#include \"yolos/core/drawing.hpp\"\n#include \"yolos/core/session_base.hpp\"\n\nnamespace yolos {\nnamespace seg {\n\n// ============================================================================\n// Segmentation Result Structure\n// ============================================================================\n\nstruct Segmentation {\n    BoundingBox box;       \n    float conf{0.0f};      \n    int classId{0};        \n    cv::Mat mask;          \n\n    Segmentation() = default;\n    Segmentation(const BoundingBox&amp; box_, float conf_, int classId_, const cv::Mat&amp; mask_)\n        : box(box_), conf(conf_), classId(classId_), mask(mask_) {}\n};\n\n// ============================================================================\n// YOLOSegDetector Class\n// ============================================================================\n\nclass YOLOSegDetector : public OrtSessionBase {\npublic:\n    YOLOSegDetector(const std::string&amp; modelPath,\n                    const std::string&amp; labelsPath,\n                    bool useGPU = false)\n        : OrtSessionBase(modelPath, useGPU) {\n\n        // Validate output count for segmentation models\n        if (numOutputNodes_ != 2) {\n            throw std::runtime_error(\"Expected 2 output nodes for segmentation model (output0 and output1)\");\n        }\n\n        classNames_ = utils::getClassNames(labelsPath);\n        classColors_ = drawing::generateColors(classNames_);\n\n        // Pre-allocate inference buffer\n        buffer_.ensureCapacity(inputShape_.height, inputShape_.width, 3);\n    }\n\n    virtual ~YOLOSegDetector() = default;\n\n    std::vector&lt;Segmentation&gt; segment(const cv::Mat&amp; image,\n                                      float confThreshold = 0.4f,\n                                      float iouThreshold = 0.45f) {\n        // Optimized preprocessing with buffer reuse\n        cv::Size actualSize;\n        preprocessing::letterBoxToBlob(image, buffer_, inputShape_, actualSize, isDynamicInputShape_);\n\n        // Create input tensor (uses pre-allocated blob)\n        std::vector&lt;int64_t&gt; inputTensorShape = {1, 3, actualSize.height, actualSize.width};\n        Ort::Value inputTensor = createInputTensor(buffer_.blob.data(), inputTensorShape);\n\n        // Run inference\n        std::vector&lt;Ort::Value&gt; outputTensors = runInference(inputTensor);\n\n        // Postprocess\n        return postprocess(image.size(), actualSize, outputTensors, confThreshold, iouThreshold);\n    }\n\n    void drawSegmentations(cv::Mat&amp; image,\n                           const std::vector&lt;Segmentation&gt;&amp; results,\n                           float maskAlpha = 0.5f) const {\n        for (const auto&amp; seg : results) {\n            if (seg.classId &lt; 0 || static_cast&lt;size_t&gt;(seg.classId) &gt;= classNames_.size()) {\n                continue;\n            }\n\n            const cv::Scalar&amp; color = classColors_[seg.classId % classColors_.size()];\n\n            // Draw mask\n            if (!seg.mask.empty()) {\n                drawing::drawSegmentationMask(image, seg.mask, color, maskAlpha);\n            }\n\n            // Draw bounding box and label\n            std::string label = classNames_[seg.classId] + \": \" +\n                               std::to_string(static_cast&lt;int&gt;(seg.conf * 100)) + \"%\";\n            drawing::drawBoundingBox(image, seg.box, label, color);\n        }\n    }\n\n    void drawMasksOnly(cv::Mat&amp; image,\n                       const std::vector&lt;Segmentation&gt;&amp; results,\n                       float maskAlpha = 0.5f) const {\n        for (const auto&amp; seg : results) {\n            if (seg.classId &lt; 0 || static_cast&lt;size_t&gt;(seg.classId) &gt;= classNames_.size()) {\n                continue;\n            }\n            const cv::Scalar&amp; color = classColors_[seg.classId % classColors_.size()];\n            if (!seg.mask.empty()) {\n                drawing::drawSegmentationMask(image, seg.mask, color, maskAlpha);\n            }\n        }\n    }\n\n    [[nodiscard]] const std::vector&lt;std::string&gt;&amp; getClassNames() const { return classNames_; }\n\n    [[nodiscard]] const std::vector&lt;cv::Scalar&gt;&amp; getClassColors() const { return classColors_; }\n\nprotected:\n    std::vector&lt;std::string&gt; classNames_;\n    std::vector&lt;cv::Scalar&gt; classColors_;\n    static constexpr float MASK_THRESHOLD = 0.5f;\n\n    // Pre-allocated buffer for inference (avoids per-frame allocations)\n    mutable preprocessing::InferenceBuffer buffer_;\n\n    std::vector&lt;Segmentation&gt; postprocess(const cv::Size&amp; originalSize,\n                                          const cv::Size&amp; letterboxSize,\n                                          const std::vector&lt;Ort::Value&gt;&amp; outputTensors,\n                                          float confThreshold,\n                                          float iouThreshold) {\n        std::vector&lt;Segmentation&gt; results;\n\n        if (outputTensors.size() &lt; 2) {\n            return results;\n        }\n\n        const float* output0 = outputTensors[0].GetTensorData&lt;float&gt;();\n        const float* output1 = outputTensors[1].GetTensorData&lt;float&gt;();\n\n        auto shape0 = outputTensors[0].GetTensorTypeAndShapeInfo().GetShape();\n        auto shape1 = outputTensors[1].GetTensorTypeAndShapeInfo().GetShape(); // [1, 32, maskH, maskW]\n\n        if (shape1.size() != 4 || shape1[1] != 32) {\n            throw std::runtime_error(\"Unexpected mask output shape. Expected [1, 32, maskH, maskW]\");\n        }\n\n        // Detect YOLO26-seg format: [1, num_detections, 38] where dim2 == 38\n        // vs standard format: [1, num_features, num_detections] where dim1 &gt; dim2\n        const bool isV26Format = (shape0.size() == 3 &amp;&amp; shape0[2] == 38);\n\n        if (isV26Format) {\n            return postprocessV26(originalSize, letterboxSize, output0, output1, shape0, shape1, confThreshold);\n        }\n\n        // Standard format: [1, 116, num_detections]\n        const size_t numFeatures = shape0[1];\n        const size_t numDetections = shape0[2];\n\n        if (numDetections == 0) return results;\n\n        const int numClasses = static_cast&lt;int&gt;(numFeatures) - 4 - 32;\n        if (numClasses &lt;= 0) return results;\n\n        const int maskH = static_cast&lt;int&gt;(shape1[2]);\n        const int maskW = static_cast&lt;int&gt;(shape1[3]);\n\n        // Load prototype masks\n        std::vector&lt;cv::Mat&gt; prototypeMasks;\n        prototypeMasks.reserve(32);\n        for (int m = 0; m &lt; 32; ++m) {\n            cv::Mat proto(maskH, maskW, CV_32F, const_cast&lt;float*&gt;(output1 + m * maskH * maskW));\n            prototypeMasks.emplace_back(proto.clone());\n        }\n\n        // Pre-compute scale and padding for descaling AFTER NMS\n        float gain, padW, padH;\n        preprocessing::getScalePad(originalSize, letterboxSize, gain, padW, padH);\n        const float invGain = 1.0f / gain;\n\n        // Process detections in LETTERBOX coordinates with FLOAT precision (NMS applied before descaling)\n        std::vector&lt;cv::Rect2f&gt; letterboxBoxes;  // Float boxes in letterbox space for NMS\n        std::vector&lt;float&gt; confidences;\n        std::vector&lt;int&gt; classIds;\n        std::vector&lt;std::vector&lt;float&gt;&gt; maskCoeffsList;\n        letterboxBoxes.reserve(256);\n        confidences.reserve(256);\n        classIds.reserve(256);\n        maskCoeffsList.reserve(256);\n\n        for (size_t i = 0; i &lt; numDetections; ++i) {\n            const float xc = output0[0 * numDetections + i];\n            const float yc = output0[1 * numDetections + i];\n            const float w = output0[2 * numDetections + i];\n            const float h = output0[3 * numDetections + i];\n\n            // Find max class score\n            int classId = 0;\n            float maxConf = output0[4 * numDetections + i];\n            for (int c = 1; c &lt; numClasses; ++c) {\n                const float conf = output0[(4 + c) * numDetections + i];\n                if (conf &gt; maxConf) {\n                    maxConf = conf;\n                    classId = c;\n                }\n            }\n\n            if (maxConf &lt; confThreshold) continue;\n\n            // Store box in LETTERBOX coordinates as FLOAT (for precise NMS)\n            cv::Rect2f box(xc - w * 0.5f, yc - h * 0.5f, w, h);\n\n            letterboxBoxes.push_back(box);\n            confidences.push_back(maxConf);\n            classIds.push_back(classId);\n\n            std::vector&lt;float&gt; maskCoeffs(32);\n            for (int m = 0; m &lt; 32; ++m) {\n                maskCoeffs[m] = output0[(4 + numClasses + m) * numDetections + i];\n            }\n            maskCoeffsList.emplace_back(std::move(maskCoeffs));\n        }\n\n        if (letterboxBoxes.empty()) return results;\n\n        // Apply class-aware (batched) NMS on LETTERBOX coordinates with FLOAT precision\n        std::vector&lt;int&gt; nmsIndices;\n        nms::NMSBoxesFBatched(letterboxBoxes, confidences, classIds, confThreshold, iouThreshold, nmsIndices);\n\n        if (nmsIndices.empty()) return results;\n\n        float maskScaleX = static_cast&lt;float&gt;(maskW) / letterboxSize.width;\n        float maskScaleY = static_cast&lt;float&gt;(maskH) / letterboxSize.height;\n\n        results.reserve(nmsIndices.size());\n\n        for (int idx : nmsIndices) {\n            Segmentation seg;\n\n            // NOW descale box coordinates from letterbox to original\n            const cv::Rect2f&amp; lbBox = letterboxBoxes[idx];\n            const float left = (lbBox.x - padW) * invGain;\n            const float top = (lbBox.y - padH) * invGain;\n            const float scaledW = lbBox.width * invGain;\n            const float scaledH = lbBox.height * invGain;\n\n            seg.box.x = utils::clamp(static_cast&lt;int&gt;(left), 0, originalSize.width - 1);\n            seg.box.y = utils::clamp(static_cast&lt;int&gt;(top), 0, originalSize.height - 1);\n            seg.box.width = utils::clamp(static_cast&lt;int&gt;(scaledW), 1, originalSize.width - seg.box.x);\n            seg.box.height = utils::clamp(static_cast&lt;int&gt;(scaledH), 1, originalSize.height - seg.box.y);\n            seg.conf = confidences[idx];\n            seg.classId = classIds[idx];\n\n            // Compute mask from prototype masks and coefficients\n            cv::Mat finalMask = cv::Mat::zeros(maskH, maskW, CV_32F);\n            for (int m = 0; m &lt; 32; ++m) {\n                finalMask += maskCoeffsList[idx][m] * prototypeMasks[m];\n            }\n\n            // Apply sigmoid activation\n            cv::exp(-finalMask, finalMask);\n            finalMask = 1.0 / (1.0 + finalMask);\n\n            // Crop to letterbox area\n            int x1 = static_cast&lt;int&gt;(std::round((padW - 0.1f) * maskScaleX));\n            int y1 = static_cast&lt;int&gt;(std::round((padH - 0.1f) * maskScaleY));\n            int x2 = static_cast&lt;int&gt;(std::round((letterboxSize.width - padW + 0.1f) * maskScaleX));\n            int y2 = static_cast&lt;int&gt;(std::round((letterboxSize.height - padH + 0.1f) * maskScaleY));\n\n            x1 = std::max(0, std::min(x1, maskW - 1));\n            y1 = std::max(0, std::min(y1, maskH - 1));\n            x2 = std::max(x1, std::min(x2, maskW));\n            y2 = std::max(y1, std::min(y2, maskH));\n\n            if (x2 &lt;= x1 || y2 &lt;= y1) continue;\n\n            cv::Mat croppedMask = finalMask(cv::Rect(x1, y1, x2 - x1, y2 - y1)).clone();\n\n            // Resize to original image size\n            cv::Mat resizedMask;\n            cv::resize(croppedMask, resizedMask, originalSize, 0, 0, cv::INTER_LINEAR);\n\n            // Threshold and convert to binary\n            cv::Mat binaryMask;\n            cv::threshold(resizedMask, binaryMask, MASK_THRESHOLD, 255.0, cv::THRESH_BINARY);\n            binaryMask.convertTo(binaryMask, CV_8U);\n\n            // Crop to bounding box\n            cv::Mat finalBinaryMask = cv::Mat::zeros(originalSize, CV_8U);\n            cv::Rect roi(seg.box.x, seg.box.y, seg.box.width, seg.box.height);\n            roi &amp;= cv::Rect(0, 0, binaryMask.cols, binaryMask.rows);\n            if (roi.area() &gt; 0) {\n                binaryMask(roi).copyTo(finalBinaryMask(roi));\n            }\n\n            seg.mask = finalBinaryMask;\n            results.push_back(seg);\n        }\n\n        return results;\n    }\n\n    std::vector&lt;Segmentation&gt; postprocessV26(const cv::Size&amp; originalSize,\n                                              const cv::Size&amp; letterboxSize,\n                                              const float* output0,\n                                              const float* output1,\n                                              const std::vector&lt;int64_t&gt;&amp; shape0,\n                                              const std::vector&lt;int64_t&gt;&amp; shape1,\n                                              float confThreshold) {\n        std::vector&lt;Segmentation&gt; results;\n\n        const size_t numDetections = shape0[1];\n        const size_t numFeaturesPerDet = shape0[2]; // Should be 38\n\n        if (numDetections == 0 || numFeaturesPerDet != 38) return results;\n\n        const int maskH = static_cast&lt;int&gt;(shape1[2]);\n        const int maskW = static_cast&lt;int&gt;(shape1[3]);\n\n        // Load prototype masks\n        std::vector&lt;cv::Mat&gt; prototypeMasks;\n        prototypeMasks.reserve(32);\n        for (int m = 0; m &lt; 32; ++m) {\n            cv::Mat proto(maskH, maskW, CV_32F, const_cast&lt;float*&gt;(output1 + m * maskH * maskW));\n            prototypeMasks.emplace_back(proto.clone());\n        }\n\n        // Pre-compute scale and padding\n        float gain, padW, padH;\n        preprocessing::getScalePad(originalSize, letterboxSize, gain, padW, padH);\n        const float invGain = 1.0f / gain;\n\n        float maskScaleX = static_cast&lt;float&gt;(maskW) / letterboxSize.width;\n        float maskScaleY = static_cast&lt;float&gt;(maskH) / letterboxSize.height;\n\n        results.reserve(numDetections);\n\n        for (size_t i = 0; i &lt; numDetections; ++i) {\n            const float* det = output0 + i * numFeaturesPerDet;\n\n            // V26 format: [x1, y1, x2, y2, conf, class_id, mask_coeffs(32)]\n            const float x1_lb = det[0];\n            const float y1_lb = det[1];\n            const float x2_lb = det[2];\n            const float y2_lb = det[3];\n            const float conf = det[4];\n            const int classId = static_cast&lt;int&gt;(det[5]);\n\n            if (conf &lt; confThreshold) continue;\n\n            // Descale from letterbox to original coordinates\n            const float x1 = (x1_lb - padW) * invGain;\n            const float y1 = (y1_lb - padH) * invGain;\n            const float x2 = (x2_lb - padW) * invGain;\n            const float y2 = (y2_lb - padH) * invGain;\n\n            Segmentation seg;\n            seg.box.x = utils::clamp(static_cast&lt;int&gt;(x1), 0, originalSize.width - 1);\n            seg.box.y = utils::clamp(static_cast&lt;int&gt;(y1), 0, originalSize.height - 1);\n            seg.box.width = utils::clamp(static_cast&lt;int&gt;(x2 - x1), 1, originalSize.width - seg.box.x);\n            seg.box.height = utils::clamp(static_cast&lt;int&gt;(y2 - y1), 1, originalSize.height - seg.box.y);\n            seg.conf = conf;\n            seg.classId = classId;\n\n            // Extract mask coefficients\n            std::vector&lt;float&gt; maskCoeffs(32);\n            for (int m = 0; m &lt; 32; ++m) {\n                maskCoeffs[m] = det[6 + m];\n            }\n\n            // Compute mask from prototype masks and coefficients\n            cv::Mat finalMask = cv::Mat::zeros(maskH, maskW, CV_32F);\n            for (int m = 0; m &lt; 32; ++m) {\n                finalMask += maskCoeffs[m] * prototypeMasks[m];\n            }\n\n            // Apply sigmoid activation\n            cv::exp(-finalMask, finalMask);\n            finalMask = 1.0 / (1.0 + finalMask);\n\n            // Crop to letterbox area\n            int mx1 = static_cast&lt;int&gt;(std::round((padW - 0.1f) * maskScaleX));\n            int my1 = static_cast&lt;int&gt;(std::round((padH - 0.1f) * maskScaleY));\n            int mx2 = static_cast&lt;int&gt;(std::round((letterboxSize.width - padW + 0.1f) * maskScaleX));\n            int my2 = static_cast&lt;int&gt;(std::round((letterboxSize.height - padH + 0.1f) * maskScaleY));\n\n            mx1 = std::max(0, std::min(mx1, maskW - 1));\n            my1 = std::max(0, std::min(my1, maskH - 1));\n            mx2 = std::max(mx1, std::min(mx2, maskW));\n            my2 = std::max(my1, std::min(my2, maskH));\n\n            if (mx2 &lt;= mx1 || my2 &lt;= my1) continue;\n\n            cv::Mat croppedMask = finalMask(cv::Rect(mx1, my1, mx2 - mx1, my2 - my1)).clone();\n\n            // Resize to original image size\n            cv::Mat resizedMask;\n            cv::resize(croppedMask, resizedMask, originalSize, 0, 0, cv::INTER_LINEAR);\n\n            // Threshold and convert to binary\n            cv::Mat binaryMask;\n            cv::threshold(resizedMask, binaryMask, MASK_THRESHOLD, 255.0, cv::THRESH_BINARY);\n            binaryMask.convertTo(binaryMask, CV_8U);\n\n            // Crop to bounding box\n            cv::Mat finalBinaryMask = cv::Mat::zeros(originalSize, CV_8U);\n            cv::Rect roi(seg.box.x, seg.box.y, seg.box.width, seg.box.height);\n            roi &amp;= cv::Rect(0, 0, binaryMask.cols, binaryMask.rows);\n            if (roi.area() &gt; 0) {\n                binaryMask(roi).copyTo(finalBinaryMask(roi));\n            }\n\n            seg.mask = finalBinaryMask;\n            results.push_back(seg);\n        }\n\n        return results;\n    }\n};\n\n} // namespace seg\n} // namespace yolos\n</code></pre>"},{"location":"yolos/yolos_8hpp/","title":"File yolos.hpp","text":"<p>FileList &gt; include &gt; yolos &gt; yolos.hpp</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"yolos/core/types.hpp\"</code></li> <li><code>#include \"yolos/core/version.hpp\"</code></li> <li><code>#include \"yolos/core/utils.hpp\"</code></li> <li><code>#include \"yolos/core/preprocessing.hpp\"</code></li> <li><code>#include \"yolos/core/nms.hpp\"</code></li> <li><code>#include \"yolos/core/drawing.hpp\"</code></li> <li><code>#include \"yolos/core/session_base.hpp\"</code></li> <li><code>#include \"yolos/tasks/detection.hpp\"</code></li> <li><code>#include \"yolos/tasks/segmentation.hpp\"</code></li> <li><code>#include \"yolos/tasks/pose.hpp\"</code></li> <li><code>#include \"yolos/tasks/obb.hpp\"</code></li> <li><code>#include \"yolos/tasks/classification.hpp\"</code></li> </ul>"},{"location":"yolos/yolos_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace yolos <p>The documentation for this class was generated from the following file <code>include/yolos/yolos.hpp</code></p>"},{"location":"yolos/yolos_8hpp_source/","title":"File yolos.hpp","text":"<p>File List &gt; include &gt; yolos &gt; yolos.hpp</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n// ============================================================================\n// YOLOs-CPP - Unified YOLO Inference Library\n// ============================================================================\n// Master include header for all YOLO tasks.\n//\n// Usage:\n//   #include \"yolos/yolos.hpp\"  // Include all tasks\n//   or include specific tasks:\n//   #include \"yolos/tasks/detection.hpp\"\n//   #include \"yolos/tasks/segmentation.hpp\"\n//   #include \"yolos/tasks/pose.hpp\"\n//   #include \"yolos/tasks/obb.hpp\"\n//   #include \"yolos/tasks/classification.hpp\"\n//\n// Author: YOLOs-CPP Team, https://github.com/Geekgineer/YOLOs-CPP\n// ============================================================================\n\n// Core components\n#include \"yolos/core/types.hpp\"\n#include \"yolos/core/version.hpp\"\n#include \"yolos/core/utils.hpp\"\n#include \"yolos/core/preprocessing.hpp\"\n#include \"yolos/core/nms.hpp\"\n#include \"yolos/core/drawing.hpp\"\n#include \"yolos/core/session_base.hpp\"\n\n// Task-specific implementations\n#include \"yolos/tasks/detection.hpp\"\n#include \"yolos/tasks/segmentation.hpp\"\n#include \"yolos/tasks/pose.hpp\"\n#include \"yolos/tasks/obb.hpp\"\n#include \"yolos/tasks/classification.hpp\"\n\n// ============================================================================\n// Namespace Aliases for Convenience\n// ============================================================================\nnamespace yolos {\n\n// Detection task aliases\nusing Detection = det::Detection;\nusing YOLODetector = det::YOLODetector;\nusing YOLO26Detector = det::YOLO26Detector;\n\n// Segmentation task aliases\nusing Segmentation = seg::Segmentation;\nusing YOLOSegDetector = seg::YOLOSegDetector;\n\n// Pose estimation task aliases\nusing PoseResult = pose::PoseResult;\nusing YOLOPoseDetector = pose::YOLOPoseDetector;\n\n// OBB detection task aliases\nusing OBBResult = obb::OBBResult;\nusing YOLOOBBDetector = obb::YOLOOBBDetector;\n\n// Classification task aliases\nusing ClassificationResult = cls::ClassificationResult;\nusing YOLOClassifier = cls::YOLOClassifier;\nusing YOLO26Classifier = cls::YOLO26Classifier;\n\n} // namespace yolos\n</code></pre>"},{"location":"yolos/namespaces/","title":"Namespace List","text":"<p>Here is a list of all namespaces with brief descriptions:</p> <ul> <li>namespace yolos <ul> <li>namespace cls </li> <li>namespace det </li> <li>namespace drawing </li> <li>namespace nms </li> <li>namespace obb </li> <li>namespace pose </li> <li>namespace preprocessing </li> <li>namespace seg </li> <li>namespace utils </li> <li>namespace version </li> </ul> </li> </ul>"},{"location":"yolos/classes/","title":"Class Index","text":""},{"location":"yolos/classes/#b","title":"b","text":"<ul> <li>BoundingBox (yolos)</li> </ul>"},{"location":"yolos/classes/#c","title":"c","text":"<ul> <li>ClassificationResult (yolos::cls)</li> </ul>"},{"location":"yolos/classes/#d","title":"d","text":"<ul> <li>Detection (yolos::det)</li> </ul>"},{"location":"yolos/classes/#i","title":"i","text":"<ul> <li>InferenceBuffer (yolos::preprocessing)</li> </ul>"},{"location":"yolos/classes/#k","title":"k","text":"<ul> <li>KeyPoint (yolos)</li> </ul>"},{"location":"yolos/classes/#o","title":"o","text":"<ul> <li>OBBResult (yolos::obb)</li> <li>OrientedBoundingBox (yolos)</li> <li>OrtSessionBase (yolos)</li> </ul>"},{"location":"yolos/classes/#p","title":"p","text":"<ul> <li>PoseResult (yolos::pose)</li> </ul>"},{"location":"yolos/classes/#s","title":"s","text":"<ul> <li>Segmentation (yolos::seg)</li> </ul>"},{"location":"yolos/classes/#y","title":"y","text":"<ul> <li>YOLO11Classifier (yolos::cls)</li> <li>YOLO12Classifier (yolos::cls)</li> <li>YOLO26Classifier (yolos::cls)</li> <li>YOLO26Detector (yolos::det)</li> <li>YOLOClassifier (yolos::cls)</li> <li>YOLODetector (yolos::det)</li> <li>YOLONASDetector (yolos::det)</li> <li>YOLOOBBDetector (yolos::obb)</li> <li>YOLOPoseDetector (yolos::pose)</li> <li>YOLOSegDetector (yolos::seg)</li> <li>YOLOv10Detector (yolos::det)</li> <li>YOLOv11Detector (yolos::det)</li> <li>YOLOv7Detector (yolos::det)</li> <li>YOLOv8Detector (yolos::det)</li> </ul>"},{"location":"yolos/hierarchy/","title":"Class Hierarchy","text":"<p>This inheritance list is sorted roughly, but not completely, alphabetically:</p> <ul> <li>class yolos::OrtSessionBase Base class for ONNX Runtime session management Handles model loading, session configuration, and common inference setup. <ul> <li>class yolos::det::YOLODetector Base YOLO detector with runtime version auto-detection. <ul> <li>class yolos::det::YOLO26Detector YOLOv26 detector (forces V26 end-to-end postprocessing) </li> <li>class yolos::det::YOLONASDetector YOLO-NAS detector (forces NAS postprocessing) </li> <li>class yolos::det::YOLOv10Detector YOLOv10 detector (forces V10 end-to-end postprocessing) </li> <li>class yolos::det::YOLOv11Detector YOLOv11 detector (forces standard postprocessing) </li> <li>class yolos::det::YOLOv7Detector YOLOv7 detector (forces V7 postprocessing) </li> <li>class yolos::det::YOLOv8Detector YOLOv8 detector (forces standard postprocessing) </li> </ul> </li> <li>class yolos::obb::YOLOOBBDetector YOLO oriented bounding box detector for rotated object detection. </li> <li>class yolos::pose::YOLOPoseDetector YOLO pose estimation detector with keypoint detection. </li> <li>class yolos::seg::YOLOSegDetector YOLO segmentation detector with mask prediction. </li> </ul> </li> <li>class yolos::cls::YOLOClassifier YOLO classifier for image classification. <ul> <li>class yolos::cls::YOLO11Classifier YOLOv11 classifier. </li> <li>class yolos::cls::YOLO12Classifier YOLOv12 classifier. </li> <li>class yolos::cls::YOLO26Classifier YOLO26 classifier. </li> </ul> </li> <li>struct yolos::BoundingBox </li> <li>struct yolos::KeyPoint </li> <li>struct yolos::OrientedBoundingBox </li> <li>struct yolos::cls::ClassificationResult Classification result containing class ID, confidence, and class name. </li> <li>struct yolos::det::Detection Detection result containing bounding box, confidence, and class ID.</li> <li>struct yolos::obb::OBBResult OBB detection result containing oriented bounding box, confidence, and class ID. </li> <li>struct yolos::pose::PoseResult Pose estimation result containing bounding box, confidence, and keypoints. </li> <li>struct yolos::preprocessing::InferenceBuffer Pre-allocated inference buffer to avoid per-frame allocations. </li> <li>struct yolos::seg::Segmentation Segmentation result containing bounding box, confidence, class ID, and mask.</li> </ul>"},{"location":"yolos/modules/","title":"Modules","text":"<p>No modules found.</p>"},{"location":"yolos/pages/","title":"Related Pages","text":"<p>Here is a list of all related documentation pages:</p>"},{"location":"yolos/class_members/","title":"Class Members","text":""},{"location":"yolos/class_members/#a","title":"a","text":"<ul> <li>area (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> <li>angle (yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_members/#b","title":"b","text":"<ul> <li>BoundingBox (yolos::BoundingBox)</li> <li>box (yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>buffer_ (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>blob (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_members/#c","title":"c","text":"<ul> <li>confidence (yolos::KeyPoint, yolos::cls::ClassificationResult)</li> <li>createInputTensor (yolos::OrtSessionBase)</li> <li>ClassificationResult (yolos::cls::ClassificationResult)</li> <li>classId (yolos::cls::ClassificationResult, yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>className (yolos::cls::ClassificationResult)</li> <li>classNames_ (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>classify (yolos::cls::YOLOClassifier)</li> <li>conf (yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>classColors_ (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_members/#d","title":"d","text":"<ul> <li>device_ (yolos::OrtSessionBase)</li> <li>drawResult (yolos::cls::YOLOClassifier)</li> <li>Detection (yolos::det::Detection)</li> <li>detect (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector)</li> <li>detectVersion (yolos::det::YOLODetector)</li> <li>drawDetections (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector)</li> <li>drawDetectionsWithMask (yolos::det::YOLODetector)</li> <li>drawPoses (yolos::pose::YOLOPoseDetector)</li> <li>drawSkeletonsOnly (yolos::pose::YOLOPoseDetector)</li> <li>drawMasksOnly (yolos::seg::YOLOSegDetector)</li> <li>drawSegmentations (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_members/#e","title":"e","text":"<ul> <li>env_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>ensureCapacity (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_members/#f","title":"f","text":"<ul> <li>FEATURES_PER_KEYPOINT (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_members/#g","title":"g","text":"<ul> <li>getDevice (yolos::OrtSessionBase)</li> <li>getInputShape (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>getNumInputNodes (yolos::OrtSessionBase)</li> <li>getNumOutputNodes (yolos::OrtSessionBase)</li> <li>getClassNames (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>getClassColors (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::seg::YOLOSegDetector)</li> <li>getPoseSkeleton (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_members/#h","title":"h","text":"<ul> <li>height (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_members/#i","title":"i","text":"<ul> <li>intersect (yolos::BoundingBox)</li> <li>iou (yolos::BoundingBox)</li> <li>initSession (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputNameAllocs_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputNames_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputShape_ (yolos::OrtSessionBase)</li> <li>isDynamicBatchSize (yolos::OrtSessionBase)</li> <li>isDynamicBatchSize_ (yolos::OrtSessionBase)</li> <li>isDynamicInputShape (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>isDynamicInputShape_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputBuffer_ (yolos::cls::YOLOClassifier)</li> <li>inputImageShape_ (yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_members/#k","title":"k","text":"<ul> <li>KeyPoint (yolos::KeyPoint)</li> <li>keypoints (yolos::pose::PoseResult)</li> </ul>"},{"location":"yolos/class_members/#l","title":"l","text":"<ul> <li>lastInputSize (yolos::preprocessing::InferenceBuffer)</li> <li>lastTargetSize (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_members/#m","title":"m","text":"<ul> <li>mask (yolos::seg::Segmentation)</li> <li>MASK_THRESHOLD (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_members/#n","title":"n","text":"<ul> <li>numInputNodes_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>numOutputNodes_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>numClasses_ (yolos::cls::YOLOClassifier)</li> <li>NUM_KEYPOINTS (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_members/#o","title":"o","text":"<ul> <li>OrientedBoundingBox (yolos::OrientedBoundingBox)</li> <li>OrtSessionBase (yolos::OrtSessionBase)</li> <li>operator= (yolos::OrtSessionBase)</li> <li>outputNameAllocs_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>outputNames_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>OBBResult (yolos::obb::OBBResult)</li> </ul>"},{"location":"yolos/class_members/#p","title":"p","text":"<ul> <li>postprocess (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>preprocess (yolos::cls::YOLOClassifier)</li> <li>postprocessNAS (yolos::det::YOLODetector)</li> <li>postprocessStandard (yolos::det::YOLODetector)</li> <li>postprocessV10 (yolos::det::YOLODetector)</li> <li>postprocessV7 (yolos::det::YOLODetector)</li> <li>postprocessV26 (yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>postprocessV8 (yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector)</li> <li>PoseResult (yolos::pose::PoseResult)</li> </ul>"},{"location":"yolos/class_members/#r","title":"r","text":"<ul> <li>runInference (yolos::OrtSessionBase)</li> <li>resized (yolos::preprocessing::InferenceBuffer)</li> <li>rgbFloat (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_members/#s","title":"s","text":"<ul> <li>sessionOptions_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>session_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>Segmentation (yolos::seg::Segmentation)</li> <li>segment (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_members/#v","title":"v","text":"<ul> <li>version_ (yolos::det::YOLODetector)</li> </ul>"},{"location":"yolos/class_members/#w","title":"w","text":"<ul> <li>width (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_members/#x","title":"x","text":"<ul> <li>x (yolos::BoundingBox, yolos::KeyPoint, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_members/#y","title":"y","text":"<ul> <li>y (yolos::BoundingBox, yolos::KeyPoint, yolos::OrientedBoundingBox)</li> <li>YOLO11Classifier (yolos::cls::YOLO11Classifier)</li> <li>YOLO12Classifier (yolos::cls::YOLO12Classifier)</li> <li>YOLO26Classifier (yolos::cls::YOLO26Classifier)</li> <li>YOLOClassifier (yolos::cls::YOLOClassifier)</li> <li>YOLO26Detector (yolos::det::YOLO26Detector)</li> <li>YOLODetector (yolos::det::YOLODetector)</li> <li>YOLONASDetector (yolos::det::YOLONASDetector)</li> <li>YOLOv10Detector (yolos::det::YOLOv10Detector)</li> <li>YOLOv11Detector (yolos::det::YOLOv11Detector)</li> <li>YOLOv7Detector (yolos::det::YOLOv7Detector)</li> <li>YOLOv8Detector (yolos::det::YOLOv8Detector)</li> <li>YOLOOBBDetector (yolos::obb::YOLOOBBDetector)</li> <li>YOLOPoseDetector (yolos::pose::YOLOPoseDetector)</li> <li>YOLOSegDetector (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_members/#_1","title":"~","text":"<ul> <li>~OrtSessionBase (yolos::OrtSessionBase)</li> <li>~YOLOClassifier (yolos::cls::YOLOClassifier)</li> <li>~YOLODetector (yolos::det::YOLODetector)</li> <li>~YOLOOBBDetector (yolos::obb::YOLOOBBDetector)</li> <li>~YOLOPoseDetector (yolos::pose::YOLOPoseDetector)</li> <li>~YOLOSegDetector (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_functions/","title":"Class Member Functions","text":""},{"location":"yolos/class_member_functions/#a","title":"a","text":"<ul> <li>area (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_functions/#b","title":"b","text":"<ul> <li>BoundingBox (yolos::BoundingBox)</li> </ul>"},{"location":"yolos/class_member_functions/#c","title":"c","text":"<ul> <li>createInputTensor (yolos::OrtSessionBase)</li> <li>ClassificationResult (yolos::cls::ClassificationResult)</li> <li>classify (yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_functions/#d","title":"d","text":"<ul> <li>drawResult (yolos::cls::YOLOClassifier)</li> <li>Detection (yolos::det::Detection)</li> <li>detect (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector)</li> <li>detectVersion (yolos::det::YOLODetector)</li> <li>drawDetections (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector)</li> <li>drawDetectionsWithMask (yolos::det::YOLODetector)</li> <li>drawPoses (yolos::pose::YOLOPoseDetector)</li> <li>drawSkeletonsOnly (yolos::pose::YOLOPoseDetector)</li> <li>drawMasksOnly (yolos::seg::YOLOSegDetector)</li> <li>drawSegmentations (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_functions/#e","title":"e","text":"<ul> <li>ensureCapacity (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_member_functions/#g","title":"g","text":"<ul> <li>getDevice (yolos::OrtSessionBase)</li> <li>getInputShape (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>getNumInputNodes (yolos::OrtSessionBase)</li> <li>getNumOutputNodes (yolos::OrtSessionBase)</li> <li>getClassNames (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>getClassColors (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::seg::YOLOSegDetector)</li> <li>getPoseSkeleton (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_member_functions/#i","title":"i","text":"<ul> <li>intersect (yolos::BoundingBox)</li> <li>iou (yolos::BoundingBox)</li> <li>initSession (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>isDynamicBatchSize (yolos::OrtSessionBase)</li> <li>isDynamicInputShape (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_functions/#k","title":"k","text":"<ul> <li>KeyPoint (yolos::KeyPoint)</li> </ul>"},{"location":"yolos/class_member_functions/#o","title":"o","text":"<ul> <li>OrientedBoundingBox (yolos::OrientedBoundingBox)</li> <li>OrtSessionBase (yolos::OrtSessionBase)</li> <li>operator= (yolos::OrtSessionBase)</li> <li>OBBResult (yolos::obb::OBBResult)</li> </ul>"},{"location":"yolos/class_member_functions/#p","title":"p","text":"<ul> <li>postprocess (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>preprocess (yolos::cls::YOLOClassifier)</li> <li>postprocessNAS (yolos::det::YOLODetector)</li> <li>postprocessStandard (yolos::det::YOLODetector)</li> <li>postprocessV10 (yolos::det::YOLODetector)</li> <li>postprocessV7 (yolos::det::YOLODetector)</li> <li>postprocessV26 (yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>postprocessV8 (yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector)</li> <li>PoseResult (yolos::pose::PoseResult)</li> </ul>"},{"location":"yolos/class_member_functions/#r","title":"r","text":"<ul> <li>runInference (yolos::OrtSessionBase)</li> </ul>"},{"location":"yolos/class_member_functions/#s","title":"s","text":"<ul> <li>Segmentation (yolos::seg::Segmentation)</li> <li>segment (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_functions/#y","title":"y","text":"<ul> <li>YOLO11Classifier (yolos::cls::YOLO11Classifier)</li> <li>YOLO12Classifier (yolos::cls::YOLO12Classifier)</li> <li>YOLO26Classifier (yolos::cls::YOLO26Classifier)</li> <li>YOLOClassifier (yolos::cls::YOLOClassifier)</li> <li>YOLO26Detector (yolos::det::YOLO26Detector)</li> <li>YOLODetector (yolos::det::YOLODetector)</li> <li>YOLONASDetector (yolos::det::YOLONASDetector)</li> <li>YOLOv10Detector (yolos::det::YOLOv10Detector)</li> <li>YOLOv11Detector (yolos::det::YOLOv11Detector)</li> <li>YOLOv7Detector (yolos::det::YOLOv7Detector)</li> <li>YOLOv8Detector (yolos::det::YOLOv8Detector)</li> <li>YOLOOBBDetector (yolos::obb::YOLOOBBDetector)</li> <li>YOLOPoseDetector (yolos::pose::YOLOPoseDetector)</li> <li>YOLOSegDetector (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_functions/#_1","title":"~","text":"<ul> <li>~OrtSessionBase (yolos::OrtSessionBase)</li> <li>~YOLOClassifier (yolos::cls::YOLOClassifier)</li> <li>~YOLODetector (yolos::det::YOLODetector)</li> <li>~YOLOOBBDetector (yolos::obb::YOLOOBBDetector)</li> <li>~YOLOPoseDetector (yolos::pose::YOLOPoseDetector)</li> <li>~YOLOSegDetector (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_variables/","title":"Class Member Variables","text":""},{"location":"yolos/class_member_variables/#a","title":"a","text":"<ul> <li>angle (yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_variables/#b","title":"b","text":"<ul> <li>box (yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>buffer_ (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>blob (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_member_variables/#c","title":"c","text":"<ul> <li>confidence (yolos::KeyPoint, yolos::cls::ClassificationResult)</li> <li>classId (yolos::cls::ClassificationResult, yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>className (yolos::cls::ClassificationResult)</li> <li>classNames_ (yolos::cls::YOLOClassifier, yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> <li>conf (yolos::det::Detection, yolos::obb::OBBResult, yolos::pose::PoseResult, yolos::seg::Segmentation)</li> <li>classColors_ (yolos::det::YOLODetector, yolos::obb::YOLOOBBDetector, yolos::pose::YOLOPoseDetector, yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_variables/#d","title":"d","text":"<ul> <li>device_ (yolos::OrtSessionBase)</li> </ul>"},{"location":"yolos/class_member_variables/#e","title":"e","text":"<ul> <li>env_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_variables/#f","title":"f","text":"<ul> <li>FEATURES_PER_KEYPOINT (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_member_variables/#h","title":"h","text":"<ul> <li>height (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_variables/#i","title":"i","text":"<ul> <li>inputNameAllocs_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputNames_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputShape_ (yolos::OrtSessionBase)</li> <li>isDynamicBatchSize_ (yolos::OrtSessionBase)</li> <li>isDynamicInputShape_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>inputBuffer_ (yolos::cls::YOLOClassifier)</li> <li>inputImageShape_ (yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_variables/#k","title":"k","text":"<ul> <li>keypoints (yolos::pose::PoseResult)</li> </ul>"},{"location":"yolos/class_member_variables/#l","title":"l","text":"<ul> <li>lastInputSize (yolos::preprocessing::InferenceBuffer)</li> <li>lastTargetSize (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_member_variables/#m","title":"m","text":"<ul> <li>mask (yolos::seg::Segmentation)</li> <li>MASK_THRESHOLD (yolos::seg::YOLOSegDetector)</li> </ul>"},{"location":"yolos/class_member_variables/#n","title":"n","text":"<ul> <li>numInputNodes_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>numOutputNodes_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>numClasses_ (yolos::cls::YOLOClassifier)</li> <li>NUM_KEYPOINTS (yolos::pose::YOLOPoseDetector)</li> </ul>"},{"location":"yolos/class_member_variables/#o","title":"o","text":"<ul> <li>outputNameAllocs_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>outputNames_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_variables/#r","title":"r","text":"<ul> <li>resized (yolos::preprocessing::InferenceBuffer)</li> <li>rgbFloat (yolos::preprocessing::InferenceBuffer)</li> </ul>"},{"location":"yolos/class_member_variables/#s","title":"s","text":"<ul> <li>sessionOptions_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> <li>session_ (yolos::OrtSessionBase, yolos::cls::YOLOClassifier)</li> </ul>"},{"location":"yolos/class_member_variables/#v","title":"v","text":"<ul> <li>version_ (yolos::det::YOLODetector)</li> </ul>"},{"location":"yolos/class_member_variables/#w","title":"w","text":"<ul> <li>width (yolos::BoundingBox, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_variables/#x","title":"x","text":"<ul> <li>x (yolos::BoundingBox, yolos::KeyPoint, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_variables/#y","title":"y","text":"<ul> <li>y (yolos::BoundingBox, yolos::KeyPoint, yolos::OrientedBoundingBox)</li> </ul>"},{"location":"yolos/class_member_typedefs/","title":"Class Member Typedefs","text":"<p>Nothing related to Class Member Typedefs found.</p>"},{"location":"yolos/class_member_enums/","title":"Class Member Enums","text":"<p>Nothing related to Class Member Enums found.</p>"},{"location":"yolos/namespace_members/","title":"Namespace Members","text":""},{"location":"yolos/namespace_members/#c","title":"c","text":"<ul> <li>ClassificationResult (yolos)</li> <li>createClassifier (yolos::cls)</li> <li>createDetector (yolos::det)</li> <li>computeRotatedIoU (yolos::nms)</li> <li>clamp (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_members/#d","title":"d","text":"<ul> <li>Detection (yolos)</li> <li>drawClassificationResult (yolos::cls)</li> <li>drawBoundingBox (yolos::drawing)</li> <li>drawBoundingBoxWithMask (yolos::drawing)</li> <li>drawOrientedBoundingBox (yolos::drawing)</li> <li>drawPoseSkeleton (yolos::drawing)</li> <li>drawSegmentationMask (yolos::drawing)</li> <li>descaleCoordsBatch (yolos::preprocessing)</li> <li>detectClassificationVersion (yolos::version)</li> <li>detectFromOutputShape (yolos::version)</li> </ul>"},{"location":"yolos/namespace_members/#g","title":"g","text":"<ul> <li>getPoseSkeleton (yolos)</li> <li>generateColors (yolos::drawing)</li> <li>getPosePalette (yolos::drawing)</li> <li>getLetterboxParams (yolos::preprocessing)</li> <li>getScalePad (yolos::preprocessing)</li> <li>getClassNames (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_members/#l","title":"l","text":"<ul> <li>letterBox (yolos::preprocessing)</li> <li>letterBoxCentered (yolos::preprocessing)</li> <li>letterBoxToBlob (yolos::preprocessing)</li> </ul>"},{"location":"yolos/namespace_members/#n","title":"n","text":"<ul> <li>NMSBoxes (yolos::nms)</li> <li>NMSBoxesBatched (yolos::nms)</li> <li>NMSBoxesF (yolos::nms)</li> <li>NMSBoxesFBatched (yolos::nms)</li> <li>NMSRotated (yolos::nms)</li> <li>NMSRotatedBatched (yolos::nms)</li> </ul>"},{"location":"yolos/namespace_members/#o","title":"o","text":"<ul> <li>OBBResult (yolos)</li> </ul>"},{"location":"yolos/namespace_members/#p","title":"p","text":"<ul> <li>PoseResult (yolos)</li> </ul>"},{"location":"yolos/namespace_members/#r","title":"r","text":"<ul> <li>requiresNMS (yolos::version)</li> </ul>"},{"location":"yolos/namespace_members/#s","title":"s","text":"<ul> <li>Segmentation (yolos)</li> <li>scaleCoords (yolos::preprocessing)</li> <li>scaleKeypoint (yolos::preprocessing)</li> <li>sigmoid (yolos::utils)</li> <li>sigmoidInplace (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_members/#t","title":"t","text":"<ul> <li>toString (yolos::version)</li> </ul>"},{"location":"yolos/namespace_members/#v","title":"v","text":"<ul> <li>vectorProduct (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_members/#y","title":"y","text":"<ul> <li>YOLO26Classifier (yolos)</li> <li>YOLO26Detector (yolos)</li> <li>YOLOClassifier (yolos)</li> <li>YOLODetector (yolos)</li> <li>YOLOOBBDetector (yolos)</li> <li>YOLOPoseDetector (yolos)</li> <li>YOLOSegDetector (yolos)</li> <li>YOLOVersion (yolos)</li> </ul>"},{"location":"yolos/namespace_member_functions/","title":"Namespace Member Functions","text":""},{"location":"yolos/namespace_member_functions/#c","title":"c","text":"<ul> <li>createClassifier (yolos::cls)</li> <li>createDetector (yolos::det)</li> <li>computeRotatedIoU (yolos::nms)</li> <li>clamp (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_member_functions/#d","title":"d","text":"<ul> <li>drawClassificationResult (yolos::cls)</li> <li>drawBoundingBox (yolos::drawing)</li> <li>drawBoundingBoxWithMask (yolos::drawing)</li> <li>drawOrientedBoundingBox (yolos::drawing)</li> <li>drawPoseSkeleton (yolos::drawing)</li> <li>drawSegmentationMask (yolos::drawing)</li> <li>descaleCoordsBatch (yolos::preprocessing)</li> <li>detectClassificationVersion (yolos::version)</li> <li>detectFromOutputShape (yolos::version)</li> </ul>"},{"location":"yolos/namespace_member_functions/#g","title":"g","text":"<ul> <li>getPoseSkeleton (yolos)</li> <li>generateColors (yolos::drawing)</li> <li>getPosePalette (yolos::drawing)</li> <li>getLetterboxParams (yolos::preprocessing)</li> <li>getScalePad (yolos::preprocessing)</li> <li>getClassNames (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_member_functions/#l","title":"l","text":"<ul> <li>letterBox (yolos::preprocessing)</li> <li>letterBoxCentered (yolos::preprocessing)</li> <li>letterBoxToBlob (yolos::preprocessing)</li> </ul>"},{"location":"yolos/namespace_member_functions/#n","title":"n","text":"<ul> <li>NMSBoxes (yolos::nms)</li> <li>NMSBoxesBatched (yolos::nms)</li> <li>NMSBoxesF (yolos::nms)</li> <li>NMSBoxesFBatched (yolos::nms)</li> <li>NMSRotated (yolos::nms)</li> <li>NMSRotatedBatched (yolos::nms)</li> </ul>"},{"location":"yolos/namespace_member_functions/#r","title":"r","text":"<ul> <li>requiresNMS (yolos::version)</li> </ul>"},{"location":"yolos/namespace_member_functions/#s","title":"s","text":"<ul> <li>scaleCoords (yolos::preprocessing)</li> <li>scaleKeypoint (yolos::preprocessing)</li> <li>sigmoid (yolos::utils)</li> <li>sigmoidInplace (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_member_functions/#t","title":"t","text":"<ul> <li>toString (yolos::version)</li> </ul>"},{"location":"yolos/namespace_member_functions/#v","title":"v","text":"<ul> <li>vectorProduct (yolos::utils)</li> </ul>"},{"location":"yolos/namespace_member_variables/","title":"Namespace Member Variables","text":"<p>Nothing related to Namespace Member Variables found.</p>"},{"location":"yolos/namespace_member_typedefs/","title":"Namespace Member Typedefs","text":""},{"location":"yolos/namespace_member_typedefs/#c","title":"c","text":"<ul> <li>ClassificationResult (yolos)</li> </ul>"},{"location":"yolos/namespace_member_typedefs/#d","title":"d","text":"<ul> <li>Detection (yolos)</li> </ul>"},{"location":"yolos/namespace_member_typedefs/#o","title":"o","text":"<ul> <li>OBBResult (yolos)</li> </ul>"},{"location":"yolos/namespace_member_typedefs/#p","title":"p","text":"<ul> <li>PoseResult (yolos)</li> </ul>"},{"location":"yolos/namespace_member_typedefs/#s","title":"s","text":"<ul> <li>Segmentation (yolos)</li> </ul>"},{"location":"yolos/namespace_member_typedefs/#y","title":"y","text":"<ul> <li>YOLO26Classifier (yolos)</li> <li>YOLO26Detector (yolos)</li> <li>YOLOClassifier (yolos)</li> <li>YOLODetector (yolos)</li> <li>YOLOOBBDetector (yolos)</li> <li>YOLOPoseDetector (yolos)</li> <li>YOLOSegDetector (yolos)</li> </ul>"},{"location":"yolos/namespace_member_enums/","title":"Namespace Member Enums","text":""},{"location":"yolos/namespace_member_enums/#y","title":"y","text":"<ul> <li>YOLOVersion (yolos)</li> </ul>"},{"location":"yolos/functions/","title":"Functions","text":"<p>Nothing related to Functions found.</p>"},{"location":"yolos/macros/","title":"Macros","text":"<p>Nothing related to Macros found.</p>"},{"location":"yolos/variables/","title":"Variables","text":"<p>Nothing related to Variables found.</p>"},{"location":"yolos/links/","title":"Links","text":"<ul> <li>Related Pages</li> <li>Modules</li> <li>Class List</li> <li>Namespace ListNamespace List</li> <li>Namespace Members</li> <li>Namespace Member Functions</li> <li>Namespace Member Variables</li> <li>Namespace Member Typedefs</li> <li>Namespace Member Enumerations</li> <li>Class Index</li> <li>Class Hierarchy</li> <li>Class Members</li> <li>Class Member Functions</li> <li>Class Member Variables</li> <li>Class Member Typedefs</li> <li>Class Member Enumerations</li> <li>Files</li> <li>File Variables</li> <li>File Functions</li> <li>File Macros</li> </ul>"}]}